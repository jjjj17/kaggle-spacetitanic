{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ae50e2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:10.677738Z",
     "iopub.status.busy": "2024-03-08T03:56:10.677307Z",
     "iopub.status.idle": "2024-03-08T03:56:11.427142Z",
     "shell.execute_reply": "2024-03-08T03:56:11.425815Z"
    },
    "papermill": {
     "duration": 0.761438,
     "end_time": "2024-03-08T03:56:11.430049",
     "exception": false,
     "start_time": "2024-03-08T03:56:10.668611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983b9a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:11.444710Z",
     "iopub.status.busy": "2024-03-08T03:56:11.444216Z",
     "iopub.status.idle": "2024-03-08T03:56:14.039397Z",
     "shell.execute_reply": "2024-03-08T03:56:14.038395Z"
    },
    "papermill": {
     "duration": 2.605229,
     "end_time": "2024-03-08T03:56:14.041971",
     "exception": false,
     "start_time": "2024-03-08T03:56:11.436742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa68c3",
   "metadata": {
    "papermill": {
     "duration": 0.0058,
     "end_time": "2024-03-08T03:56:14.054011",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.048211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6e50fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.068258Z",
     "iopub.status.busy": "2024-03-08T03:56:14.067608Z",
     "iopub.status.idle": "2024-03-08T03:56:14.120569Z",
     "shell.execute_reply": "2024-03-08T03:56:14.119553Z"
    },
    "papermill": {
     "duration": 0.062921,
     "end_time": "2024-03-08T03:56:14.122993",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.060072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695e93eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.137452Z",
     "iopub.status.busy": "2024-03-08T03:56:14.136537Z",
     "iopub.status.idle": "2024-03-08T03:56:14.140856Z",
     "shell.execute_reply": "2024-03-08T03:56:14.140189Z"
    },
    "papermill": {
     "duration": 0.013489,
     "end_time": "2024-03-08T03:56:14.142665",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.129176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71790647",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.156452Z",
     "iopub.status.busy": "2024-03-08T03:56:14.155661Z",
     "iopub.status.idle": "2024-03-08T03:56:14.210779Z",
     "shell.execute_reply": "2024-03-08T03:56:14.209696Z"
    },
    "papermill": {
     "duration": 0.064805,
     "end_time": "2024-03-08T03:56:14.213470",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.148665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2362847667.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/2362847667.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_raw['Transported']\n",
    "train_df[['CabinDeck', 'CabinNum', 'CabinSide']] = train_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "train_df = pd.concat([train_df,pd.get_dummies(train_df.Destination)], axis = 1)\n",
    "train_df = train_df.drop(['Name','Destination','Cabin'],axis=1)\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "train_df['CryoSleep'] = train_df['CryoSleep'].astype(bool)\n",
    "train_df['VIP'] = train_df['VIP'].astype(bool)\n",
    "train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "train_df['CabinNum'] = train_df['CabinNum'].astype(int)\n",
    "train_df['CabinDeck'] = train_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ad4a3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.227902Z",
     "iopub.status.busy": "2024-03-08T03:56:14.227516Z",
     "iopub.status.idle": "2024-03-08T03:56:14.232025Z",
     "shell.execute_reply": "2024-03-08T03:56:14.230938Z"
    },
    "papermill": {
     "duration": 0.013886,
     "end_time": "2024-03-08T03:56:14.233883",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.219997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[train_df['HomePlanet'].isnull()]\n",
    "#df1 = train_df[train_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2165f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.248376Z",
     "iopub.status.busy": "2024-03-08T03:56:14.247417Z",
     "iopub.status.idle": "2024-03-08T03:56:14.276171Z",
     "shell.execute_reply": "2024-03-08T03:56:14.274992Z"
    },
    "papermill": {
     "duration": 0.038316,
     "end_time": "2024-03-08T03:56:14.278410",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.240094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6913 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0        0001_01           0      False  39.0  False          0.0        0.0   \n",
       "1        0002_01           1      False  24.0  False        109.0        9.0   \n",
       "2        0003_01           0      False  58.0   True         43.0     3576.0   \n",
       "3        0003_02           0      False  33.0  False          0.0     1283.0   \n",
       "4        0004_01           1      False  16.0  False        303.0       70.0   \n",
       "...          ...         ...        ...   ...    ...          ...        ...   \n",
       "8688     9276_01           0      False  41.0   True          0.0     6819.0   \n",
       "8689     9278_01           1       True  18.0  False          0.0        0.0   \n",
       "8690     9279_01           1      False  26.0  False          0.0        0.0   \n",
       "8691     9280_01           0      False  32.0  False          0.0     1049.0   \n",
       "8692     9280_02           0      False  44.0  False        126.0     4688.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Transported  CabinDeck  CabinNum  \\\n",
       "0              0.0     0.0     0.0        False          1         0   \n",
       "1             25.0   549.0    44.0         True          0         0   \n",
       "2              0.0  6715.0    49.0        False          0         0   \n",
       "3            371.0  3329.0   193.0        False          0         0   \n",
       "4            151.0   565.0     2.0         True          0         1   \n",
       "...            ...     ...     ...          ...        ...       ...   \n",
       "8688           0.0  1643.0    74.0        False          1        98   \n",
       "8689           0.0     0.0     0.0        False          0      1499   \n",
       "8690        1872.0     1.0     0.0         True          0      1500   \n",
       "8691           0.0   353.0  3235.0        False          0       608   \n",
       "8692           0.0     0.0    12.0         True          0       608   \n",
       "\n",
       "      CabinSide  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0             1        False          False         True  \n",
       "1             0        False          False         True  \n",
       "2             0        False          False         True  \n",
       "3             0        False          False         True  \n",
       "4             0        False          False         True  \n",
       "...         ...          ...            ...          ...  \n",
       "8688          1         True          False        False  \n",
       "8689          0        False           True        False  \n",
       "8690          0        False          False         True  \n",
       "8691          0         True          False        False  \n",
       "8692          0        False          False         True  \n",
       "\n",
       "[6913 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f4a5d0",
   "metadata": {
    "papermill": {
     "duration": 0.0063,
     "end_time": "2024-03-08T03:56:14.291250",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.284950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043792c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.305451Z",
     "iopub.status.busy": "2024-03-08T03:56:14.305055Z",
     "iopub.status.idle": "2024-03-08T03:56:14.310201Z",
     "shell.execute_reply": "2024-03-08T03:56:14.309092Z"
    },
    "papermill": {
     "duration": 0.014799,
     "end_time": "2024-03-08T03:56:14.312352",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.297553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.25):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01460e9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.328965Z",
     "iopub.status.busy": "2024-03-08T03:56:14.328216Z",
     "iopub.status.idle": "2024-03-08T03:56:14.336386Z",
     "shell.execute_reply": "2024-03-08T03:56:14.335211Z"
    },
    "papermill": {
     "duration": 0.019324,
     "end_time": "2024-03-08T03:56:14.338487",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.319163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5226 examples in training, 1687 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "dft, dfv = split_dataset(train_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(dft), len(dfv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1c5d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.353238Z",
     "iopub.status.busy": "2024-03-08T03:56:14.352883Z",
     "iopub.status.idle": "2024-03-08T03:56:14.359839Z",
     "shell.execute_reply": "2024-03-08T03:56:14.359063Z"
    },
    "papermill": {
     "duration": 0.016576,
     "end_time": "2024-03-08T03:56:14.361833",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.345257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y= dft['Transported']\n",
    "Y=dfv['Transported']\n",
    "x = dfv.drop(['Transported','PassengerId'],axis=1)\n",
    "X=dft.drop(['Transported','PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef5ef8a",
   "metadata": {
    "papermill": {
     "duration": 0.006391,
     "end_time": "2024-03-08T03:56:14.374805",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.368414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optuna HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66cb7713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:14.389635Z",
     "iopub.status.busy": "2024-03-08T03:56:14.389014Z",
     "iopub.status.idle": "2024-03-08T03:56:53.816504Z",
     "shell.execute_reply": "2024-03-08T03:56:53.815393Z"
    },
    "papermill": {
     "duration": 39.437778,
     "end_time": "2024-03-08T03:56:53.819027",
     "exception": false,
     "start_time": "2024-03-08T03:56:14.381249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 03:56:14,426] A new study created in memory with name: no-name-314351ee-8ea0-414f-aeca-e808442ebaba\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,463] Trial 0 finished with value: 0.7403675163011263 and parameters: {'booster': 'gblinear', 'gamma': 2.2771232381946017e-07, 'max_depth': 76, 'n_estimators': 99, 'grow_policy': 'depthwise', 'learning_rate': 0.013899900569374695}. Best is trial 0 with value: 0.7403675163011263.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,501] Trial 1 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 2.456651786276337e-06, 'max_depth': 16, 'n_estimators': 74, 'grow_policy': 'depthwise', 'learning_rate': 3.5850088518438147e-06}. Best is trial 0 with value: 0.7403675163011263.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,571] Trial 2 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 4.0871257084382885e-07, 'max_depth': 86, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 2.7070825216728338e-05}. Best is trial 0 with value: 0.7403675163011263.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,638] Trial 3 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.04144898355496692, 'max_depth': 82, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 1.4256540569068381e-07}. Best is trial 0 with value: 0.7403675163011263.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,679] Trial 4 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 2.9685696930204013e-07, 'max_depth': 44, 'n_estimators': 59, 'grow_policy': 'depthwise', 'learning_rate': 1.6314531372532136e-06}. Best is trial 0 with value: 0.7403675163011263.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,694] Trial 5 finished with value: 0.7409602845287493 and parameters: {'booster': 'gblinear', 'gamma': 0.013300822073363635, 'max_depth': 86, 'n_estimators': 81, 'grow_policy': 'depthwise', 'learning_rate': 0.01110617559292513}. Best is trial 5 with value: 0.7409602845287493.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,744] Trial 6 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 7.298685891430521e-05, 'max_depth': 46, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 2.086269034768402e-06}. Best is trial 5 with value: 0.7409602845287493.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,793] Trial 7 finished with value: 0.7605216360403082 and parameters: {'booster': 'gbtree', 'gamma': 0.0015571956303000462, 'max_depth': 49, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.0028235705137604483}. Best is trial 7 with value: 0.7605216360403082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,820] Trial 8 finished with value: 0.7676348547717843 and parameters: {'booster': 'dart', 'gamma': 1.2112482797819315e-06, 'max_depth': 5, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.026768461952667206}. Best is trial 8 with value: 0.7676348547717843.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,852] Trial 9 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.0432990710361529, 'max_depth': 20, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.0012078532707785205}. Best is trial 8 with value: 0.7676348547717843.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,904] Trial 10 finished with value: 0.7540011855364552 and parameters: {'booster': 'dart', 'gamma': 1.4633862576837494e-05, 'max_depth': 3, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.3305346011825711}. Best is trial 8 with value: 0.7676348547717843.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:14,995] Trial 11 finished with value: 0.7676348547717843 and parameters: {'booster': 'dart', 'gamma': 0.0013733127671925656, 'max_depth': 62, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.9388088741037335}. Best is trial 8 with value: 0.7676348547717843.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,092] Trial 12 finished with value: 0.7705986959098993 and parameters: {'booster': 'dart', 'gamma': 1.0587828191042182e-08, 'max_depth': 65, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.9104938093519679}. Best is trial 12 with value: 0.7705986959098993.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,168] Trial 13 finished with value: 0.7972732661529343 and parameters: {'booster': 'dart', 'gamma': 1.4351591543253687e-08, 'max_depth': 30, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.10826254589388}. Best is trial 13 with value: 0.7972732661529343.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,242] Trial 14 finished with value: 0.8043864848844102 and parameters: {'booster': 'dart', 'gamma': 2.332953659710084e-08, 'max_depth': 31, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.20103643167563887}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,315] Trial 15 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 1.1818014810020638e-08, 'max_depth': 30, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.0002768544507649712}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,353] Trial 16 finished with value: 0.7468879668049793 and parameters: {'booster': 'gblinear', 'gamma': 5.25373716200683e-08, 'max_depth': 35, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.08694791888497626}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,468] Trial 17 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 8.647860263267965e-06, 'max_depth': 100, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 1.7360141656793625e-08}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,528] Trial 18 finished with value: 0.7860106698280972 and parameters: {'booster': 'dart', 'gamma': 5.63487262727575e-08, 'max_depth': 27, 'n_estimators': 20, 'grow_policy': 'depthwise', 'learning_rate': 0.08686950876721553}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,610] Trial 19 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 0.00016811016373463253, 'max_depth': 39, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.00011742213771753048}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,649] Trial 20 finished with value: 0.5554238292827505 and parameters: {'booster': 'gblinear', 'gamma': 0.9279101073030919, 'max_depth': 14, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.0012038656269435192}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,710] Trial 21 finished with value: 0.7901600474214582 and parameters: {'booster': 'dart', 'gamma': 6.425505950036157e-08, 'max_depth': 26, 'n_estimators': 23, 'grow_policy': 'depthwise', 'learning_rate': 0.13417409657537263}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,768] Trial 22 finished with value: 0.7919383521043272 and parameters: {'booster': 'dart', 'gamma': 4.623576351026079e-08, 'max_depth': 24, 'n_estimators': 29, 'grow_policy': 'depthwise', 'learning_rate': 0.1338791074496342}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,835] Trial 23 finished with value: 0.7759336099585062 and parameters: {'booster': 'dart', 'gamma': 1.0556357991072642e-08, 'max_depth': 60, 'n_estimators': 34, 'grow_policy': 'depthwise', 'learning_rate': 0.007172431495808581}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,899] Trial 24 finished with value: 0.7836395969176052 and parameters: {'booster': 'dart', 'gamma': 9.062924935376417e-08, 'max_depth': 35, 'n_estimators': 16, 'grow_policy': 'depthwise', 'learning_rate': 0.04599483578915916}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:15,957] Trial 25 finished with value: 0.8014226437462952 and parameters: {'booster': 'dart', 'gamma': 1.376797824837718e-06, 'max_depth': 12, 'n_estimators': 31, 'grow_policy': 'depthwise', 'learning_rate': 0.26795491801385835}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,012] Trial 26 finished with value: 0.7978660343805573 and parameters: {'booster': 'dart', 'gamma': 1.9165436236585784e-06, 'max_depth': 13, 'n_estimators': 44, 'grow_policy': 'depthwise', 'learning_rate': 0.26634818396266075}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,065] Trial 27 finished with value: 0.7403675163011263 and parameters: {'booster': 'dart', 'gamma': 4.330098106855198e-06, 'max_depth': 5, 'n_estimators': 61, 'grow_policy': 'depthwise', 'learning_rate': 0.004215130147740157}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,109] Trial 28 finished with value: 0.7836395969176052 and parameters: {'booster': 'gblinear', 'gamma': 5.428530516048657e-05, 'max_depth': 13, 'n_estimators': 46, 'grow_policy': 'depthwise', 'learning_rate': 0.3753718495542486}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,165] Trial 29 finished with value: 0.7522228808535862 and parameters: {'booster': 'dart', 'gamma': 8.810958221704733e-07, 'max_depth': 9, 'n_estimators': 40, 'grow_policy': 'depthwise', 'learning_rate': 0.016649675256229294}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,207] Trial 30 finished with value: 0.7836395969176052 and parameters: {'booster': 'gblinear', 'gamma': 1.1239989064927214e-05, 'max_depth': 20, 'n_estimators': 69, 'grow_policy': 'depthwise', 'learning_rate': 0.3342071100943209}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,270] Trial 31 finished with value: 0.7771191464137522 and parameters: {'booster': 'dart', 'gamma': 1.7457810304605336e-07, 'max_depth': 32, 'n_estimators': 35, 'grow_policy': 'depthwise', 'learning_rate': 0.021045660501777325}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,336] Trial 32 finished with value: 0.7972732661529343 and parameters: {'booster': 'dart', 'gamma': 1.027319853793087e-06, 'max_depth': 21, 'n_estimators': 16, 'grow_policy': 'depthwise', 'learning_rate': 0.23849209538690724}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,392] Trial 33 finished with value: 0.7860106698280972 and parameters: {'booster': 'dart', 'gamma': 3.3115546500928144e-07, 'max_depth': 13, 'n_estimators': 43, 'grow_policy': 'depthwise', 'learning_rate': 0.9360198941936653}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,480] Trial 34 finished with value: 0.7984588026081803 and parameters: {'booster': 'dart', 'gamma': 1.936034506769057e-06, 'max_depth': 40, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.04777347421160738}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,563] Trial 35 finished with value: 0.7889745109662122 and parameters: {'booster': 'dart', 'gamma': 3.250915999248297e-06, 'max_depth': 40, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.039021472762320486}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,619] Trial 36 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 2.406501499602737e-05, 'max_depth': 56, 'n_estimators': 32, 'grow_policy': 'depthwise', 'learning_rate': 0.0005809136749166028}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,689] Trial 37 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 0.00016531952721006982, 'max_depth': 54, 'n_estimators': 2, 'grow_policy': 'depthwise', 'learning_rate': 6.0545574701850525e-05}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,775] Trial 38 finished with value: 0.7800829875518672 and parameters: {'booster': 'dart', 'gamma': 6.321044275219253e-07, 'max_depth': 41, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.009263587566122545}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,816] Trial 39 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.8087283441584837e-06, 'max_depth': 1, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 1.540958510643864e-05}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,893] Trial 40 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 0.00048224953513375927, 'max_depth': 71, 'n_estimators': 37, 'grow_policy': 'depthwise', 'learning_rate': 1.9291967805587731e-07}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:16,984] Trial 41 finished with value: 0.7895672791938352 and parameters: {'booster': 'dart', 'gamma': 1.672270868409862e-07, 'max_depth': 48, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.04361420608978836}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,054] Trial 42 finished with value: 0.7960877296976882 and parameters: {'booster': 'dart', 'gamma': 2.184452379599399e-08, 'max_depth': 18, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.1450354007812784}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,136] Trial 43 finished with value: 0.7978660343805573 and parameters: {'booster': 'dart', 'gamma': 3.616985128591933e-07, 'max_depth': 33, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.34688979563481953}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,223] Trial 44 finished with value: 0.7925311203319502 and parameters: {'booster': 'dart', 'gamma': 4.0231213874750137e-07, 'max_depth': 43, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.45605867971766284}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,272] Trial 45 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 5.138497216013036e-06, 'max_depth': 7, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.5456284800149176}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,322] Trial 46 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 5.086207784674552e-06, 'max_depth': 9, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.6038869508927632}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,375] Trial 47 finished with value: 0.7794902193242442 and parameters: {'booster': 'gbtree', 'gamma': 3.4076120625159794e-05, 'max_depth': 8, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.05493858532185744}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,432] Trial 48 finished with value: 0.7783046828689982 and parameters: {'booster': 'gbtree', 'gamma': 2.374978060535108e-06, 'max_depth': 15, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.004028482170203929}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,496] Trial 49 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 9.919331860992753e-06, 'max_depth': 23, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 0.21569432657586968}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,565] Trial 50 finished with value: 0.7812685240071132 and parameters: {'booster': 'gbtree', 'gamma': 2.1864746254115404e-05, 'max_depth': 24, 'n_estimators': 70, 'grow_policy': 'lossguide', 'learning_rate': 0.02028589822362406}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,628] Trial 51 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 7.127019561259654e-06, 'max_depth': 18, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.23797603654985272}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,694] Trial 52 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 7.049044753633813e-06, 'max_depth': 28, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.0716583224138672}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,757] Trial 53 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.2319743182281684e-05, 'max_depth': 23, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.17986739083985925}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,819] Trial 54 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 0.000109619747512575, 'max_depth': 23, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.19392166151157647}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:17,911] Trial 55 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 1.5859676083174276e-05, 'max_depth': 18, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.4721702958996839}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,028] Trial 56 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.00034014884653764854, 'max_depth': 17, 'n_estimators': 75, 'grow_policy': 'lossguide', 'learning_rate': 0.9741512475093694}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,085] Trial 57 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 3.385125071509632e-05, 'max_depth': 7, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.4855804404543251}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,132] Trial 58 finished with value: 0.7551867219917012 and parameters: {'booster': 'gbtree', 'gamma': 6.360465562445765e-05, 'max_depth': 4, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.10096308816563593}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,186] Trial 59 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 1.6232441873801427e-05, 'max_depth': 11, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.6036124388031475}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,249] Trial 60 finished with value: 0.7818612922347362 and parameters: {'booster': 'gbtree', 'gamma': 0.010083701264150908, 'max_depth': 19, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.030293917133191274}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,339] Trial 61 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 6.772496730327351e-06, 'max_depth': 11, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.472048594502769}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,432] Trial 62 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 1.2298435008260602e-05, 'max_depth': 11, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.16920660757089642}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,489] Trial 63 finished with value: 0.7877889745109662 and parameters: {'booster': 'gbtree', 'gamma': 2.0608230817480858e-05, 'max_depth': 17, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.6512327603254014}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,533] Trial 64 finished with value: 0.7178423236514523 and parameters: {'booster': 'gbtree', 'gamma': 4.2968417770299155e-05, 'max_depth': 2, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.08730055473985038}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,588] Trial 65 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 5.838461431759278e-06, 'max_depth': 11, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.28001203922044093}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,635] Trial 66 finished with value: 0.7794902193242442 and parameters: {'booster': 'gblinear', 'gamma': 2.6441464801153226e-08, 'max_depth': 28, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.2289601227192052}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,693] Trial 67 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.0001081084859137789, 'max_depth': 15, 'n_estimators': 74, 'grow_policy': 'lossguide', 'learning_rate': 9.458041231472441e-06}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,751] Trial 68 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 7.725407711662843e-07, 'max_depth': 11, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 6.779113094975903e-07}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,814] Trial 69 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 3.4595584021943042e-06, 'max_depth': 21, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.9801056169870008}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,859] Trial 70 finished with value: 0.7415530527563723 and parameters: {'booster': 'gblinear', 'gamma': 1.363305212251261e-06, 'max_depth': 36, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.011166747885849336}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:18,910] Trial 71 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 7.407842310008368e-06, 'max_depth': 6, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.46005814436763126}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,082] Trial 72 finished with value: 0.7747480735032602 and parameters: {'booster': 'gbtree', 'gamma': 1.8092893413478085e-05, 'max_depth': 96, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.6118549735320378}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,150] Trial 73 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 9.931778076885638e-06, 'max_depth': 26, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 1.1952300338211987e-08}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,205] Trial 74 finished with value: 0.7877889745109662 and parameters: {'booster': 'gbtree', 'gamma': 3.560103645791866e-06, 'max_depth': 11, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.11470978467723689}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,266] Trial 75 finished with value: 0.7866034380557202 and parameters: {'booster': 'gbtree', 'gamma': 5.828220640640243e-06, 'max_depth': 16, 'n_estimators': 72, 'grow_policy': 'lossguide', 'learning_rate': 0.06982644223705191}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,328] Trial 76 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 6.166535162071672e-07, 'max_depth': 20, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.2443701224252977}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,400] Trial 77 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 1.3176058816831786e-06, 'max_depth': 21, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.18971398602880418}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,459] Trial 78 finished with value: 0.7812685240071132 and parameters: {'booster': 'gbtree', 'gamma': 1.4189601049194898e-07, 'max_depth': 30, 'n_estimators': 12, 'grow_policy': 'depthwise', 'learning_rate': 0.03309178539675947}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,510] Trial 79 finished with value: 0.6455245998814464 and parameters: {'booster': 'gblinear', 'gamma': 1.466370931789529e-06, 'max_depth': 24, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.0019781682450239683}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,575] Trial 80 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 8.078930943092646e-08, 'max_depth': 13, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.3512245480602295}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,632] Trial 81 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 2.899771321592247e-08, 'max_depth': 13, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.3106214270823117}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,693] Trial 82 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 8.38268755207259e-08, 'max_depth': 18, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.13917909849219118}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,763] Trial 83 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 1.0013060920001709e-07, 'max_depth': 22, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.36787063980593665}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,830] Trial 84 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 4.188198202722797e-08, 'max_depth': 22, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.18871159915541047}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,892] Trial 85 finished with value: 0.7866034380557202 and parameters: {'booster': 'gbtree', 'gamma': 1.5779022840762672e-08, 'max_depth': 14, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.06682573731342012}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:19,956] Trial 86 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 1.1440125648100381e-07, 'max_depth': 32, 'n_estimators': 6, 'grow_policy': 'depthwise', 'learning_rate': 0.7099293686436728}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,013] Trial 87 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 3.923717555297823e-08, 'max_depth': 9, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.35476931934279243}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,082] Trial 88 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 4.621540456025532e-07, 'max_depth': 26, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.11123165201933395}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,140] Trial 89 finished with value: 0.7788974510966212 and parameters: {'booster': 'gbtree', 'gamma': 2.1336198321163517e-07, 'max_depth': 16, 'n_estimators': 18, 'grow_policy': 'depthwise', 'learning_rate': 0.016350829382882653}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,201] Trial 90 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 8.07529565766766e-08, 'max_depth': 4, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.0002723258664717895}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,268] Trial 91 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 2.842608161488727e-06, 'max_depth': 20, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.4376307361930623}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,335] Trial 92 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 1.002050472972127e-06, 'max_depth': 20, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.29886407105305596}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,404] Trial 93 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 2.508984109306279e-06, 'max_depth': 20, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.7479625604792931}. Best is trial 14 with value: 0.8043864848844102.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,476] Trial 94 finished with value: 0.8073503260225252 and parameters: {'booster': 'gbtree', 'gamma': 2.915907777722595e-06, 'max_depth': 21, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.6304997307378953}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,549] Trial 95 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 2.7660881377158844e-06, 'max_depth': 30, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.7401417753686881}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,626] Trial 96 finished with value: 0.7788974510966212 and parameters: {'booster': 'gbtree', 'gamma': 2.000628471364469e-06, 'max_depth': 37, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.9754873125526504}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,697] Trial 97 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 1.1268690810366964e-06, 'max_depth': 25, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.160467238319487}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,762] Trial 98 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 0.8467851529433696, 'max_depth': 20, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.46227799547963505}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,825] Trial 99 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.05376895080587644, 'max_depth': 20, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.4278210441127326}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,897] Trial 100 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 0.3282359984957211, 'max_depth': 28, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.058671660795073084}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:20,965] Trial 101 finished with value: 0.8067575577949022 and parameters: {'booster': 'gbtree', 'gamma': 0.004534675226128668, 'max_depth': 22, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.6227219746393406}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,032] Trial 102 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 2.5283478207897646e-07, 'max_depth': 22, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.4202311987298535}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,109] Trial 103 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 0.01108384868010996, 'max_depth': 32, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.24800344354475387}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,179] Trial 104 finished with value: 0.7871962062833432 and parameters: {'booster': 'gbtree', 'gamma': 0.003717813826042626, 'max_depth': 23, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.7069793567655205}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,244] Trial 105 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 0.8528748189615365, 'max_depth': 22, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.103071030349571}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,291] Trial 106 finished with value: 0.7717842323651453 and parameters: {'booster': 'gblinear', 'gamma': 0.001313690580046553, 'max_depth': 27, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.16945178683614043}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,359] Trial 107 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 5.006412305444482e-07, 'max_depth': 20, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.5189069175120744}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,427] Trial 108 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 6.061822932750812e-07, 'max_depth': 19, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.5583446468668509}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,506] Trial 109 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.05441143526616266, 'max_depth': 30, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.271150243230334}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,568] Trial 110 finished with value: 0.7919383521043272 and parameters: {'booster': 'gbtree', 'gamma': 0.02490747206277281, 'max_depth': 16, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.9663936186983308}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,638] Trial 111 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 0.20951800078025662, 'max_depth': 24, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.38208354906756903}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,700] Trial 112 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 4.088986818486108e-06, 'max_depth': 20, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.5202126213681326}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,766] Trial 113 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 4.1773062981469835e-06, 'max_depth': 20, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.6420033749167692}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,837] Trial 114 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 8.73762993130622e-07, 'max_depth': 26, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.2037474351117744}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,898] Trial 115 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 2.6241182361993192e-06, 'max_depth': 15, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.132879228140445}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:21,999] Trial 116 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.4960610924956683e-06, 'max_depth': 78, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.4958739381169396}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,062] Trial 117 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 8.687458200866726e-06, 'max_depth': 18, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.08522984002524084}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,125] Trial 118 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 2.7131530448029784e-06, 'max_depth': 20, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.27715820083223625}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,189] Trial 119 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 4.3391333922534056e-07, 'max_depth': 24, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.7557703973899436}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,235] Trial 120 finished with value: 0.7753408417308832 and parameters: {'booster': 'gblinear', 'gamma': 4.24654555915526e-06, 'max_depth': 29, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.20452422049890093}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,299] Trial 121 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 1.0678749274801755e-06, 'max_depth': 21, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.3877894282905487}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,371] Trial 122 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 2.0088971578300962e-06, 'max_depth': 22, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.5101537202686143}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,436] Trial 123 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 6.888893308979037e-07, 'max_depth': 17, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.3212413550273845}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,496] Trial 124 finished with value: 0.7871962062833432 and parameters: {'booster': 'gbtree', 'gamma': 6.393795538885837e-07, 'max_depth': 17, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.9811756295411022}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,559] Trial 125 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 2.9011661194908487e-05, 'max_depth': 14, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.12850365719174428}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,626] Trial 126 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 3.177068796310207e-07, 'max_depth': 19, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.29437678604827205}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,698] Trial 127 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.00039719828634790397, 'max_depth': 25, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.6040791573502976}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,774] Trial 128 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 1.560021844185432e-06, 'max_depth': 34, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.20955384441885325}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,851] Trial 129 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.6524217090610439e-06, 'max_depth': 33, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 4.5025312445570685e-08}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:22,945] Trial 130 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 4.6174243032332905e-06, 'max_depth': 50, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.1905189903360757}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,035] Trial 131 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 1.11818303074547e-06, 'max_depth': 44, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.2750790360559984}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,100] Trial 132 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 3.4326769253320744e-06, 'max_depth': 17, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.4898469990914799}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,172] Trial 133 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 8.236166627949769e-07, 'max_depth': 26, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.08842233735410887}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,234] Trial 134 finished with value: 0.7860106698280972 and parameters: {'booster': 'gbtree', 'gamma': 1.0264100630928732e-05, 'max_depth': 15, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.0462772480967036}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,296] Trial 135 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 2.164706752840027e-06, 'max_depth': 12, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.3669638924772148}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,371] Trial 136 finished with value: 0.7990515708358032 and parameters: {'booster': 'dart', 'gamma': 4.919669059043864e-07, 'max_depth': 19, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.1526201954401545}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,447] Trial 137 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 0.0007526225316582886, 'max_depth': 34, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.707771046029597}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,523] Trial 138 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.00712421995797672, 'max_depth': 38, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.2217823004311337}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,581] Trial 139 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 6.64050883741828e-06, 'max_depth': 10, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 4.066107236649365e-05}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,653] Trial 140 finished with value: 0.7806757557794902 and parameters: {'booster': 'gbtree', 'gamma': 1.3123168339678068e-06, 'max_depth': 28, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.9999915610588644}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,743] Trial 141 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 1.029179842560319e-06, 'max_depth': 53, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.2874824074788523}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,812] Trial 142 finished with value: 0.8073503260225252 and parameters: {'booster': 'gbtree', 'gamma': 2.8310995820886253e-06, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.4818826045239756}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,882] Trial 143 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 0.0951287661121288, 'max_depth': 23, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.4435064266309134}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:23,953] Trial 144 finished with value: 0.8073503260225252 and parameters: {'booster': 'gbtree', 'gamma': 3.3652730326941564e-06, 'max_depth': 21, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.6303868884373032}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,022] Trial 145 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 2.741114114145663e-06, 'max_depth': 21, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.5668441748073836}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,091] Trial 146 finished with value: 0.7871962062833432 and parameters: {'booster': 'gbtree', 'gamma': 6.304614260958273e-06, 'max_depth': 25, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.6851115362251325}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,141] Trial 147 finished with value: 0.49318316538233553 and parameters: {'booster': 'gblinear', 'gamma': 3.3906289175044377e-06, 'max_depth': 23, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 1.238111981910121e-06}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,223] Trial 148 finished with value: 0.8008298755186722 and parameters: {'booster': 'dart', 'gamma': 4.532250173513767e-06, 'max_depth': 27, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.17714919003662327}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,287] Trial 149 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 1.5159257881807688e-05, 'max_depth': 20, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.3771363731233434}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,381] Trial 150 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 1.8516407534913063e-06, 'max_depth': 62, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.11866113066581538}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,450] Trial 151 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.808859005509824e-06, 'max_depth': 21, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.11945846014419996}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,550] Trial 152 finished with value: 0.7753408417308832 and parameters: {'booster': 'gbtree', 'gamma': 2.364906567394998e-06, 'max_depth': 68, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.7285837450890633}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,648] Trial 153 finished with value: 0.7836395969176052 and parameters: {'booster': 'gbtree', 'gamma': 0.0002384737519452139, 'max_depth': 66, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.5054414779784447}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,748] Trial 154 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 9.173713876891466e-06, 'max_depth': 71, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.228189367674607}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,820] Trial 155 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 1.373411211558975e-06, 'max_depth': 24, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.358120124525228}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,894] Trial 156 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 1.5231423154492237e-06, 'max_depth': 24, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.15138502871813758}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:24,969] Trial 157 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 4.817815050945512e-06, 'max_depth': 28, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.3032414654672144}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,047] Trial 158 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 3.3315216433053275e-06, 'max_depth': 31, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.06993679733127968}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,143] Trial 159 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 8.347341832655544e-07, 'max_depth': 61, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.4101078976321573}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,238] Trial 160 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.644811751168507e-06, 'max_depth': 59, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 4.60711046396542e-06}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,306] Trial 161 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 2.403833710658965e-06, 'max_depth': 18, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.7376756699896087}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,376] Trial 162 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 6.0728529975383585e-06, 'max_depth': 22, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.5388787186036192}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,462] Trial 163 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 3.0458805017505193e-06, 'max_depth': 42, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.23756877000706755}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,574] Trial 164 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 1.1450620867184383e-06, 'max_depth': 90, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.3460720129656094}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,643] Trial 165 finished with value: 0.7889745109662122 and parameters: {'booster': 'gbtree', 'gamma': 1.9709859737501465e-06, 'max_depth': 19, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.967544877309425}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,728] Trial 166 finished with value: 0.7919383521043272 and parameters: {'booster': 'dart', 'gamma': 0.02155084898218701, 'max_depth': 26, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.4740969077808363}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,794] Trial 167 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 7.733579326690702e-06, 'max_depth': 16, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.11060038813966097}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,867] Trial 168 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 7.726256136774022e-05, 'max_depth': 23, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.18632168786816367}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:25,944] Trial 169 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 2.5091844801009883e-05, 'max_depth': 24, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.18073172969270646}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,014] Trial 170 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 3.959353867991919e-05, 'max_depth': 47, 'n_estimators': 15, 'grow_policy': 'depthwise', 'learning_rate': 0.23989959557732463}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,085] Trial 171 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 3.996776285388102e-06, 'max_depth': 21, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.3308685563196139}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,155] Trial 172 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 0.00018961190060996577, 'max_depth': 19, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.6270116264607142}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,227] Trial 173 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 1.3513940337402087e-06, 'max_depth': 22, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.1435578531230529}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,302] Trial 174 finished with value: 0.8055720213396562 and parameters: {'booster': 'gbtree', 'gamma': 6.357648195276908e-05, 'max_depth': 25, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.43886010325295843}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,379] Trial 175 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.3606745254162594e-05, 'max_depth': 25, 'n_estimators': 77, 'grow_policy': 'lossguide', 'learning_rate': 0.0005917897175480726}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,461] Trial 176 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 7.964774231072895e-05, 'max_depth': 30, 'n_estimators': 74, 'grow_policy': 'lossguide', 'learning_rate': 0.39671741268742033}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,533] Trial 177 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 0.00013872008337028228, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.1990691462886275}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,590] Trial 178 finished with value: 0.7468879668049793 and parameters: {'booster': 'gblinear', 'gamma': 5.132330523467749e-07, 'max_depth': 28, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.08765077783362275}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,661] Trial 179 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 6.602711461067484e-05, 'max_depth': 25, 'n_estimators': 69, 'grow_policy': 'lossguide', 'learning_rate': 0.30627857155491345}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,754] Trial 180 finished with value: 0.7996443390634262 and parameters: {'booster': 'dart', 'gamma': 9.308237588805052e-05, 'max_depth': 35, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.4721575986989069}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,822] Trial 181 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 0.0033902350318955735, 'max_depth': 21, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.728389264209624}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,885] Trial 182 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 2.5093127419296862e-06, 'max_depth': 18, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.9739010351718804}. Best is trial 94 with value: 0.8073503260225252.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:26,957] Trial 183 finished with value: 0.8085358624777712 and parameters: {'booster': 'gbtree', 'gamma': 5.2996500268767484e-05, 'max_depth': 20, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.5583597658288443}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,026] Trial 184 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 2.7957847745780537e-05, 'max_depth': 23, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.24416730205190187}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,094] Trial 185 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 6.963416507897462e-05, 'max_depth': 15, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.5128744861269238}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,173] Trial 186 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 5.269144495092989e-05, 'max_depth': 26, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.3520470182482827}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,240] Trial 187 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 0.00011377662800438091, 'max_depth': 20, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.18375008218069103}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,330] Trial 188 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 0.0002557508594461703, 'max_depth': 58, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.5298676132519496}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,398] Trial 189 finished with value: 0.8061647895672792 and parameters: {'booster': 'gbtree', 'gamma': 0.7312606072088732, 'max_depth': 17, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.26691508138619596}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,461] Trial 190 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 0.3984830349410261, 'max_depth': 17, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.14501416869095538}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,530] Trial 191 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 0.2569768462075008, 'max_depth': 22, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.26434598902427275}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,599] Trial 192 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.6037781127000486, 'max_depth': 19, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.3954080893725863}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,661] Trial 193 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 0.8751989399144088, 'max_depth': 13, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.6074090563649525}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,734] Trial 194 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 0.5277830896115789, 'max_depth': 24, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.26425779333231203}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,805] Trial 195 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.729568558372792, 'max_depth': 23, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.24682210545772917}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:27,895] Trial 196 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.4371715845502313, 'max_depth': 26, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.00010088201818659812}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,005] Trial 197 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.5421638217194925, 'max_depth': 17, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.11380213226782017}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,091] Trial 198 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 0.15457594138224304, 'max_depth': 24, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.3251298193607595}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,291] Trial 199 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 4.0036804809409757e-05, 'max_depth': 63, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.1961933150481861}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,364] Trial 200 finished with value: 0.8032009484291642 and parameters: {'booster': 'dart', 'gamma': 0.0007559435323816997, 'max_depth': 28, 'n_estimators': 30, 'grow_policy': 'depthwise', 'learning_rate': 0.7027991955912322}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,434] Trial 201 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 8.366856985387402e-07, 'max_depth': 21, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.43560558559416224}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,504] Trial 202 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 4.440744551527023e-06, 'max_depth': 20, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.3036363299941997}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,578] Trial 203 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.8523524796777232, 'max_depth': 24, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.4742856227482683}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,645] Trial 204 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 1.8319738809637222e-06, 'max_depth': 18, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.15330593589140895}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,718] Trial 205 finished with value: 0.7883817427385892 and parameters: {'booster': 'gbtree', 'gamma': 1.2775616385314497e-06, 'max_depth': 22, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.6873684489570623}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,790] Trial 206 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 3.31720541779242e-06, 'max_depth': 20, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.25521001098281976}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,857] Trial 207 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 5.389066703449711e-06, 'max_depth': 15, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.9961207815616915}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:28,935] Trial 208 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.5630744635813136, 'max_depth': 26, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.3470112401530923}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,013] Trial 209 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 9.304356923719002e-06, 'max_depth': 21, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.5206965432985706}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,096] Trial 210 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.558283568339857e-05, 'max_depth': 23, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.5638068857436236}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,169] Trial 211 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 6.922214176563178e-06, 'max_depth': 21, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.4427145341307317}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,242] Trial 212 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 5.4685044877590375e-05, 'max_depth': 19, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.1897138091666599}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,309] Trial 213 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 9.489550623002822e-06, 'max_depth': 17, 'n_estimators': 68, 'grow_policy': 'lossguide', 'learning_rate': 0.3584291581863895}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,380] Trial 214 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 0.9642439860655, 'max_depth': 24, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.7087265010445332}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,452] Trial 215 finished with value: 0.8049792531120332 and parameters: {'booster': 'gbtree', 'gamma': 1.6806689337711847e-08, 'max_depth': 21, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.25914264687846966}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:29,510] Trial 216 finished with value: 0.7788974510966212 and parameters: {'booster': 'gblinear', 'gamma': 2.9422360746523302e-08, 'max_depth': 22, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.24068074322784982}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:30,066] Trial 217 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.9858290177772353e-05, 'max_depth': 25, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.11448290555573812}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:30,871] Trial 218 finished with value: 0.7688203912270303 and parameters: {'booster': 'gbtree', 'gamma': 1.8186772864993194e-06, 'max_depth': 52, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.005594627186348065}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:30,947] Trial 219 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 4.804024978674487e-08, 'max_depth': 21, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.29522778682135453}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,021] Trial 220 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 1.4711864066019392e-08, 'max_depth': 19, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.18103984955845112}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,101] Trial 221 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 1.1070407561071648e-08, 'max_depth': 22, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.5002467899906282}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,175] Trial 222 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 1.914466283895977e-08, 'max_depth': 19, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.44999924099374417}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,248] Trial 223 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 3.3244465534071663e-06, 'max_depth': 16, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.3375927981048876}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,325] Trial 224 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 2.421359004407382e-06, 'max_depth': 23, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.638682621079434}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,440] Trial 225 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 5.5434168984131634e-06, 'max_depth': 78, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.23423041940451944}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,531] Trial 226 finished with value: 0.8014226437462952 and parameters: {'booster': 'dart', 'gamma': 1.0491971746237502e-05, 'max_depth': 27, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.4411900412001366}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,606] Trial 227 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 2.3652230710027012e-08, 'max_depth': 20, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.7779726585359548}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,683] Trial 228 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 1.1683468717358554e-06, 'max_depth': 24, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.15298830809277048}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,759] Trial 229 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 0.29265847246569265, 'max_depth': 18, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.30531258865385064}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,836] Trial 230 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 8.534010297746455e-07, 'max_depth': 21, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.5158955981311178}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,908] Trial 231 finished with value: 0.7871962062833432 and parameters: {'booster': 'gbtree', 'gamma': 2.3954128080058922e-06, 'max_depth': 20, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.7593918030081823}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:31,988] Trial 232 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 1.8879469862510705e-06, 'max_depth': 22, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.5881458053338506}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,066] Trial 233 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 3.7723331496406107e-06, 'max_depth': 17, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.37418081698992106}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,147] Trial 234 finished with value: 0.7806757557794902 and parameters: {'booster': 'gbtree', 'gamma': 1.6142192060320017e-06, 'max_depth': 25, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.9669289823137279}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,226] Trial 235 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 3.1267332901666075e-06, 'max_depth': 20, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.23392742319907553}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,301] Trial 236 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 4.886187381061195e-06, 'max_depth': 23, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.5732595203660201}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,373] Trial 237 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 2.4758842340738287e-06, 'max_depth': 18, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.33777238439128526}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,437] Trial 238 finished with value: 0.7889745109662122 and parameters: {'booster': 'gbtree', 'gamma': 7.669973409037676e-06, 'max_depth': 14, 'n_estimators': 40, 'grow_policy': 'depthwise', 'learning_rate': 0.19543947023439912}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,511] Trial 239 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.00010055300209038854, 'max_depth': 21, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 3.177717724614267e-07}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,595] Trial 240 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 1.3639424839480944e-06, 'max_depth': 29, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.42350569588413667}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,667] Trial 241 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 7.825322001765308e-07, 'max_depth': 16, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.29870171975196014}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,738] Trial 242 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 5.399915065847045e-07, 'max_depth': 17, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.0001926737907843151}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,811] Trial 243 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 2.6633319294770643e-07, 'max_depth': 19, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.6846863728468118}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,883] Trial 244 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 1.0438245002313194e-06, 'max_depth': 19, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.7486267599382583}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:32,960] Trial 245 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 3.6079684812862524e-07, 'max_depth': 23, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.5819484747604705}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,038] Trial 246 finished with value: 0.7830468286899822 and parameters: {'booster': 'gbtree', 'gamma': 0.6381953236885707, 'max_depth': 21, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.9548839507871147}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,150] Trial 247 finished with value: 0.7901600474214582 and parameters: {'booster': 'dart', 'gamma': 2.3723373801870878e-07, 'max_depth': 55, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.4213866432778248}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,230] Trial 248 finished with value: 0.7877889745109662 and parameters: {'booster': 'gbtree', 'gamma': 3.64721229906928e-06, 'max_depth': 25, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.6008506676266698}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,307] Trial 249 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 0.00015406903532098995, 'max_depth': 20, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.24885570980208457}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,400] Trial 250 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 0.4025849907834095, 'max_depth': 45, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.42236285123648176}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,458] Trial 251 finished with value: 0.7812685240071132 and parameters: {'booster': 'gblinear', 'gamma': 1.4447820818483942e-06, 'max_depth': 23, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.693914837103329}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,540] Trial 252 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 2.6054607948224484e-06, 'max_depth': 27, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.12036792044460344}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,616] Trial 253 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 4.6774855960494015e-05, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.3216103337720052}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,692] Trial 254 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 0.0030628202117327697, 'max_depth': 22, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.18257089543175536}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,773] Trial 255 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 1.592735581331676e-07, 'max_depth': 25, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.4988174832409366}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,845] Trial 256 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 2.068689028249618e-06, 'max_depth': 18, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.25137617567472675}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:33,933] Trial 257 finished with value: 0.7848251333728512 and parameters: {'booster': 'gbtree', 'gamma': 6.801114530522274e-07, 'max_depth': 39, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.8079259990283733}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,011] Trial 258 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 0.0982425268719534, 'max_depth': 21, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.398359400946854}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,081] Trial 259 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 5.095927262887084e-06, 'max_depth': 15, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.9827930857135049}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,167] Trial 260 finished with value: 0.8020154119739182 and parameters: {'booster': 'dart', 'gamma': 3.631505662705842e-07, 'max_depth': 24, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.14836151047756502}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,235] Trial 261 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 6.421717391967729e-08, 'max_depth': 20, 'n_estimators': 5, 'grow_policy': 'depthwise', 'learning_rate': 0.5159434207325434}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,310] Trial 262 finished with value: 0.7741553052756373 and parameters: {'booster': 'gbtree', 'gamma': 1.0798319455280308e-08, 'max_depth': 22, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 0.002081597948691407}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,377] Trial 263 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.9764326779447439, 'max_depth': 7, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.28609547863132334}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,447] Trial 264 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 3.3218670381372484e-08, 'max_depth': 18, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.22520756751239832}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,524] Trial 265 finished with value: 0.7907528156490812 and parameters: {'booster': 'gbtree', 'gamma': 8.16280792519967e-05, 'max_depth': 27, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.6262363860403568}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,599] Trial 266 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.6966963980313417e-08, 'max_depth': 24, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.09917783750085299}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,665] Trial 267 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.1166347318470689e-05, 'max_depth': 13, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.36642229815442345}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,737] Trial 268 finished with value: 0.8055720213396562 and parameters: {'booster': 'gbtree', 'gamma': 1.175143435601682e-06, 'max_depth': 20, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.482914570539568}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,816] Trial 269 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 1.074332494772433e-06, 'max_depth': 31, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.21104597805792333}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,886] Trial 270 finished with value: 0.8055720213396562 and parameters: {'booster': 'gbtree', 'gamma': 6.712583674931634e-07, 'max_depth': 16, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.3479573491010629}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:34,951] Trial 271 finished with value: 0.7901600474214582 and parameters: {'booster': 'gbtree', 'gamma': 4.5361176896917844e-07, 'max_depth': 10, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.1501242995373174}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,029] Trial 272 finished with value: 0.8032009484291642 and parameters: {'booster': 'dart', 'gamma': 6.957877216573889e-07, 'max_depth': 15, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.3034359291778987}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,098] Trial 273 finished with value: 0.7889745109662122 and parameters: {'booster': 'gbtree', 'gamma': 9.584959705506767e-07, 'max_depth': 16, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.07072727013997565}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,167] Trial 274 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 2.5660324561235085e-07, 'max_depth': 18, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.4198039489674216}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,240] Trial 275 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 1.4518567853988996e-06, 'max_depth': 22, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.17219321112069377}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,312] Trial 276 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 6.121247100599767e-07, 'max_depth': 19, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.29332726952734717}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,377] Trial 277 finished with value: 0.8067575577949022 and parameters: {'booster': 'gbtree', 'gamma': 0.01753070305511448, 'max_depth': 12, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.5311049145737275}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,433] Trial 278 finished with value: 0.7800829875518672 and parameters: {'booster': 'gblinear', 'gamma': 0.0247971740491249, 'max_depth': 11, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.4582581667718992}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,500] Trial 279 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 3.246253465826889e-05, 'max_depth': 12, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.23408563412546607}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,569] Trial 280 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.016523358543101642, 'max_depth': 13, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.0007929025607132513}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,634] Trial 281 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 0.21116797659375008, 'max_depth': 8, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.32117973553828205}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,697] Trial 282 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 7.084298952543652e-06, 'max_depth': 15, 'n_estimators': 19, 'grow_policy': 'depthwise', 'learning_rate': 0.11463278667692284}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,776] Trial 283 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.007856010352925203, 'max_depth': 26, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.5738921140558286}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,884] Trial 284 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.03661819547341904, 'max_depth': 74, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.38684140884107937}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:35,960] Trial 285 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 0.0010983330768707413, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.20146239696339038}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,035] Trial 286 finished with value: 0.7943094250148192 and parameters: {'booster': 'dart', 'gamma': 0.0003077939457150383, 'max_depth': 9, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.5297395691599007}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,147] Trial 287 finished with value: 0.7901600474214582 and parameters: {'booster': 'gbtree', 'gamma': 1.7195962118166936e-06, 'max_depth': 82, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.27239115312662}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,218] Trial 288 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 2.1434434908771396e-05, 'max_depth': 17, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 1.3420871605756071e-05}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,303] Trial 289 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 0.10814388282364304, 'max_depth': 36, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.141015073804566}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,379] Trial 290 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 0.002294324361022256, 'max_depth': 25, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.37922048907867145}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,460] Trial 291 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.44212748909856453, 'max_depth': 33, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.698335705623936}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,539] Trial 292 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 1.0063422751887557e-06, 'max_depth': 29, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.21517896172888792}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,611] Trial 293 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.6250022696016061, 'max_depth': 21, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.43649531383934614}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,680] Trial 294 finished with value: 0.7812685240071132 and parameters: {'booster': 'gbtree', 'gamma': 0.00019865226844424126, 'max_depth': 14, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.9634703467366599}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,755] Trial 295 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 5.859398759197027e-05, 'max_depth': 23, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.28260021817185094}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,828] Trial 296 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 0.0001357802198770905, 'max_depth': 21, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.5666332699416837}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,887] Trial 297 finished with value: 0.7504445761707172 and parameters: {'booster': 'gblinear', 'gamma': 1.3808795516378744e-05, 'max_depth': 57, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.09852961834823311}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:36,965] Trial 298 finished with value: 0.8067575577949022 and parameters: {'booster': 'dart', 'gamma': 1.7267665087638302e-06, 'max_depth': 16, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.3400758926835595}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,046] Trial 299 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 1.97595636443502e-06, 'max_depth': 16, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 5.6804088740673513e-08}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,125] Trial 300 finished with value: 0.7913455838767042 and parameters: {'booster': 'dart', 'gamma': 1.652974122089287e-06, 'max_depth': 13, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.1652133940188758}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,211] Trial 301 finished with value: 0.7990515708358032 and parameters: {'booster': 'dart', 'gamma': 1.2160162664996245e-06, 'max_depth': 64, 'n_estimators': 92, 'grow_policy': 'depthwise', 'learning_rate': 0.29188831587400166}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,292] Trial 302 finished with value: 0.7966804979253111 and parameters: {'booster': 'dart', 'gamma': 4.042424651238134e-06, 'max_depth': 16, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.19118920332538036}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,374] Trial 303 finished with value: 0.8002371072910492 and parameters: {'booster': 'dart', 'gamma': 0.005214331896943019, 'max_depth': 18, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.3444226186079094}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,451] Trial 304 finished with value: 0.8020154119739182 and parameters: {'booster': 'dart', 'gamma': 2.3659158008952865e-06, 'max_depth': 11, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.39712546905545887}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,529] Trial 305 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 8.383883113359225e-07, 'max_depth': 26, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.7258885783619473}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,611] Trial 306 finished with value: 0.7960877296976882 and parameters: {'booster': 'dart', 'gamma': 2.8286415402707975e-06, 'max_depth': 19, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.23933487898498032}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,682] Trial 307 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.372017920706841e-06, 'max_depth': 17, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.1496567368948087}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,758] Trial 308 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 5.95493946346438e-07, 'max_depth': 24, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.5068196203314479}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,832] Trial 309 finished with value: 0.7889745109662122 and parameters: {'booster': 'gbtree', 'gamma': 0.07039329607473044, 'max_depth': 20, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.049623755863598976}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,902] Trial 310 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 8.07859243713441e-05, 'max_depth': 13, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.348929064182313}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:37,996] Trial 311 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 4.112045868657484e-06, 'max_depth': 28, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.2397110267477134}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,093] Trial 312 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 9.445325668381207e-07, 'max_depth': 22, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.0893382253142413}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,166] Trial 313 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 2.1580660400869e-08, 'max_depth': 15, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.747202319885779}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,244] Trial 314 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 2.0629870692983246e-06, 'max_depth': 24, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.5197419343357114}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,319] Trial 315 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 0.6495461804456303, 'max_depth': 20, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.1799321090503123}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,401] Trial 316 finished with value: 0.8002371072910492 and parameters: {'booster': 'dart', 'gamma': 1.3936932340751582e-06, 'max_depth': 18, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.3616970483997561}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,475] Trial 317 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 3.7974629617999246e-06, 'max_depth': 22, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.2671478412176982}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,554] Trial 318 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 3.009656491212854e-06, 'max_depth': 26, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.13011163819373098}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,628] Trial 319 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 0.3168275695422397, 'max_depth': 20, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.9659953533670601}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,687] Trial 320 finished with value: 0.7806757557794902 and parameters: {'booster': 'gblinear', 'gamma': 3.6940237974602916e-05, 'max_depth': 17, 'n_estimators': 29, 'grow_policy': 'depthwise', 'learning_rate': 0.4831316431636337}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,765] Trial 321 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.0007620817658646777, 'max_depth': 23, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.6412390990859596}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,835] Trial 322 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 5.926037218939341e-06, 'max_depth': 11, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.3401187519399631}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,900] Trial 323 finished with value: 0.7901600474214582 and parameters: {'booster': 'gbtree', 'gamma': 0.000429625683092487, 'max_depth': 6, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.21265751725420448}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:38,978] Trial 324 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 1.6427243724333415e-06, 'max_depth': 25, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.4278997392008632}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,059] Trial 325 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 1.0745739494206532e-06, 'max_depth': 30, 'n_estimators': 68, 'grow_policy': 'lossguide', 'learning_rate': 0.26798621100928505}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,131] Trial 326 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 0.041071175323884615, 'max_depth': 15, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.6805245509115018}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,230] Trial 327 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 2.3759735626311948e-06, 'max_depth': 41, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 6.27759359956929e-05}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,305] Trial 328 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 0.9512341539897079, 'max_depth': 21, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.12618269747020702}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,386] Trial 329 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 6.809836269402779e-07, 'max_depth': 19, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.4613054260730522}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,466] Trial 330 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.44441518610795705, 'max_depth': 23, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.19219156318452132}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,540] Trial 331 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 0.18732791677060814, 'max_depth': 17, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.32849155625296905}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,619] Trial 332 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 9.863599421895667e-05, 'max_depth': 21, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.0789876520893262}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,694] Trial 333 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 4.022036568933095e-07, 'max_depth': 14, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 3.5644426533160853e-06}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,775] Trial 334 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.001936566046368562, 'max_depth': 27, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.6946831430437012}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:39,914] Trial 335 finished with value: 0.7812685240071132 and parameters: {'booster': 'dart', 'gamma': 4.9998993804198784e-05, 'max_depth': 97, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.4784033918060857}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,000] Trial 336 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 0.014021728829393404, 'max_depth': 24, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.2625151482059598}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,069] Trial 337 finished with value: 0.7907528156490812 and parameters: {'booster': 'gbtree', 'gamma': 1.4020661182763452e-08, 'max_depth': 9, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.1734809003014121}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,145] Trial 338 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 1.7945930436465127e-06, 'max_depth': 19, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.9765656976336031}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,223] Trial 339 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 1.2018105635670017e-06, 'max_depth': 22, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.3496005662957346}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,293] Trial 340 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 5.0827994301286166e-06, 'max_depth': 18, 'n_estimators': 23, 'grow_policy': 'depthwise', 'learning_rate': 0.6052077381174598}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,355] Trial 341 finished with value: 0.7788974510966212 and parameters: {'booster': 'gblinear', 'gamma': 2.9598849860959136e-06, 'max_depth': 67, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.23062151933307337}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,442] Trial 342 finished with value: 0.7818612922347362 and parameters: {'booster': 'gbtree', 'gamma': 1.295525162717572e-07, 'max_depth': 25, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.025297379740996592}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,524] Trial 343 finished with value: 0.8049792531120332 and parameters: {'booster': 'gbtree', 'gamma': 4.219009612350239e-08, 'max_depth': 16, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.4735462701702115}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,601] Trial 344 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 4.5367861833780017e-08, 'max_depth': 15, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.5520493743999647}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,688] Trial 345 finished with value: 0.7978660343805573 and parameters: {'booster': 'dart', 'gamma': 3.3235023751764965e-08, 'max_depth': 13, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.3876340376362131}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,805] Trial 346 finished with value: 0.7700059276822763 and parameters: {'booster': 'gbtree', 'gamma': 2.213143412790243e-08, 'max_depth': 70, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.7355098550786356}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,883] Trial 347 finished with value: 0.8061647895672792 and parameters: {'booster': 'gbtree', 'gamma': 1.0586790487990747e-08, 'max_depth': 16, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.4911479249528329}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:40,963] Trial 348 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 1.049549223419541e-08, 'max_depth': 16, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.4654781222156826}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,039] Trial 349 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 1.551532415375307e-08, 'max_depth': 12, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.9971329282971335}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,129] Trial 350 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 2.9219483302962265e-08, 'max_depth': 17, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.6375672083487357}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,208] Trial 351 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 1.583447885042431e-08, 'max_depth': 19, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.37554697810336823}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,284] Trial 352 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 2.1364228931219663e-08, 'max_depth': 15, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.5487504108003215}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,360] Trial 353 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 1.4162453756722652e-08, 'max_depth': 14, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.3371460218281627}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,447] Trial 354 finished with value: 0.7966804979253111 and parameters: {'booster': 'dart', 'gamma': 4.955952385427706e-08, 'max_depth': 17, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.7238240158879418}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,520] Trial 355 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 2.293772640176807e-08, 'max_depth': 12, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4475023987978802}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,602] Trial 356 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 1.1134146343247746e-08, 'max_depth': 20, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.30214690661391935}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,675] Trial 357 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 5.846781071261075e-07, 'max_depth': 10, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.7281517160769988}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,753] Trial 358 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 8.141556640196453e-08, 'max_depth': 18, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.5048973650922487}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,823] Trial 359 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 0.6357912235492563, 'max_depth': 16, 'n_estimators': 14, 'grow_policy': 'depthwise', 'learning_rate': 0.25782952974326506}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,904] Trial 360 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 8.309768029456418e-07, 'max_depth': 21, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.9888238689079055}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:41,992] Trial 361 finished with value: 0.8073503260225252 and parameters: {'booster': 'gbtree', 'gamma': 5.778728296372504e-06, 'max_depth': 32, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.43389936800240897}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,082] Trial 362 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 3.2713664493053984e-08, 'max_depth': 30, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.3810074713290203}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,179] Trial 363 finished with value: 0.7913455838767042 and parameters: {'booster': 'dart', 'gamma': 3.5927491090040836e-06, 'max_depth': 27, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.572624786079606}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,268] Trial 364 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 2.468800156986598e-06, 'max_depth': 29, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.2672901070352404}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,358] Trial 365 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 1.6729377285659252e-08, 'max_depth': 31, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.4126801624362518}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,422] Trial 366 finished with value: 0.7800829875518672 and parameters: {'booster': 'gblinear', 'gamma': 1.2257734405453067e-06, 'max_depth': 32, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.6623547178362875}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,513] Trial 367 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 7.358158163530208e-06, 'max_depth': 34, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.20467827363480406}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,604] Trial 368 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 4.254446311150027e-07, 'max_depth': 33, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.3487009934390565}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,701] Trial 369 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 0.9961695710555555, 'max_depth': 37, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.5266483733533891}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,785] Trial 370 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 1.0798629184388419e-08, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.27871935439697004}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,881] Trial 371 finished with value: 0.7824540604623592 and parameters: {'booster': 'gbtree', 'gamma': 0.3287679775593793, 'max_depth': 35, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.013794642157821434}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:42,978] Trial 372 finished with value: 0.7984588026081803 and parameters: {'booster': 'dart', 'gamma': 4.736952329557869e-06, 'max_depth': 22, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.15117554797200944}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,063] Trial 373 finished with value: 0.7848251333728512 and parameters: {'booster': 'gbtree', 'gamma': 0.0049384206050351554, 'max_depth': 20, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.9909830069091087}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,152] Trial 374 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.1531735202379244, 'max_depth': 24, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.4438130707618738}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,231] Trial 375 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 7.994285796977206e-07, 'max_depth': 17, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.2305634896893568}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,314] Trial 376 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 1.94750293095138e-06, 'max_depth': 22, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.6275162087066909}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,399] Trial 377 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 1.416695929368871e-06, 'max_depth': 19, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.329357406163228}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,486] Trial 378 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 3.2184157403194202e-06, 'max_depth': 27, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 2.5091203457332034e-05}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,566] Trial 379 finished with value: 0.7836395969176052 and parameters: {'booster': 'gbtree', 'gamma': 0.45442553972093064, 'max_depth': 21, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.7757134525185285}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,642] Trial 380 finished with value: 0.8061647895672792 and parameters: {'booster': 'gbtree', 'gamma': 1.1252098376826463e-06, 'max_depth': 25, 'n_estimators': 26, 'grow_policy': 'depthwise', 'learning_rate': 0.5042708332034681}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,731] Trial 381 finished with value: 0.8002371072910492 and parameters: {'booster': 'dart', 'gamma': 6.025379792527661e-07, 'max_depth': 25, 'n_estimators': 26, 'grow_policy': 'depthwise', 'learning_rate': 0.5142109457006337}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,808] Trial 382 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 1.055752494201307e-06, 'max_depth': 28, 'n_estimators': 26, 'grow_policy': 'depthwise', 'learning_rate': 0.7341245938298548}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,880] Trial 383 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 9.312443125575972e-07, 'max_depth': 16, 'n_estimators': 29, 'grow_policy': 'depthwise', 'learning_rate': 0.45635899774878474}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:43,951] Trial 384 finished with value: 0.7569650266745702 and parameters: {'booster': 'gbtree', 'gamma': 1.5815797174187945e-06, 'max_depth': 14, 'n_estimators': 23, 'grow_policy': 'depthwise', 'learning_rate': 0.008088603314460062}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,025] Trial 385 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 4.842367084840628e-07, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'depthwise', 'learning_rate': 0.3447160691312429}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,098] Trial 386 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 0.0005738231906184545, 'max_depth': 18, 'n_estimators': 100, 'grow_policy': 'depthwise', 'learning_rate': 0.5655426928937446}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,178] Trial 387 finished with value: 0.7812685240071132 and parameters: {'booster': 'gbtree', 'gamma': 2.0704858833259887e-06, 'max_depth': 20, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.9806063706161603}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,245] Trial 388 finished with value: 0.7800829875518672 and parameters: {'booster': 'gblinear', 'gamma': 1.857571380568452e-07, 'max_depth': 26, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.30509134337564}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,317] Trial 389 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 1.080532723348019e-06, 'max_depth': 24, 'n_estimators': 27, 'grow_policy': 'depthwise', 'learning_rate': 0.4109673177163453}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,390] Trial 390 finished with value: 0.8049792531120332 and parameters: {'booster': 'gbtree', 'gamma': 2.953769710222104e-07, 'max_depth': 29, 'n_estimators': 10, 'grow_policy': 'depthwise', 'learning_rate': 0.6489270718608716}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,477] Trial 391 finished with value: 0.7901600474214582 and parameters: {'booster': 'dart', 'gamma': 5.96569297929851e-07, 'max_depth': 31, 'n_estimators': 13, 'grow_policy': 'depthwise', 'learning_rate': 0.7690092259861196}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,553] Trial 392 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 4.4744065214774083e-07, 'max_depth': 33, 'n_estimators': 11, 'grow_policy': 'depthwise', 'learning_rate': 0.5811256029911654}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,627] Trial 393 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 3.0748118936204435e-07, 'max_depth': 29, 'n_estimators': 8, 'grow_policy': 'depthwise', 'learning_rate': 0.7225100658563658}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,703] Trial 394 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 7.933106894594016e-07, 'max_depth': 28, 'n_estimators': 15, 'grow_policy': 'depthwise', 'learning_rate': 0.5149080153615643}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,781] Trial 395 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 3.4337127688309374e-07, 'max_depth': 30, 'n_estimators': 4, 'grow_policy': 'depthwise', 'learning_rate': 0.4357840695077267}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,861] Trial 396 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 1.3212360961089278e-06, 'max_depth': 32, 'n_estimators': 10, 'grow_policy': 'depthwise', 'learning_rate': 0.7208508995520051}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:44,936] Trial 397 finished with value: 0.7907528156490812 and parameters: {'booster': 'gbtree', 'gamma': 1.8946540791708643e-08, 'max_depth': 17, 'n_estimators': 9, 'grow_policy': 'depthwise', 'learning_rate': 0.982063924436377}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,011] Trial 398 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 4.004779610721016e-08, 'max_depth': 15, 'n_estimators': 18, 'grow_policy': 'depthwise', 'learning_rate': 0.3676485755632222}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,086] Trial 399 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 8.603708889970981e-07, 'max_depth': 21, 'n_estimators': 13, 'grow_policy': 'depthwise', 'learning_rate': 0.5466923340944952}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,173] Trial 400 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 2.001394693341454e-07, 'max_depth': 26, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.22956237621886266}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,281] Trial 401 finished with value: 0.7949021932424422 and parameters: {'booster': 'dart', 'gamma': 1.936026815497109e-06, 'max_depth': 35, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.34171037001016225}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,366] Trial 402 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 7.059995884910482e-08, 'max_depth': 19, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.6665907605145803}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,454] Trial 403 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 6.538568944999206e-07, 'max_depth': 22, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.4447762588263193}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,536] Trial 404 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 2.5444416507759498e-06, 'max_depth': 18, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.00028225753140613123}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,624] Trial 405 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 1.5371838875609778e-06, 'max_depth': 16, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.1785519237804433}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,711] Trial 406 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 9.299360101831719e-07, 'max_depth': 28, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.282079956686757}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,789] Trial 407 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 0.008009562432333327, 'max_depth': 13, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.5461292935586822}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,871] Trial 408 finished with value: 0.8014226437462952 and parameters: {'booster': 'dart', 'gamma': 2.308402662702877e-08, 'max_depth': 20, 'n_estimators': 22, 'grow_policy': 'depthwise', 'learning_rate': 0.726609360486445}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:45,962] Trial 409 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 4.900537834415684e-07, 'max_depth': 31, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.3634992789383248}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,051] Trial 410 finished with value: 0.7753408417308832 and parameters: {'booster': 'gbtree', 'gamma': 3.2955597035566233e-06, 'max_depth': 23, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.00430356519406718}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,118] Trial 411 finished with value: 0.7788974510966212 and parameters: {'booster': 'gblinear', 'gamma': 1.3532694754751746e-07, 'max_depth': 25, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.23067713330934955}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,201] Trial 412 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.4515864924763239e-08, 'max_depth': 19, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.4550270447168254}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,287] Trial 413 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 1.0310468668827093e-08, 'max_depth': 22, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.7835465613932261}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,369] Trial 414 finished with value: 0.7913455838767042 and parameters: {'booster': 'gbtree', 'gamma': 1.3316722138920722e-06, 'max_depth': 17, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.14514983883226207}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,476] Trial 415 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 3.5180934051095453e-07, 'max_depth': 49, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.3017333103640141}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,559] Trial 416 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 0.0015900252496904566, 'max_depth': 14, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.4999374963779614}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,651] Trial 417 finished with value: 0.49318316538233553 and parameters: {'booster': 'dart', 'gamma': 2.9303100649528127e-08, 'max_depth': 21, 'n_estimators': 21, 'grow_policy': 'depthwise', 'learning_rate': 4.498177849637551e-07}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,743] Trial 418 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.0010593918485122108, 'max_depth': 27, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.2004741298050394}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,834] Trial 419 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 2.094379706405579e-06, 'max_depth': 24, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.35414812018566394}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:46,921] Trial 420 finished with value: 0.7818612922347362 and parameters: {'booster': 'gbtree', 'gamma': 6.854419066728641e-07, 'max_depth': 20, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.9564485619269212}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,006] Trial 421 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 1.3746998582503714e-06, 'max_depth': 16, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.5751082194369398}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,103] Trial 422 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 0.053392806160772376, 'max_depth': 29, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.27360679199068605}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,234] Trial 423 finished with value: 0.7889745109662122 and parameters: {'booster': 'gbtree', 'gamma': 5.6181958703750534e-08, 'max_depth': 90, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.4176294265341864}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,318] Trial 424 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 2.856641236651751e-06, 'max_depth': 18, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.6261866117256877}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,394] Trial 425 finished with value: 0.7907528156490812 and parameters: {'booster': 'gbtree', 'gamma': 1.0265119456916402e-06, 'max_depth': 23, 'n_estimators': 7, 'grow_policy': 'depthwise', 'learning_rate': 0.11719730332409474}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,490] Trial 426 finished with value: 0.7990515708358032 and parameters: {'booster': 'dart', 'gamma': 4.1698910169063576e-06, 'max_depth': 25, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.2157807432664462}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,572] Trial 427 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.056078455375616e-07, 'max_depth': 21, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.9801367420793741}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,669] Trial 428 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 2.3223501251886357e-06, 'max_depth': 38, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.4062400438763099}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,764] Trial 429 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 0.019386961322497107, 'max_depth': 33, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.2882444356077219}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,850] Trial 430 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 0.033282991984191254, 'max_depth': 19, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.5928958183243531}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:47,932] Trial 431 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.6972790024754649e-06, 'max_depth': 12, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 1.112293810095777e-06}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,053] Trial 432 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 6.67507000942406e-07, 'max_depth': 16, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.16524183148535782}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,125] Trial 433 finished with value: 0.7812685240071132 and parameters: {'booster': 'gblinear', 'gamma': 1.9227946571097497e-08, 'max_depth': 22, 'n_estimators': 9, 'grow_policy': 'depthwise', 'learning_rate': 0.4282922758562523}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,194] Trial 434 finished with value: 0.7800829875518672 and parameters: {'booster': 'gbtree', 'gamma': 2.5367851546379526e-07, 'max_depth': 3, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.6908608789325574}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,288] Trial 435 finished with value: 0.7996443390634262 and parameters: {'booster': 'dart', 'gamma': 1.0725288289104864e-06, 'max_depth': 18, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.2619373758759428}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,375] Trial 436 finished with value: 0.7907528156490812 and parameters: {'booster': 'gbtree', 'gamma': 0.011309513180974127, 'max_depth': 26, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.35531491340178284}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,458] Trial 437 finished with value: 0.8085358624777712 and parameters: {'booster': 'gbtree', 'gamma': 5.190437300996084e-06, 'max_depth': 14, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.5438336394570304}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,532] Trial 438 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 6.4812821012888334e-06, 'max_depth': 10, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.7376042102703697}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,609] Trial 439 finished with value: 0.7830468286899822 and parameters: {'booster': 'gbtree', 'gamma': 5.604122561904268e-06, 'max_depth': 14, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.9994200669316375}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,689] Trial 440 finished with value: 0.7990515708358032 and parameters: {'booster': 'gbtree', 'gamma': 4.584591329847161e-06, 'max_depth': 16, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.5296947623638545}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,768] Trial 441 finished with value: 0.8055720213396562 and parameters: {'booster': 'gbtree', 'gamma': 1.0750184809874729e-05, 'max_depth': 15, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.5279665388801172}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,841] Trial 442 finished with value: 0.7931238885595732 and parameters: {'booster': 'gbtree', 'gamma': 1.0182843835273764e-05, 'max_depth': 13, 'n_estimators': 26, 'grow_policy': 'depthwise', 'learning_rate': 0.6912818103870043}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,920] Trial 443 finished with value: 0.8043864848844102 and parameters: {'booster': 'gbtree', 'gamma': 2.686683017550029e-05, 'max_depth': 11, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.5207995889489586}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:48,999] Trial 444 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 1.8049937938983597e-05, 'max_depth': 16, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.736644154236304}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,087] Trial 445 finished with value: 0.7830468286899822 and parameters: {'booster': 'dart', 'gamma': 8.485629151351205e-06, 'max_depth': 14, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.9988490390687074}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,165] Trial 446 finished with value: 0.8032009484291642 and parameters: {'booster': 'gbtree', 'gamma': 1.3032218135523906e-05, 'max_depth': 12, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.5107796423120513}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,245] Trial 447 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 8.593203760800222e-06, 'max_depth': 14, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.4104274125802868}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,324] Trial 448 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 5.138713280527903e-06, 'max_depth': 15, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.5715963635441385}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,408] Trial 449 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 3.3470291719377243e-06, 'max_depth': 18, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.3399377334326265}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,483] Trial 450 finished with value: 0.7895672791938352 and parameters: {'booster': 'gbtree', 'gamma': 5.671656676048456e-06, 'max_depth': 16, 'n_estimators': 63, 'grow_policy': 'depthwise', 'learning_rate': 0.7481758970102143}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,566] Trial 451 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 3.5860585333099677e-05, 'max_depth': 19, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.4541552591962109}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,645] Trial 452 finished with value: 0.7949021932424422 and parameters: {'booster': 'gbtree', 'gamma': 4.0644565443103865e-06, 'max_depth': 12, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.29631896907393096}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,728] Trial 453 finished with value: 0.7990515708358032 and parameters: {'booster': 'dart', 'gamma': 3.677942539231302e-08, 'max_depth': 7, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.5309045026547337}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,810] Trial 454 finished with value: 0.7972732661529343 and parameters: {'booster': 'gbtree', 'gamma': 0.0001781203576534267, 'max_depth': 17, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.3800359266223509}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,891] Trial 455 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.394639511772371e-08, 'max_depth': 14, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.0014406318765315196}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:49,981] Trial 456 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 6.948395226756814e-06, 'max_depth': 20, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.7477983975383208}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,052] Trial 457 finished with value: 0.7854179016004742 and parameters: {'booster': 'gblinear', 'gamma': 6.20436058803244e-05, 'max_depth': 17, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.9899536911349768}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,129] Trial 458 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 0.07307528958796064, 'max_depth': 9, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.2345943920501026}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,209] Trial 459 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 2.5364938866972026e-08, 'max_depth': 21, 'n_estimators': 6, 'grow_policy': 'depthwise', 'learning_rate': 0.5339913354381309}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,294] Trial 460 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 6.847299746620387e-06, 'max_depth': 18, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.37251085941660717}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,383] Trial 461 finished with value: 0.7984588026081803 and parameters: {'booster': 'gbtree', 'gamma': 2.8078135145956727e-06, 'max_depth': 20, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.2818702327720463}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,479] Trial 462 finished with value: 0.8002371072910492 and parameters: {'booster': 'dart', 'gamma': 3.729276258390969e-06, 'max_depth': 13, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.6608246665543509}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,574] Trial 463 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.00028991133903870717, 'max_depth': 15, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 1.4083403491601378e-08}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,667] Trial 464 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.53636200146438e-08, 'max_depth': 22, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 6.8347737382174965e-06}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,759] Trial 465 finished with value: 0.8002371072910492 and parameters: {'booster': 'gbtree', 'gamma': 1.025003123791777e-05, 'max_depth': 19, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.4332662160571718}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,850] Trial 466 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 4.449828693350722e-07, 'max_depth': 17, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 2.497524696145291e-08}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:50,938] Trial 467 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 4.538749580058763e-06, 'max_depth': 23, 'n_estimators': 11, 'grow_policy': 'depthwise', 'learning_rate': 0.19925003947570055}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,020] Trial 468 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 0.00011320879744870006, 'max_depth': 11, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.6043363300250454}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,112] Trial 469 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 2.1412767934611447e-05, 'max_depth': 20, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.3370955728258494}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,198] Trial 470 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 3.3699459948447344e-06, 'max_depth': 15, 'n_estimators': 75, 'grow_policy': 'lossguide', 'learning_rate': 0.7242679668579117}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,298] Trial 471 finished with value: 0.8014226437462952 and parameters: {'booster': 'dart', 'gamma': 2.2952111673005265e-06, 'max_depth': 18, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.45311732934237875}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,392] Trial 472 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 0.005047679310323701, 'max_depth': 22, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.26911194945787337}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,486] Trial 473 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 1.061171324549648e-08, 'max_depth': 24, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.1575933251897143}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,578] Trial 474 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 0.1473544203864734, 'max_depth': 20, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 1.403312557512363e-07}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,660] Trial 475 finished with value: 0.7854179016004742 and parameters: {'booster': 'gbtree', 'gamma': 2.8073138255480457e-08, 'max_depth': 15, 'n_estimators': 27, 'grow_policy': 'depthwise', 'learning_rate': 0.9766912796608979}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,745] Trial 476 finished with value: 0.8026081802015412 and parameters: {'booster': 'gbtree', 'gamma': 1.176511023855988e-05, 'max_depth': 18, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.4916413181066248}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,838] Trial 477 finished with value: 0.7925311203319502 and parameters: {'booster': 'gbtree', 'gamma': 2.0829653939560117e-06, 'max_depth': 26, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.2940192062701437}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,908] Trial 478 finished with value: 0.7812685240071132 and parameters: {'booster': 'gblinear', 'gamma': 5.683331166815997e-07, 'max_depth': 13, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.6807272977303646}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:51,998] Trial 479 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 0.0030199227492950166, 'max_depth': 21, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.3983441038561388}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,105] Trial 480 finished with value: 0.7990515708358032 and parameters: {'booster': 'dart', 'gamma': 2.7693343723682565e-07, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.19084199897554666}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,197] Trial 481 finished with value: 0.7883817427385892 and parameters: {'booster': 'gbtree', 'gamma': 5.159597077606466e-05, 'max_depth': 17, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.5495680289778776}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,287] Trial 482 finished with value: 0.7978660343805573 and parameters: {'booster': 'gbtree', 'gamma': 4.654179165574774e-06, 'max_depth': 19, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.3062533316353178}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,366] Trial 483 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 7.914061478724957e-07, 'max_depth': 16, 'n_estimators': 4, 'grow_policy': 'depthwise', 'learning_rate': 0.9928562131986319}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,463] Trial 484 finished with value: 0.8014226437462952 and parameters: {'booster': 'gbtree', 'gamma': 3.1716277126647057e-06, 'max_depth': 25, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.4236110801823287}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,556] Trial 485 finished with value: 0.8020154119739182 and parameters: {'booster': 'gbtree', 'gamma': 1.9335586266817257e-08, 'max_depth': 21, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.10558033902995714}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,645] Trial 486 finished with value: 0.7943094250148192 and parameters: {'booster': 'gbtree', 'gamma': 4.457183866623088e-08, 'max_depth': 11, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.23167637723932172}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,746] Trial 487 finished with value: 0.7901600474214582 and parameters: {'booster': 'gbtree', 'gamma': 1.0053499021867958e-08, 'max_depth': 28, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.6929012740052096}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,846] Trial 488 finished with value: 0.8043864848844102 and parameters: {'booster': 'dart', 'gamma': 6.069692956597787e-06, 'max_depth': 14, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.5343969103979688}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:52,935] Trial 489 finished with value: 0.8008298755186722 and parameters: {'booster': 'gbtree', 'gamma': 1.7437290978880456e-06, 'max_depth': 18, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.35489634593126}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,027] Trial 490 finished with value: 0.49318316538233553 and parameters: {'booster': 'gbtree', 'gamma': 1.0389667474865928e-06, 'max_depth': 23, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.0001593564086126842}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,106] Trial 491 finished with value: 0.7954949614700652 and parameters: {'booster': 'gbtree', 'gamma': 4.0916940234207744e-07, 'max_depth': 19, 'n_estimators': 5, 'grow_policy': 'depthwise', 'learning_rate': 0.23241964269537227}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,193] Trial 492 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 0.23801830729896514, 'max_depth': 21, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.1476853755625528}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,276] Trial 493 finished with value: 0.8037937166567872 and parameters: {'booster': 'gbtree', 'gamma': 2.4314966637994252e-06, 'max_depth': 15, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.7271841102866001}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,367] Trial 494 finished with value: 0.7996443390634262 and parameters: {'booster': 'gbtree', 'gamma': 1.4054111587422113e-06, 'max_depth': 24, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.4439066005176759}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,445] Trial 495 finished with value: 0.7966804979253111 and parameters: {'booster': 'gbtree', 'gamma': 3.0387042131036567e-06, 'max_depth': 8, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.3464126637754786}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,530] Trial 496 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 1.6517744984315073e-05, 'max_depth': 16, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.5731362086403269}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,628] Trial 497 finished with value: 0.8026081802015412 and parameters: {'booster': 'dart', 'gamma': 8.013875047640394e-06, 'max_depth': 20, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.2755175077818571}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,727] Trial 498 finished with value: 0.7960877296976882 and parameters: {'booster': 'gbtree', 'gamma': 1.8849036433731397e-07, 'max_depth': 27, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.7541973339552035}. Best is trial 183 with value: 0.8085358624777712.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:56:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:56:53,810] Trial 499 finished with value: 0.7937166567871962 and parameters: {'booster': 'gbtree', 'gamma': 8.0246646723492e-07, 'max_depth': 13, 'n_estimators': 7, 'grow_policy': 'depthwise', 'learning_rate': 0.4257717077601193}. Best is trial 183 with value: 0.8085358624777712.\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X, label=dft['Transported'])\n",
    "dvalid = xgb.DMatrix(x, label=dfv['Transported'])\n",
    "\n",
    "def objective(trial):\n",
    "    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth',1, 100),\n",
    "        'max_leaves': trial.suggest_int('max_depth',1, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',1, 100),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True)\n",
    "    }    \n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(dfv['Transported'], pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153dc80a",
   "metadata": {
    "papermill": {
     "duration": 0.056099,
     "end_time": "2024-03-08T03:56:53.930905",
     "exception": false,
     "start_time": "2024-03-08T03:56:53.874806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9c6f431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:54.043649Z",
     "iopub.status.busy": "2024-03-08T03:56:54.042859Z",
     "iopub.status.idle": "2024-03-08T03:56:54.049883Z",
     "shell.execute_reply": "2024-03-08T03:56:54.048878Z"
    },
    "papermill": {
     "duration": 0.06584,
     "end_time": "2024-03-08T03:56:54.052034",
     "exception": false,
     "start_time": "2024-03-08T03:56:53.986194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRFClassifier(\n",
    "    booster='gbtree',\n",
    "    device='cpu',\n",
    "    eval_metric=sklearn.metrics.mean_absolute_percentage_error,\n",
    "    grow_policy = 'lossguide',\n",
    "    gamma = 0.030185106394347308,\n",
    "    max_depth= 5,\n",
    "    n_estimators = 93,\n",
    "    learning_rate = 0.571705231643359\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c376aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:54.169285Z",
     "iopub.status.busy": "2024-03-08T03:56:54.168092Z",
     "iopub.status.idle": "2024-03-08T03:56:54.379792Z",
     "shell.execute_reply": "2024-03-08T03:56:54.378995Z"
    },
    "papermill": {
     "duration": 0.273443,
     "end_time": "2024-03-08T03:56:54.381962",
     "exception": false,
     "start_time": "2024-03-08T03:56:54.108519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.50937\tvalidation_0-mean_absolute_percentage_error:864003672768512.00000\tvalidation_1-logloss:0.52928\tvalidation_1-mean_absolute_percentage_error:890380677545984.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7ada8985e290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7ada8985e290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRFClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device='cpu',\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=<function mean_absolute_percentage_error at 0x7ada8985e290>,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy='lossguide', importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective='binary:logistic',\n",
       "                random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,eval_set=[(X,y),(x,Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da5f2417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:54.564643Z",
     "iopub.status.busy": "2024-03-08T03:56:54.563899Z",
     "iopub.status.idle": "2024-03-08T03:56:54.582079Z",
     "shell.execute_reply": "2024-03-08T03:56:54.581217Z"
    },
    "papermill": {
     "duration": 0.142558,
     "end_time": "2024-03-08T03:56:54.584166",
     "exception": false,
     "start_time": "2024-03-08T03:56:54.441608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7759336099585062"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueval = dfv['Transported']\n",
    "predval = model.predict(x)\n",
    "sklearn.metrics.accuracy_score(trueval, predval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcb87ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:54.701431Z",
     "iopub.status.busy": "2024-03-08T03:56:54.700363Z",
     "iopub.status.idle": "2024-03-08T03:56:55.141174Z",
     "shell.execute_reply": "2024-03-08T03:56:55.140381Z"
    },
    "papermill": {
     "duration": 0.501879,
     "end_time": "2024-03-08T03:56:55.143593",
     "exception": false,
     "start_time": "2024-03-08T03:56:54.641714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050819c",
   "metadata": {
    "papermill": {
     "duration": 0.056897,
     "end_time": "2024-03-08T03:56:55.258168",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.201271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e550bb7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:55.374870Z",
     "iopub.status.busy": "2024-03-08T03:56:55.374515Z",
     "iopub.status.idle": "2024-03-08T03:56:55.404101Z",
     "shell.execute_reply": "2024-03-08T03:56:55.403324Z"
    },
    "papermill": {
     "duration": 0.090929,
     "end_time": "2024-03-08T03:56:55.406323",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.315394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "labels = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f4d210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:55.522963Z",
     "iopub.status.busy": "2024-03-08T03:56:55.521925Z",
     "iopub.status.idle": "2024-03-08T03:56:55.548711Z",
     "shell.execute_reply": "2024-03-08T03:56:55.547671Z"
    },
    "papermill": {
     "duration": 0.087191,
     "end_time": "2024-03-08T03:56:55.550805",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.463614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4195.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>4179.000000</td>\n",
       "      <td>4176.000000</td>\n",
       "      <td>4197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.658146</td>\n",
       "      <td>219.266269</td>\n",
       "      <td>439.484296</td>\n",
       "      <td>177.295525</td>\n",
       "      <td>303.052443</td>\n",
       "      <td>310.710031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.179072</td>\n",
       "      <td>607.011289</td>\n",
       "      <td>1527.663045</td>\n",
       "      <td>560.821123</td>\n",
       "      <td>1117.186015</td>\n",
       "      <td>1246.994742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>11567.000000</td>\n",
       "      <td>25273.000000</td>\n",
       "      <td>8292.000000</td>\n",
       "      <td>19844.000000</td>\n",
       "      <td>22272.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  4186.000000   4195.000000   4171.000000   4179.000000   4176.000000   \n",
       "mean     28.658146    219.266269    439.484296    177.295525    303.052443   \n",
       "std      14.179072    607.011289   1527.663045    560.821123   1117.186015   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      26.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      37.000000     53.000000     78.000000     33.000000     50.000000   \n",
       "max      79.000000  11567.000000  25273.000000   8292.000000  19844.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   4197.000000  \n",
       "mean     310.710031  \n",
       "std     1246.994742  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       36.000000  \n",
       "max    22272.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4038eca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:55.667403Z",
     "iopub.status.busy": "2024-03-08T03:56:55.666985Z",
     "iopub.status.idle": "2024-03-08T03:56:55.698865Z",
     "shell.execute_reply": "2024-03-08T03:56:55.697881Z"
    },
    "papermill": {
     "duration": 0.092531,
     "end_time": "2024-03-08T03:56:55.700963",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.608432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/17557714.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/17557714.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "test_df[['CabinDeck', 'CabinNum', 'CabinSide']] = test_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "test_df = pd.concat([test_df,pd.get_dummies(test_df.Destination)], axis = 1)\n",
    "test_df = test_df.drop(['Name','Destination','Cabin','PassengerId'],axis=1)\n",
    "test_df.fillna(0,inplace=True)\n",
    "\n",
    "test_df['CryoSleep'] = test_df['CryoSleep'].astype(bool)\n",
    "test_df['VIP'] = test_df['VIP'].astype(bool)\n",
    "test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "test_df['CabinNum'] = test_df['CabinNum'].astype(int)\n",
    "test_df['CabinDeck'] = test_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15365d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:55.819934Z",
     "iopub.status.busy": "2024-03-08T03:56:55.819311Z",
     "iopub.status.idle": "2024-03-08T03:56:55.840834Z",
     "shell.execute_reply": "2024-03-08T03:56:55.839799Z"
    },
    "papermill": {
     "duration": 0.083793,
     "end_time": "2024-03-08T03:56:55.843124",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.759331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0              1       True  27.0  False          0.0        0.0   \n",
       "1              1      False  19.0  False          0.0        9.0   \n",
       "2              0       True  31.0  False          0.0        0.0   \n",
       "3              0      False  38.0  False          0.0     6652.0   \n",
       "4              1      False  20.0  False         10.0        0.0   \n",
       "...          ...        ...   ...    ...          ...        ...   \n",
       "4272           1       True  34.0  False          0.0        0.0   \n",
       "4273           1      False  42.0  False          0.0      847.0   \n",
       "4274           2       True   0.0  False          0.0        0.0   \n",
       "4275           0      False   0.0  False          0.0     2680.0   \n",
       "4276           1       True  43.0  False          0.0        0.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  CabinDeck  CabinNum  CabinSide  \\\n",
       "0              0.0     0.0     0.0          0         3          0   \n",
       "1              0.0  2823.0     0.0          0         4          0   \n",
       "2              0.0     0.0     0.0          0         0          0   \n",
       "3              0.0   181.0   585.0          0         1          0   \n",
       "4            635.0     0.0     0.0          0         5          0   \n",
       "...            ...     ...     ...        ...       ...        ...   \n",
       "4272           0.0     0.0     0.0          0      1496          0   \n",
       "4273          17.0    10.0   144.0          0         0          0   \n",
       "4274           0.0     0.0     0.0          1       296          1   \n",
       "4275           0.0     0.0   523.0          1       297          1   \n",
       "4276           0.0     0.0     0.0          0      1498          0   \n",
       "\n",
       "      55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0           False          False         True  \n",
       "1           False          False         True  \n",
       "2            True          False        False  \n",
       "3           False          False         True  \n",
       "4           False          False         True  \n",
       "...           ...            ...          ...  \n",
       "4272        False          False         True  \n",
       "4273        False          False         True  \n",
       "4274         True          False        False  \n",
       "4275        False          False        False  \n",
       "4276        False           True        False  \n",
       "\n",
       "[4277 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "905ee9c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:55.961688Z",
     "iopub.status.busy": "2024-03-08T03:56:55.961054Z",
     "iopub.status.idle": "2024-03-08T03:56:55.987149Z",
     "shell.execute_reply": "2024-03-08T03:56:55.986192Z"
    },
    "papermill": {
     "duration": 0.087948,
     "end_time": "2024-03-08T03:56:55.989449",
     "exception": false,
     "start_time": "2024-03-08T03:56:55.901501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['Transported'] = model.predict(test_df)\n",
    "test_df['PassengerId'] = labels\n",
    "dfexport = test_df[['PassengerId','Transported']]\n",
    "dfexport.to_csv('predictionoutput1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79f5cc80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:56.108881Z",
     "iopub.status.busy": "2024-03-08T03:56:56.108216Z",
     "iopub.status.idle": "2024-03-08T03:56:56.118704Z",
     "shell.execute_reply": "2024-03-08T03:56:56.117651Z"
    },
    "papermill": {
     "duration": 0.073093,
     "end_time": "2024-03-08T03:56:56.120697",
     "exception": false,
     "start_time": "2024-03-08T03:56:56.047604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01            1\n",
       "1        0018_01            0\n",
       "2        0019_01            1\n",
       "3        0021_01            1\n",
       "4        0023_01            0\n",
       "...          ...          ...\n",
       "4272     9266_02            1\n",
       "4273     9269_01            0\n",
       "4274     9271_01            1\n",
       "4275     9273_01            1\n",
       "4276     9277_01            1\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7226811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:56:56.239826Z",
     "iopub.status.busy": "2024-03-08T03:56:56.239443Z",
     "iopub.status.idle": "2024-03-08T03:56:56.243518Z",
     "shell.execute_reply": "2024-03-08T03:56:56.242401Z"
    },
    "papermill": {
     "duration": 0.06543,
     "end_time": "2024-03-08T03:56:56.245580",
     "exception": false,
     "start_time": "2024-03-08T03:56:56.180150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The fillna method is trash"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.929765,
   "end_time": "2024-03-08T03:56:57.027306",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T03:56:08.097541",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
