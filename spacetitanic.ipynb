{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53477aff",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:12.223824Z",
     "iopub.status.busy": "2024-03-08T03:51:12.223290Z",
     "iopub.status.idle": "2024-03-08T03:51:13.155929Z",
     "shell.execute_reply": "2024-03-08T03:51:13.154692Z"
    },
    "papermill": {
     "duration": 0.948476,
     "end_time": "2024-03-08T03:51:13.159148",
     "exception": false,
     "start_time": "2024-03-08T03:51:12.210672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ca9aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:13.178879Z",
     "iopub.status.busy": "2024-03-08T03:51:13.178329Z",
     "iopub.status.idle": "2024-03-08T03:51:16.167019Z",
     "shell.execute_reply": "2024-03-08T03:51:16.166138Z"
    },
    "papermill": {
     "duration": 3.001807,
     "end_time": "2024-03-08T03:51:16.169839",
     "exception": false,
     "start_time": "2024-03-08T03:51:13.168032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b7623",
   "metadata": {
    "papermill": {
     "duration": 0.008173,
     "end_time": "2024-03-08T03:51:16.186681",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.178508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995813b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.206897Z",
     "iopub.status.busy": "2024-03-08T03:51:16.206022Z",
     "iopub.status.idle": "2024-03-08T03:51:16.266031Z",
     "shell.execute_reply": "2024-03-08T03:51:16.265120Z"
    },
    "papermill": {
     "duration": 0.073607,
     "end_time": "2024-03-08T03:51:16.268836",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.195229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adcd4639",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.289528Z",
     "iopub.status.busy": "2024-03-08T03:51:16.288729Z",
     "iopub.status.idle": "2024-03-08T03:51:16.293688Z",
     "shell.execute_reply": "2024-03-08T03:51:16.292889Z"
    },
    "papermill": {
     "duration": 0.018605,
     "end_time": "2024-03-08T03:51:16.296137",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.277532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec524c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.315882Z",
     "iopub.status.busy": "2024-03-08T03:51:16.315012Z",
     "iopub.status.idle": "2024-03-08T03:51:16.388331Z",
     "shell.execute_reply": "2024-03-08T03:51:16.387195Z"
    },
    "papermill": {
     "duration": 0.086063,
     "end_time": "2024-03-08T03:51:16.390748",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.304685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2362847667.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/2362847667.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_raw['Transported']\n",
    "train_df[['CabinDeck', 'CabinNum', 'CabinSide']] = train_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "train_df = pd.concat([train_df,pd.get_dummies(train_df.Destination)], axis = 1)\n",
    "train_df = train_df.drop(['Name','Destination','Cabin'],axis=1)\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "train_df['CryoSleep'] = train_df['CryoSleep'].astype(bool)\n",
    "train_df['VIP'] = train_df['VIP'].astype(bool)\n",
    "train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "train_df['CabinNum'] = train_df['CabinNum'].astype(int)\n",
    "train_df['CabinDeck'] = train_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38c5c1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.410118Z",
     "iopub.status.busy": "2024-03-08T03:51:16.409663Z",
     "iopub.status.idle": "2024-03-08T03:51:16.413665Z",
     "shell.execute_reply": "2024-03-08T03:51:16.412794Z"
    },
    "papermill": {
     "duration": 0.016344,
     "end_time": "2024-03-08T03:51:16.415688",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.399344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[train_df['HomePlanet'].isnull()]\n",
    "#df1 = train_df[train_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b0a1b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.435534Z",
     "iopub.status.busy": "2024-03-08T03:51:16.434292Z",
     "iopub.status.idle": "2024-03-08T03:51:16.473441Z",
     "shell.execute_reply": "2024-03-08T03:51:16.472247Z"
    },
    "papermill": {
     "duration": 0.052167,
     "end_time": "2024-03-08T03:51:16.476504",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.424337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6913 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0        0001_01           0      False  39.0  False          0.0        0.0   \n",
       "1        0002_01           1      False  24.0  False        109.0        9.0   \n",
       "2        0003_01           0      False  58.0   True         43.0     3576.0   \n",
       "3        0003_02           0      False  33.0  False          0.0     1283.0   \n",
       "4        0004_01           1      False  16.0  False        303.0       70.0   \n",
       "...          ...         ...        ...   ...    ...          ...        ...   \n",
       "8688     9276_01           0      False  41.0   True          0.0     6819.0   \n",
       "8689     9278_01           1       True  18.0  False          0.0        0.0   \n",
       "8690     9279_01           1      False  26.0  False          0.0        0.0   \n",
       "8691     9280_01           0      False  32.0  False          0.0     1049.0   \n",
       "8692     9280_02           0      False  44.0  False        126.0     4688.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Transported  CabinDeck  CabinNum  \\\n",
       "0              0.0     0.0     0.0        False          1         0   \n",
       "1             25.0   549.0    44.0         True          0         0   \n",
       "2              0.0  6715.0    49.0        False          0         0   \n",
       "3            371.0  3329.0   193.0        False          0         0   \n",
       "4            151.0   565.0     2.0         True          0         1   \n",
       "...            ...     ...     ...          ...        ...       ...   \n",
       "8688           0.0  1643.0    74.0        False          1        98   \n",
       "8689           0.0     0.0     0.0        False          0      1499   \n",
       "8690        1872.0     1.0     0.0         True          0      1500   \n",
       "8691           0.0   353.0  3235.0        False          0       608   \n",
       "8692           0.0     0.0    12.0         True          0       608   \n",
       "\n",
       "      CabinSide  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0             1        False          False         True  \n",
       "1             0        False          False         True  \n",
       "2             0        False          False         True  \n",
       "3             0        False          False         True  \n",
       "4             0        False          False         True  \n",
       "...         ...          ...            ...          ...  \n",
       "8688          1         True          False        False  \n",
       "8689          0        False           True        False  \n",
       "8690          0        False          False         True  \n",
       "8691          0         True          False        False  \n",
       "8692          0        False          False         True  \n",
       "\n",
       "[6913 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1b292",
   "metadata": {
    "papermill": {
     "duration": 0.008958,
     "end_time": "2024-03-08T03:51:16.494667",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.485709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8651dd1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.515647Z",
     "iopub.status.busy": "2024-03-08T03:51:16.514973Z",
     "iopub.status.idle": "2024-03-08T03:51:16.520693Z",
     "shell.execute_reply": "2024-03-08T03:51:16.519797Z"
    },
    "papermill": {
     "duration": 0.019004,
     "end_time": "2024-03-08T03:51:16.523084",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.504080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.25):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e581b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.543853Z",
     "iopub.status.busy": "2024-03-08T03:51:16.543170Z",
     "iopub.status.idle": "2024-03-08T03:51:16.552012Z",
     "shell.execute_reply": "2024-03-08T03:51:16.550699Z"
    },
    "papermill": {
     "duration": 0.022171,
     "end_time": "2024-03-08T03:51:16.554434",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.532263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5156 examples in training, 1757 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "dft, dfv = split_dataset(train_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(dft), len(dfv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91def1cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.576030Z",
     "iopub.status.busy": "2024-03-08T03:51:16.575616Z",
     "iopub.status.idle": "2024-03-08T03:51:16.583865Z",
     "shell.execute_reply": "2024-03-08T03:51:16.582581Z"
    },
    "papermill": {
     "duration": 0.021657,
     "end_time": "2024-03-08T03:51:16.586337",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.564680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y= dft['Transported']\n",
    "Y=dfv['Transported']\n",
    "x = dfv.drop(['Transported','PassengerId'],axis=1)\n",
    "X=dft.drop(['Transported','PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07878306",
   "metadata": {
    "papermill": {
     "duration": 0.00903,
     "end_time": "2024-03-08T03:51:16.604777",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.595747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optuna HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045ab666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:51:16.626915Z",
     "iopub.status.busy": "2024-03-08T03:51:16.626500Z",
     "iopub.status.idle": "2024-03-08T03:52:09.474069Z",
     "shell.execute_reply": "2024-03-08T03:52:09.473111Z"
    },
    "papermill": {
     "duration": 52.861671,
     "end_time": "2024-03-08T03:52:09.477104",
     "exception": false,
     "start_time": "2024-03-08T03:51:16.615433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 03:51:16,677] A new study created in memory with name: no-name-1b10d182-f713-4a94-a480-39fd6a714863\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,721] Trial 0 finished with value: 0.5082527034718269 and parameters: {'booster': 'gblinear', 'gamma': 0.0003965076599134902, 'max_depth': 29, 'n_estimators': 52, 'grow_policy': 'depthwise', 'learning_rate': 1.9561626147921054e-05}. Best is trial 0 with value: 0.5082527034718269.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,828] Trial 1 finished with value: 0.7911212293682414 and parameters: {'booster': 'dart', 'gamma': 0.020715304487916572, 'max_depth': 91, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.9572455378016091}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,895] Trial 2 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 7.846697486262443e-05, 'max_depth': 72, 'n_estimators': 70, 'grow_policy': 'lossguide', 'learning_rate': 8.95347982626907e-05}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,931] Trial 3 finished with value: 0.7785998861696073 and parameters: {'booster': 'dart', 'gamma': 0.13937617214653764, 'max_depth': 25, 'n_estimators': 32, 'grow_policy': 'depthwise', 'learning_rate': 0.007305191052084571}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,971] Trial 4 finished with value: 0.7848605577689243 and parameters: {'booster': 'gbtree', 'gamma': 1.3022197352264246e-08, 'max_depth': 71, 'n_estimators': 62, 'grow_policy': 'depthwise', 'learning_rate': 0.014921354394775866}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:16,986] Trial 5 finished with value: 0.5116676152532726 and parameters: {'booster': 'gblinear', 'gamma': 7.87160714957906e-08, 'max_depth': 86, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 3.363858050718325e-05}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,001] Trial 6 finished with value: 0.5082527034718269 and parameters: {'booster': 'gblinear', 'gamma': 4.792800847910691e-05, 'max_depth': 79, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 2.6860694869950588e-08}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,018] Trial 7 finished with value: 0.5082527034718269 and parameters: {'booster': 'gblinear', 'gamma': 0.0020159231672831537, 'max_depth': 31, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 1.538351188389047e-05}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,034] Trial 8 finished with value: 0.7455890722822994 and parameters: {'booster': 'gblinear', 'gamma': 7.571902304295517e-07, 'max_depth': 59, 'n_estimators': 47, 'grow_policy': 'depthwise', 'learning_rate': 0.0029273427519003873}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,067] Trial 9 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 0.0163907156626173, 'max_depth': 67, 'n_estimators': 66, 'grow_policy': 'depthwise', 'learning_rate': 2.4688605873191638e-06}. Best is trial 1 with value: 0.7911212293682414.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,185] Trial 10 finished with value: 0.7933978372225384 and parameters: {'booster': 'dart', 'gamma': 0.8629031958502023, 'max_depth': 100, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.748487899359399}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,313] Trial 11 finished with value: 0.7797381900967558 and parameters: {'booster': 'dart', 'gamma': 0.5124130744905299, 'max_depth': 99, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.835624049718294}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,439] Trial 12 finished with value: 0.7859988616960728 and parameters: {'booster': 'dart', 'gamma': 0.037047238812648604, 'max_depth': 97, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.46337607219097116}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,494] Trial 13 finished with value: 0.5082527034718269 and parameters: {'booster': 'dart', 'gamma': 0.5673779812668029, 'max_depth': 1, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.09520198812494444}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,621] Trial 14 finished with value: 0.7894137734775185 and parameters: {'booster': 'dart', 'gamma': 0.007229481192487265, 'max_depth': 89, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.0009824020116991248}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,721] Trial 15 finished with value: 0.7933978372225384 and parameters: {'booster': 'dart', 'gamma': 0.0013162806622977312, 'max_depth': 52, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.04128744095253615}. Best is trial 10 with value: 0.7933978372225384.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,816] Trial 16 finished with value: 0.8025042686397268 and parameters: {'booster': 'dart', 'gamma': 3.0971708343951007e-06, 'max_depth': 45, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.07850245975238632}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,913] Trial 17 finished with value: 0.790552077404667 and parameters: {'booster': 'dart', 'gamma': 2.6242410172380915e-06, 'max_depth': 42, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.0004366140299392835}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:17,990] Trial 18 finished with value: 0.8007968127490039 and parameters: {'booster': 'dart', 'gamma': 6.7268947515086205e-06, 'max_depth': 15, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.13200000708227566}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,054] Trial 19 finished with value: 0.7785998861696073 and parameters: {'booster': 'dart', 'gamma': 5.740017277787216e-06, 'max_depth': 5, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.08043727146611697}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,115] Trial 20 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 1.4253905147405228e-05, 'max_depth': 10, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 1.9301720607060122e-07}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,188] Trial 21 finished with value: 0.8019351166761526 and parameters: {'booster': 'dart', 'gamma': 5.562563268857059e-07, 'max_depth': 15, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.1226249598659915}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,268] Trial 22 finished with value: 0.794536141149687 and parameters: {'booster': 'dart', 'gamma': 2.1708671659261394e-07, 'max_depth': 16, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.0585310605687941}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,363] Trial 23 finished with value: 0.7951052931132613 and parameters: {'booster': 'dart', 'gamma': 9.889682949112803e-07, 'max_depth': 39, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.0020343724359553526}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,444] Trial 24 finished with value: 0.7859988616960728 and parameters: {'booster': 'dart', 'gamma': 1.0485423322607715e-07, 'max_depth': 19, 'n_estimators': 75, 'grow_policy': 'lossguide', 'learning_rate': 0.010772928485878623}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,524] Trial 25 finished with value: 0.8007968127490039 and parameters: {'booster': 'dart', 'gamma': 1.4814043946154013e-05, 'max_depth': 14, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.1400544952312069}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,649] Trial 26 finished with value: 0.774046670461013 and parameters: {'booster': 'dart', 'gamma': 1.7705627822179618e-08, 'max_depth': 41, 'n_estimators': 85, 'grow_policy': 'depthwise', 'learning_rate': 0.0003453842869815624}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,811] Trial 27 finished with value: 0.7933978372225384 and parameters: {'booster': 'dart', 'gamma': 5.882909363072379e-07, 'max_depth': 48, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 0.01907546827922931}. Best is trial 16 with value: 0.8025042686397268.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,892] Trial 28 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 3.981747430070812e-06, 'max_depth': 23, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.21153758416681473}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:18,957] Trial 29 finished with value: 0.778030734206033 and parameters: {'booster': 'gbtree', 'gamma': 0.00023029236989407844, 'max_depth': 31, 'n_estimators': 92, 'grow_policy': 'depthwise', 'learning_rate': 0.004750791615405252}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,032] Trial 30 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 2.1510956407543624e-06, 'max_depth': 24, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.2680788879874519}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,116] Trial 31 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 2.180123477074488e-06, 'max_depth': 22, 'n_estimators': 99, 'grow_policy': 'lossguide', 'learning_rate': 0.2710412208886727}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,230] Trial 32 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 2.0072861775968338e-06, 'max_depth': 24, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.28661591546906595}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,305] Trial 33 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 3.4692714504436315e-05, 'max_depth': 24, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.2870781664671869}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,386] Trial 34 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 3.431138781755437e-05, 'max_depth': 33, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.34277907228631554}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,468] Trial 35 finished with value: 0.796812749003984 and parameters: {'booster': 'gbtree', 'gamma': 0.00015358198945387177, 'max_depth': 34, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.02266365849261702}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,536] Trial 36 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 0.0006115583483343491, 'max_depth': 35, 'n_estimators': 69, 'grow_policy': 'depthwise', 'learning_rate': 0.9837257840745703}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,632] Trial 37 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 2.7624257660098168e-05, 'max_depth': 26, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.2848817453827794}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,732] Trial 38 finished with value: 0.7763232783153102 and parameters: {'booster': 'gbtree', 'gamma': 9.456098310419973e-05, 'max_depth': 9, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.02954728590594046}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,807] Trial 39 finished with value: 0.7871371656232214 and parameters: {'booster': 'gbtree', 'gamma': 2.452299808066796e-07, 'max_depth': 20, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.009027822914809502}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,881] Trial 40 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 7.717530004552918e-06, 'max_depth': 52, 'n_estimators': 41, 'grow_policy': 'depthwise', 'learning_rate': 4.871638943228116e-06}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:19,959] Trial 41 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 3.590725551568249e-05, 'max_depth': 25, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.31803488929955076}. Best is trial 28 with value: 0.813318155947638.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,040] Trial 42 finished with value: 0.8173022196926579 and parameters: {'booster': 'gbtree', 'gamma': 1.796648930642123e-05, 'max_depth': 28, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.3505484778295789}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,122] Trial 43 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.4060321295828827e-06, 'max_depth': 37, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.45099697726634813}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,202] Trial 44 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 1.8859862086078447e-05, 'max_depth': 36, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.9341592410371017}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,256] Trial 45 finished with value: 0.7558338076266363 and parameters: {'booster': 'gblinear', 'gamma': 7.464553772290421e-05, 'max_depth': 31, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.046244940938478474}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,349] Trial 46 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 3.452861294989787e-08, 'max_depth': 58, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.16044764401473727}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,424] Trial 47 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.1641820360860662e-06, 'max_depth': 29, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.5888374259699729}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,491] Trial 48 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 2.0112508450211897e-07, 'max_depth': 20, 'n_estimators': 66, 'grow_policy': 'depthwise', 'learning_rate': 0.8868268439523765}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,549] Trial 49 finished with value: 0.5082527034718269 and parameters: {'booster': 'gblinear', 'gamma': 1.395460575610156e-06, 'max_depth': 29, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 1.7441543358294359e-07}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,642] Trial 50 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 3.426584400360069e-07, 'max_depth': 37, 'n_estimators': 75, 'grow_policy': 'lossguide', 'learning_rate': 0.44493863074652656}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,724] Trial 51 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 5.332686530295689e-06, 'max_depth': 28, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.4761225136128957}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,820] Trial 52 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 4.385208732801386e-06, 'max_depth': 43, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.15996770321191467}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,905] Trial 53 finished with value: 0.7962435970404098 and parameters: {'booster': 'gbtree', 'gamma': 1.2045181831527188e-05, 'max_depth': 32, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.03007837699765165}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:20,981] Trial 54 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 9.0511468540737e-08, 'max_depth': 20, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 5.198188150166973e-05}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,076] Trial 55 finished with value: 0.7951052931132613 and parameters: {'booster': 'gbtree', 'gamma': 1.0856202766795636e-06, 'max_depth': 46, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.05448149479986999}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,142] Trial 56 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 6.371372564672036e-05, 'max_depth': 11, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.1631313614777376}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,201] Trial 57 finished with value: 0.7979510529311327 and parameters: {'booster': 'gblinear', 'gamma': 0.0005182034620599961, 'max_depth': 57, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.5962640432639033}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,292] Trial 58 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 9.331208077167366e-06, 'max_depth': 39, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.08915982842440243}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,352] Trial 59 finished with value: 0.7700626067159931 and parameters: {'booster': 'gbtree', 'gamma': 3.7510752778104877e-06, 'max_depth': 5, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.01453580931054138}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,431] Trial 60 finished with value: 0.8144564598747865 and parameters: {'booster': 'gbtree', 'gamma': 4.6131816310977797e-07, 'max_depth': 28, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.21442811465569733}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,515] Trial 61 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 3.9708837644551916e-07, 'max_depth': 28, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.4144759698060524}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,591] Trial 62 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 1.0859412004857734e-06, 'max_depth': 22, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.17597443147464664}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,665] Trial 63 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 8.633341833434754e-07, 'max_depth': 18, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.18685454007329347}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,744] Trial 64 finished with value: 0.7951052931132613 and parameters: {'booster': 'gbtree', 'gamma': 1.593693539697257e-06, 'max_depth': 21, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.08471045769991215}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,816] Trial 65 finished with value: 0.7774615822424588 and parameters: {'booster': 'gbtree', 'gamma': 1.239171981916056e-07, 'max_depth': 14, 'n_estimators': 77, 'grow_policy': 'lossguide', 'learning_rate': 0.004787735616479598}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,888] Trial 66 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 2.7452967491933875e-06, 'max_depth': 27, 'n_estimators': 93, 'grow_policy': 'depthwise', 'learning_rate': 1.0450800008774942e-08}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:21,970] Trial 67 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 5.411798713819358e-07, 'max_depth': 23, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.07316992836974157}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,032] Trial 68 finished with value: 0.6533864541832669 and parameters: {'booster': 'gblinear', 'gamma': 3.270543762639833e-08, 'max_depth': 12, 'n_estimators': 68, 'grow_policy': 'lossguide', 'learning_rate': 0.00018354716273591854}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,115] Trial 69 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.3315260774586763e-06, 'max_depth': 30, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 0.5584655014618781}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,208] Trial 70 finished with value: 0.7956744450768355 and parameters: {'booster': 'gbtree', 'gamma': 3.40937796611629e-06, 'max_depth': 38, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.04557529868537958}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,301] Trial 71 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 2.4694835769693444e-05, 'max_depth': 33, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.2043923753539284}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,414] Trial 72 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 7.980060874212233e-06, 'max_depth': 67, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.5639201958076796}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,497] Trial 73 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 7.953832611812164e-07, 'max_depth': 23, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.28439214816539743}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,577] Trial 74 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 1.7112228213999991e-07, 'max_depth': 18, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.10849494514431395}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,703] Trial 75 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 5.7486523292494526e-08, 'max_depth': 79, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.3828411417966699}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,793] Trial 76 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 1.9875569687552476e-06, 'max_depth': 35, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.9879246151286764}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,865] Trial 77 finished with value: 0.7763232783153102 and parameters: {'booster': 'gbtree', 'gamma': 0.0002628983800078452, 'max_depth': 41, 'n_estimators': 21, 'grow_policy': 'depthwise', 'learning_rate': 0.0016201791672553313}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:22,944] Trial 78 finished with value: 0.7922595332953899 and parameters: {'booster': 'gbtree', 'gamma': 0.10135722205201118, 'max_depth': 27, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.027943923625511586}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,024] Trial 79 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 3.83751206961111e-07, 'max_depth': 22, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.21861865739719877}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,092] Trial 80 finished with value: 0.7956744450768355 and parameters: {'booster': 'gbtree', 'gamma': 5.029816691078647e-07, 'max_depth': 8, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.11484714898864022}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,170] Trial 81 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 2.7568075471850033e-07, 'max_depth': 22, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.20622205694965517}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,247] Trial 82 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 2.9876770920699185e-07, 'max_depth': 16, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.25184805661722043}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,321] Trial 83 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 7.540255909504502e-07, 'max_depth': 16, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.7108147869032343}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,397] Trial 84 finished with value: 0.8025042686397268 and parameters: {'booster': 'gbtree', 'gamma': 1.608293438672253e-07, 'max_depth': 17, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.2299272707980932}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,463] Trial 85 finished with value: 0.755264655663062 and parameters: {'booster': 'gblinear', 'gamma': 2.273344710282173e-06, 'max_depth': 25, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.0389143872792919}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,548] Trial 86 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 5.458596107778958e-08, 'max_depth': 30, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.06425320241631674}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,615] Trial 87 finished with value: 0.794536141149687 and parameters: {'booster': 'gbtree', 'gamma': 2.9943498378203137e-07, 'max_depth': 6, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.11745791350862507}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,695] Trial 88 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 4.746293887803689e-06, 'max_depth': 12, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.5907550826507071}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,767] Trial 89 finished with value: 0.7814456459874787 and parameters: {'booster': 'gbtree', 'gamma': 1.2305944942883995e-06, 'max_depth': 22, 'n_estimators': 71, 'grow_policy': 'depthwise', 'learning_rate': 0.017440873993673976}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,839] Trial 90 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 4.399842933320907e-07, 'max_depth': 14, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 1.5343344425761727e-05}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,916] Trial 91 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 3.0641225739675466e-07, 'max_depth': 22, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.202688034978705}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:23,996] Trial 92 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 7.262918540319674e-07, 'max_depth': 25, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.3772374640767979}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,072] Trial 93 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.3964764461522132e-07, 'max_depth': 19, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.21140735468404367}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,160] Trial 94 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.7227571575146028e-06, 'max_depth': 27, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.14968395298766898}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,258] Trial 95 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 3.087805344401217e-07, 'max_depth': 33, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.2756405404938986}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,341] Trial 96 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 1.3015264481240667e-05, 'max_depth': 21, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.6130314365405172}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,432] Trial 97 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 6.333189560697212e-07, 'max_depth': 29, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.06353811468888677}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,528] Trial 98 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 9.411835979658801e-08, 'max_depth': 32, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 7.552524686922607e-07}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,617] Trial 99 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 3.1711948372195984e-06, 'max_depth': 27, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.08235701359421962}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,682] Trial 100 finished with value: 0.7933978372225384 and parameters: {'booster': 'gblinear', 'gamma': 5.007238559618161e-07, 'max_depth': 1, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.4169529698392446}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,770] Trial 101 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 8.418669233474531e-07, 'max_depth': 29, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.14295285127537277}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,857] Trial 102 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 2.2720304452823828e-07, 'max_depth': 29, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.05788697892749934}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:24,954] Trial 103 finished with value: 0.8025042686397268 and parameters: {'booster': 'gbtree', 'gamma': 6.079808767976192e-06, 'max_depth': 36, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.11672849463436522}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,239] Trial 104 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 6.964944175151645e-07, 'max_depth': 24, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.7360997231677201}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,330] Trial 105 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.020901844424328e-06, 'max_depth': 30, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.29899554098358144}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,416] Trial 106 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.621495491510811e-06, 'max_depth': 26, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.41554829945426297}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,545] Trial 107 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 1.5716522830765518e-06, 'max_depth': 17, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.4436430800205823}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,690] Trial 108 finished with value: 0.8093340922026181 and parameters: {'booster': 'dart', 'gamma': 0.0035530629753083667, 'max_depth': 26, 'n_estimators': 85, 'grow_policy': 'depthwise', 'learning_rate': 0.23644773737623553}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,803] Trial 109 finished with value: 0.7894137734775185 and parameters: {'booster': 'gbtree', 'gamma': 3.9910804297683415e-07, 'max_depth': 20, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.9640554499135633}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,894] Trial 110 finished with value: 0.8155947638019351 and parameters: {'booster': 'gbtree', 'gamma': 2.865769512882768e-06, 'max_depth': 34, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.3301298856351556}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:25,989] Trial 111 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 2.4316339526180533e-06, 'max_depth': 32, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.3572939439513867}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,086] Trial 112 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 2.5141564800110704e-06, 'max_depth': 34, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.38912738595470653}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,182] Trial 113 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 8.186657745313872e-06, 'max_depth': 40, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.664875388895148}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,277] Trial 114 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 5.330199321505877e-06, 'max_depth': 37, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.09328370432276369}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,368] Trial 115 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 3.1828654630034256e-06, 'max_depth': 31, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.5168460763009295}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,452] Trial 116 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.738033477649231e-05, 'max_depth': 25, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.18452260095217235}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,551] Trial 117 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.8028719510606435e-06, 'max_depth': 44, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.3318179434362034}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,650] Trial 118 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 1.0202349116184827e-05, 'max_depth': 45, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.37789831886593994}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,755] Trial 119 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 4.464332943922702e-05, 'max_depth': 49, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.33819264292211015}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,818] Trial 120 finished with value: 0.7535571997723393 and parameters: {'booster': 'gblinear', 'gamma': 9.724260467037284e-06, 'max_depth': 54, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.035491478336672946}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:26,916] Trial 121 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 4.399945251031716e-06, 'max_depth': 44, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.7537337184649033}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,016] Trial 122 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 2.1027903717752998e-06, 'max_depth': 46, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.49517458715551826}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,114] Trial 123 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 1.7434343491345587e-06, 'max_depth': 42, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.1375005511748033}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,207] Trial 124 finished with value: 0.7899829254410927 and parameters: {'booster': 'gbtree', 'gamma': 2.2609270173087864e-05, 'max_depth': 35, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.9998016429403555}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,308] Trial 125 finished with value: 0.8042117245304496 and parameters: {'booster': 'gbtree', 'gamma': 3.7882105013607012e-06, 'max_depth': 39, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.3047327937925947}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,406] Trial 126 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 1.072060557737258e-06, 'max_depth': 37, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.3500078733713998}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,498] Trial 127 finished with value: 0.7990893568582812 and parameters: {'booster': 'gbtree', 'gamma': 1.2225389762808425e-06, 'max_depth': 32, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.07085257133233612}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,596] Trial 128 finished with value: 0.8036425725668753 and parameters: {'booster': 'dart', 'gamma': 6.448766791860812e-06, 'max_depth': 51, 'n_estimators': 10, 'grow_policy': 'depthwise', 'learning_rate': 0.17383191210146082}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,713] Trial 129 finished with value: 0.7899829254410927 and parameters: {'booster': 'gbtree', 'gamma': 2.5306590208105247e-06, 'max_depth': 46, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.0005610776625970021}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,820] Trial 130 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 5.855194850023741e-07, 'max_depth': 48, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.3339639074893915}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:27,922] Trial 131 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 1.26724113031222e-06, 'max_depth': 42, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.503095771370781}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,018] Trial 132 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 9.525418421514333e-07, 'max_depth': 38, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.10911677693302474}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,118] Trial 133 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.8322219648190398e-06, 'max_depth': 34, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.25634766259648967}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,219] Trial 134 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 3.436602182121211e-06, 'max_depth': 36, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.6252233877350962}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,315] Trial 135 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 9.69511366365822e-06, 'max_depth': 28, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.3990022193546935}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,408] Trial 136 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 6.456320254593301e-07, 'max_depth': 31, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.1890029772726353}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,500] Trial 137 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 2.478839296539377e-06, 'max_depth': 28, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.7392297770548961}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,613] Trial 138 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 4.949571166793114e-06, 'max_depth': 24, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.6616279511587703}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,708] Trial 139 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.2756737635801935e-05, 'max_depth': 27, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.2906972056002942}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,844] Trial 140 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 2.6106749486812983e-06, 'max_depth': 30, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.15642134037621902}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:28,948] Trial 141 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 1.611164698595774e-06, 'max_depth': 33, 'n_estimators': 99, 'grow_policy': 'lossguide', 'learning_rate': 0.44092002469613584}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,046] Trial 142 finished with value: 0.7916903813318156 and parameters: {'booster': 'gbtree', 'gamma': 1.1069526735954043e-06, 'max_depth': 40, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.9965395185156961}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,137] Trial 143 finished with value: 0.8161639157655094 and parameters: {'booster': 'gbtree', 'gamma': 2.366675296041848e-06, 'max_depth': 29, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.21704522277096167}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,230] Trial 144 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.854922463392703e-06, 'max_depth': 29, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.22858917788627073}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,319] Trial 145 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 2.1220920876941233e-06, 'max_depth': 23, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.12773605058451715}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,410] Trial 146 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 9.066149645771743e-07, 'max_depth': 25, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.36145290694970156}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,504] Trial 147 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 5.654099715300566e-06, 'max_depth': 27, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.6994710697314244}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,600] Trial 148 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 3.078016194030318e-06, 'max_depth': 29, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.05428573483386384}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,670] Trial 149 finished with value: 0.7677859988616961 and parameters: {'booster': 'gblinear', 'gamma': 1.463150064144035e-06, 'max_depth': 32, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.09232784568719374}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,748] Trial 150 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 4.748009116244852e-07, 'max_depth': 20, 'n_estimators': 67, 'grow_policy': 'depthwise', 'learning_rate': 0.31308602651492873}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,844] Trial 151 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 2.2154661637130065e-06, 'max_depth': 37, 'n_estimators': 51, 'grow_policy': 'lossguide', 'learning_rate': 0.5002802104551434}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:29,941] Trial 152 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 6.921070809761408e-07, 'max_depth': 34, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.2089299594882366}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,034] Trial 153 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 1.1843905601665285e-06, 'max_depth': 27, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.46717981023874633}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,128] Trial 154 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 6.686982717886893e-06, 'max_depth': 31, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.24411492153783262}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,217] Trial 155 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 6.5289358016609695e-06, 'max_depth': 25, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.15704588949963744}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,309] Trial 156 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.018340186609173e-05, 'max_depth': 31, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.25754869787341667}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,406] Trial 157 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 4.5036083689358e-06, 'max_depth': 23, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.7095092552809599}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,498] Trial 158 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 2.1712993182697394e-07, 'max_depth': 29, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.10462228570611018}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,598] Trial 159 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 3.1271934554399243e-06, 'max_depth': 44, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.21064914962914474}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,694] Trial 160 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 1.7876563278365347e-05, 'max_depth': 33, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.35726731132373063}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,791] Trial 161 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 1.5578741765150387e-06, 'max_depth': 35, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.5631743963415605}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,881] Trial 162 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 6.956299066647832e-06, 'max_depth': 26, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.3506228442347974}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:30,974] Trial 163 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 8.8536132812025e-07, 'max_depth': 31, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.14191209338917565}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,073] Trial 164 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 2.195331139268399e-06, 'max_depth': 38, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.2373772501272309}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,160] Trial 165 finished with value: 0.7933978372225384 and parameters: {'booster': 'gbtree', 'gamma': 4.844735250290134e-07, 'max_depth': 22, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.9984478131693215}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,290] Trial 166 finished with value: 0.7962435970404098 and parameters: {'booster': 'gbtree', 'gamma': 2.726407543117914e-06, 'max_depth': 92, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.5057083109401903}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,382] Trial 167 finished with value: 0.8150256118383609 and parameters: {'booster': 'gbtree', 'gamma': 4.576164014118989e-06, 'max_depth': 28, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.3265883034413078}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,469] Trial 168 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 4.8878395166334856e-06, 'max_depth': 28, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.07801231861148568}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,562] Trial 169 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 2.7726780173167577e-05, 'max_depth': 24, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.2845176512519861}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,681] Trial 170 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 1.249342360352911e-05, 'max_depth': 54, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.17103013030521938}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,785] Trial 171 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 1.5146248535959998e-06, 'max_depth': 29, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 0.38719260948396}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,877] Trial 172 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 3.7676680952817773e-06, 'max_depth': 26, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.7565203299801789}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:31,976] Trial 173 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 7.033272138025168e-06, 'max_depth': 35, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.4781302242476366}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,072] Trial 174 finished with value: 0.8161639157655094 and parameters: {'booster': 'gbtree', 'gamma': 1.2072221559889004e-06, 'max_depth': 33, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.24951364879542232}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,167] Trial 175 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 2.1292045136235823e-06, 'max_depth': 32, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.23173967729682085}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,259] Trial 176 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 0.00011546364277074073, 'max_depth': 30, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.11443249977812618}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,347] Trial 177 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.005243085633594e-06, 'max_depth': 19, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.3145151740179965}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,415] Trial 178 finished with value: 0.7820147979510529 and parameters: {'booster': 'gblinear', 'gamma': 3.134125440529209e-06, 'max_depth': 28, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.1724288543764773}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,495] Trial 179 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 3.476500000613308e-07, 'max_depth': 33, 'n_estimators': 78, 'grow_policy': 'depthwise', 'learning_rate': 0.00011835782479430422}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,581] Trial 180 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 8.650971788200759e-06, 'max_depth': 26, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 1.641440887259921e-07}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,677] Trial 181 finished with value: 0.7973819009675583 and parameters: {'booster': 'gbtree', 'gamma': 6.312554334900345e-07, 'max_depth': 36, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.6816024671676773}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,773] Trial 182 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 1.349175823419976e-06, 'max_depth': 31, 'n_estimators': 98, 'grow_policy': 'lossguide', 'learning_rate': 0.43775597758481777}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:32,880] Trial 183 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.7900310552066001e-06, 'max_depth': 39, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.32444562653232834}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,101] Trial 184 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 8.83984561066235e-07, 'max_depth': 42, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.23241864048721675}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,186] Trial 185 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 4.557108061069251e-06, 'max_depth': 22, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.5849350058064782}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,283] Trial 186 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 2.525085923329252e-06, 'max_depth': 34, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.1458747242631143}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,379] Trial 187 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.2047546021372138e-06, 'max_depth': 28, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.3792795929444047}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,487] Trial 188 finished with value: 0.8116107000569152 and parameters: {'booster': 'dart', 'gamma': 7.245031719762264e-07, 'max_depth': 30, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.22715604300485182}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,578] Trial 189 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.9828215278134097e-06, 'max_depth': 24, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.5311990516007317}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,684] Trial 190 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 3.4717252081384074e-06, 'max_depth': 37, 'n_estimators': 96, 'grow_policy': 'lossguide', 'learning_rate': 9.169094496012677e-06}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,783] Trial 191 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 3.1886151516864265e-07, 'max_depth': 20, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.23744917915851402}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,880] Trial 192 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 4.7062599415787625e-07, 'max_depth': 26, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.3269387692849899}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:33,973] Trial 193 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.781326084565091e-07, 'max_depth': 22, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.21208582120360575}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,075] Trial 194 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 1.2334866199390866e-06, 'max_depth': 32, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.1623049973615557}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,173] Trial 195 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 6.415993281562596e-08, 'max_depth': 32, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.13025285572425116}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,270] Trial 196 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.7759785572437615e-07, 'max_depth': 28, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.17402198690613369}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,367] Trial 197 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 1.1454100437334725e-07, 'max_depth': 24, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.08459930994193983}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,467] Trial 198 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 2.5621270009388025e-07, 'max_depth': 30, 'n_estimators': 77, 'grow_policy': 'lossguide', 'learning_rate': 0.2690627542374574}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,562] Trial 199 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.4829391082263393e-06, 'max_depth': 21, 'n_estimators': 74, 'grow_policy': 'lossguide', 'learning_rate': 0.17391470599179598}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,686] Trial 200 finished with value: 0.8042117245304496 and parameters: {'booster': 'gbtree', 'gamma': 5.034935626754058e-06, 'max_depth': 63, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.11113444716520045}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,791] Trial 201 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.0442019665726945e-06, 'max_depth': 33, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.37764080587493404}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,883] Trial 202 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 2.4951069190197285e-06, 'max_depth': 27, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.5237973972014416}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:34,982] Trial 203 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 2.528899639956228e-06, 'max_depth': 27, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.6024694983222895}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,092] Trial 204 finished with value: 0.790552077404667 and parameters: {'booster': 'gbtree', 'gamma': 1.992726680775779e-06, 'max_depth': 48, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.7744422700965086}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,185] Trial 205 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.696071219468844e-06, 'max_depth': 26, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.27728148562412724}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,283] Trial 206 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 6.676651297452016e-07, 'max_depth': 30, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.4182209721364738}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,382] Trial 207 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.4450165964684456e-06, 'max_depth': 24, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.22985348014171691}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,478] Trial 208 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 1.6055268996131997e-06, 'max_depth': 23, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.19208403738440197}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,577] Trial 209 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 1.040794065588869e-06, 'max_depth': 29, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.43951248848326285}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,663] Trial 210 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 5.37010677196178e-07, 'max_depth': 25, 'n_estimators': 22, 'grow_policy': 'depthwise', 'learning_rate': 0.9907189409915582}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,762] Trial 211 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.103065177778727e-06, 'max_depth': 29, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.5142819330021002}. Best is trial 42 with value: 0.8173022196926579.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,861] Trial 212 finished with value: 0.8207171314741036 and parameters: {'booster': 'gbtree', 'gamma': 2.709891198571726e-06, 'max_depth': 31, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.2910006396647754}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:35,959] Trial 213 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 2.813604618217937e-06, 'max_depth': 28, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.35577231443040275}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,059] Trial 214 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 6.405839199424509e-06, 'max_depth': 31, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.29912381588667414}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,156] Trial 215 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 4.18707298371382e-06, 'max_depth': 26, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.4779380579243777}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,256] Trial 216 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 2.0561926521982645e-06, 'max_depth': 28, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.7250599743647044}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,338] Trial 217 finished with value: 0.794536141149687 and parameters: {'booster': 'gblinear', 'gamma': 2.709697755234177e-06, 'max_depth': 76, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.3065271440328985}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,448] Trial 218 finished with value: 0.8150256118383609 and parameters: {'booster': 'gbtree', 'gamma': 8.383140137535939e-07, 'max_depth': 34, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.42419650990206037}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,546] Trial 219 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 7.730205847647658e-07, 'max_depth': 23, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.6191066027282562}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,650] Trial 220 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 3.942344041162664e-07, 'max_depth': 35, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.4430425725344475}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,758] Trial 221 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 1.4826105353643214e-06, 'max_depth': 31, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.3040859197087731}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,857] Trial 222 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 8.374896581733154e-07, 'max_depth': 34, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.21403370485974876}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:36,953] Trial 223 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 0.021236942512412153, 'max_depth': 29, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.3997068357762293}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,056] Trial 224 finished with value: 0.7928286852589641 and parameters: {'booster': 'gbtree', 'gamma': 1.6656771908935133e-06, 'max_depth': 32, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.0032529065749897176}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,154] Trial 225 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 5.117251258743088e-06, 'max_depth': 27, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.5807676839576472}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,257] Trial 226 finished with value: 0.8178713716562322 and parameters: {'booster': 'gbtree', 'gamma': 6.077999653399189e-07, 'max_depth': 30, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.28128251895065826}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,353] Trial 227 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 4.911204778959697e-07, 'max_depth': 25, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.24538662327370314}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,462] Trial 228 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 2.2859757239633492e-07, 'max_depth': 29, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.3149434979497153}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,563] Trial 229 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 8.755718797061158e-07, 'max_depth': 31, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.13645221555989528}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,658] Trial 230 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 3.730158844453039e-07, 'max_depth': 27, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.2004207217844904}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,765] Trial 231 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 6.140880456459945e-07, 'max_depth': 34, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.415636821507047}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,863] Trial 232 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 1.1069553053865936e-06, 'max_depth': 30, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.745139426894218}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:37,962] Trial 233 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 3.072410275731003e-06, 'max_depth': 32, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.30480051697217175}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,061] Trial 234 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 2.3030425651003683e-06, 'max_depth': 25, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.45121831958157127}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,158] Trial 235 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.6230042091106309e-06, 'max_depth': 24, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.4948407391227678}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,253] Trial 236 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 7.876908048557462e-06, 'max_depth': 21, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.2223523585406196}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,352] Trial 237 finished with value: 0.8025042686397268 and parameters: {'booster': 'gbtree', 'gamma': 1.1122286525474714e-06, 'max_depth': 26, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.5744110091537185}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,450] Trial 238 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 2.13912512081766e-06, 'max_depth': 28, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.3763266674580567}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,545] Trial 239 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 6.792189782512181e-07, 'max_depth': 24, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 1.3871255645074284e-06}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,645] Trial 240 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 0.001312912696076725, 'max_depth': 22, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 3.249048314760123e-05}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,787] Trial 241 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.7961357639377343e-06, 'max_depth': 29, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.27707147614782274}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:38,912] Trial 242 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 2.436177202491501e-06, 'max_depth': 33, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.3993148557199143}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,018] Trial 243 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 2.481305284629766e-06, 'max_depth': 36, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.7757660251626161}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,118] Trial 244 finished with value: 0.8155947638019351 and parameters: {'booster': 'gbtree', 'gamma': 1.4784219531077238e-06, 'max_depth': 33, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.4614589655415859}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,221] Trial 245 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.5406916666002823e-06, 'max_depth': 33, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.465149193657257}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,324] Trial 246 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 0.2658023523818489, 'max_depth': 34, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.5663143983867934}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,424] Trial 247 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.2982743486779578e-06, 'max_depth': 30, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.37641299247521676}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,527] Trial 248 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.9775933570817703e-06, 'max_depth': 36, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.27776629423119453}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,628] Trial 249 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.690038512027233e-06, 'max_depth': 31, 'n_estimators': 51, 'grow_policy': 'lossguide', 'learning_rate': 0.654183827741638}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,726] Trial 250 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 9.658365333734028e-07, 'max_depth': 27, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.41815929555074394}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,820] Trial 251 finished with value: 0.796812749003984 and parameters: {'booster': 'gbtree', 'gamma': 2.7606169444960927e-06, 'max_depth': 33, 'n_estimators': 20, 'grow_policy': 'depthwise', 'learning_rate': 0.9927325866753519}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:39,925] Trial 252 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.3660734105957712e-05, 'max_depth': 29, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.19140109009576428}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:40,036] Trial 253 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 5.367998502578612e-06, 'max_depth': 40, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.31531011163919875}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:40,136] Trial 254 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.9795750013029764e-06, 'max_depth': 26, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.5472114485222239}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:40,249] Trial 255 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 1.2958496321839395e-06, 'max_depth': 45, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.14612482472118293}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:40,327] Trial 256 finished with value: 0.7859988616960728 and parameters: {'booster': 'gblinear', 'gamma': 8.269570624231433e-07, 'max_depth': 31, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.23338345019157336}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:40,465] Trial 257 finished with value: 0.7933978372225384 and parameters: {'booster': 'gbtree', 'gamma': 3.3506741221908343e-06, 'max_depth': 37, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.0010805177455386623}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:41,052] Trial 258 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 1.6516979943146782e-06, 'max_depth': 28, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.40642861362991833}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:41,823] Trial 259 finished with value: 0.7962435970404098 and parameters: {'booster': 'gbtree', 'gamma': 2.455079206894081e-06, 'max_depth': 35, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.81692128364942}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:41,941] Trial 260 finished with value: 0.8087649402390438 and parameters: {'booster': 'dart', 'gamma': 1.0246554718848099e-05, 'max_depth': 33, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.2870811190574502}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,049] Trial 261 finished with value: 0.796812749003984 and parameters: {'booster': 'gbtree', 'gamma': 4.685575506609669e-06, 'max_depth': 30, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.546299288921245}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,152] Trial 262 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 6.428009517625884e-06, 'max_depth': 25, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.3886896019093332}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,258] Trial 263 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 1.1841886463661155e-06, 'max_depth': 27, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.1853642233622007}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,362] Trial 264 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 7.555180661872992e-07, 'max_depth': 31, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.2568007962016065}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,472] Trial 265 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 1.9546653600779794e-06, 'max_depth': 29, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.12609352324596587}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,573] Trial 266 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.6889883909792964e-06, 'max_depth': 28, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.10196648318034754}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,674] Trial 267 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.1230873522663063e-06, 'max_depth': 25, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.14953057760913877}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,779] Trial 268 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 2.4957669305187204e-06, 'max_depth': 29, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.12813910358571773}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,875] Trial 269 finished with value: 0.7990893568582812 and parameters: {'booster': 'gbtree', 'gamma': 1.8679458517142598e-06, 'max_depth': 50, 'n_estimators': 40, 'grow_policy': 'depthwise', 'learning_rate': 0.06967558930504898}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:42,974] Trial 270 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 6.531867873572191e-07, 'max_depth': 24, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.2000278949439148}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,080] Trial 271 finished with value: 0.796812749003984 and parameters: {'booster': 'gbtree', 'gamma': 3.198669946313509e-06, 'max_depth': 27, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.7106069400771554}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,190] Trial 272 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 1.2477361758542884e-06, 'max_depth': 33, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 8.348173919642637e-08}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,305] Trial 273 finished with value: 0.8025042686397268 and parameters: {'booster': 'gbtree', 'gamma': 8.78812507318651e-07, 'max_depth': 38, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.4850040430524255}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,407] Trial 274 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 4.986231462788856e-07, 'max_depth': 29, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.343669879461189}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,527] Trial 275 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.97502359292913e-06, 'max_depth': 47, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.18073799318797884}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,622] Trial 276 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.5270105107259915e-06, 'max_depth': 18, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.44786864447319774}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,734] Trial 277 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 2.6566528762156436e-06, 'max_depth': 35, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.24680811509651834}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,850] Trial 278 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 1.0471755394702875e-06, 'max_depth': 43, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.7209647077434328}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:43,933] Trial 279 finished with value: 0.7723392145702903 and parameters: {'booster': 'gblinear', 'gamma': 3.5197862175633036e-06, 'max_depth': 53, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.11913759747991598}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,038] Trial 280 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 6.286871975503904e-07, 'max_depth': 26, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.359361168917637}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,140] Trial 281 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 6.101158694441211e-05, 'max_depth': 23, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.2261942328385723}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,257] Trial 282 finished with value: 0.7956744450768355 and parameters: {'booster': 'dart', 'gamma': 2.1176857525496156e-06, 'max_depth': 31, 'n_estimators': 70, 'grow_policy': 'lossguide', 'learning_rate': 0.9772022668120653}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,368] Trial 283 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.4749360456791163e-06, 'max_depth': 33, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.5390828082834338}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,474] Trial 284 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 9.363142751866054e-07, 'max_depth': 29, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.29731535173452334}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,582] Trial 285 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 3.932317860481779e-08, 'max_depth': 26, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.15340087294777063}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,691] Trial 286 finished with value: 0.8144564598747865 and parameters: {'booster': 'gbtree', 'gamma': 3.4991669130330563e-06, 'max_depth': 28, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.45000235250085}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,803] Trial 287 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 4.680050680237655e-06, 'max_depth': 32, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.1032236371150981}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:44,901] Trial 288 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 3.552213780290054e-06, 'max_depth': 30, 'n_estimators': 58, 'grow_policy': 'depthwise', 'learning_rate': 0.35185034729824405}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,013] Trial 289 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 5.110970297398014e-07, 'max_depth': 34, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.20156634549557198}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,127] Trial 290 finished with value: 0.7933978372225384 and parameters: {'booster': 'gbtree', 'gamma': 1.385253415407025e-06, 'max_depth': 41, 'n_estimators': 68, 'grow_policy': 'lossguide', 'learning_rate': 0.00029505811262813377}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,235] Trial 291 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 2.030599956403652e-06, 'max_depth': 21, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.26892391550880895}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,346] Trial 292 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 4.239584334441851e-06, 'max_depth': 28, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.46245188019988276}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,457] Trial 293 finished with value: 0.7933978372225384 and parameters: {'booster': 'gbtree', 'gamma': 3.5913626129554003e-07, 'max_depth': 24, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.009121019871423242}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,573] Trial 294 finished with value: 0.796812749003984 and parameters: {'booster': 'gbtree', 'gamma': 1.3609142707859572e-07, 'max_depth': 36, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.64149463842539}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,685] Trial 295 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 7.848080999459513e-07, 'max_depth': 30, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.1766221222042229}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,801] Trial 296 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 8.089615137655786e-07, 'max_depth': 30, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.07843097560711307}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:45,915] Trial 297 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 6.640135490811345e-07, 'max_depth': 32, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.1605827522365818}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,030] Trial 298 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 1.1519609045303472e-06, 'max_depth': 33, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.15464943918362387}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,144] Trial 299 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 4.7033804048713156e-07, 'max_depth': 32, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.1841010607445916}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,229] Trial 300 finished with value: 0.7899829254410927 and parameters: {'booster': 'gblinear', 'gamma': 8.022617798503966e-07, 'max_depth': 35, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.24514842924336752}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,340] Trial 301 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 0.00023976593919355994, 'max_depth': 31, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.11859438678142291}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,451] Trial 302 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 1.5856825259249792e-06, 'max_depth': 28, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.34107274920487585}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,560] Trial 303 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.6781724749946646e-06, 'max_depth': 26, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.3347674827152918}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,686] Trial 304 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 2.7416271603375655e-06, 'max_depth': 29, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.4381618290413699}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,806] Trial 305 finished with value: 0.8013659647125783 and parameters: {'booster': 'dart', 'gamma': 1.3282673857176796e-06, 'max_depth': 23, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.7193527004032495}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:46,914] Trial 306 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.9008866850477773e-08, 'max_depth': 27, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.2848425766498305}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:46] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,023] Trial 307 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.7801526162885053e-06, 'max_depth': 27, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.41949291121365695}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,129] Trial 308 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 2.5854759598363707e-06, 'max_depth': 25, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.5994949211600783}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,224] Trial 309 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 1.2456445349173902e-06, 'max_depth': 29, 'n_estimators': 60, 'grow_policy': 'depthwise', 'learning_rate': 0.25880144974930425}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,330] Trial 310 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 9.687740378254716e-07, 'max_depth': 21, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.358049561352977}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,441] Trial 311 finished with value: 0.7951052931132613 and parameters: {'booster': 'gbtree', 'gamma': 3.446532013242855e-06, 'max_depth': 30, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.9692626542767955}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,557] Trial 312 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 2.0820786633837666e-06, 'max_depth': 38, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.2146561387413251}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,661] Trial 313 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 1.4420375912632263e-06, 'max_depth': 25, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.4324187571546141}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,761] Trial 314 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.6384453804471344e-06, 'max_depth': 19, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.5510994528684073}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,865] Trial 315 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 2.4977962966887442e-06, 'max_depth': 23, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.6963523236848416}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:47] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:47,968] Trial 316 finished with value: 0.8042117245304496 and parameters: {'booster': 'gbtree', 'gamma': 1.356237914277844e-06, 'max_depth': 24, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.4370288203273298}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,074] Trial 317 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 2.9461507686208116e-06, 'max_depth': 25, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.3432412992301863}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,180] Trial 318 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 4.712558100328611e-06, 'max_depth': 27, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 1.0977623507543225e-08}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,290] Trial 319 finished with value: 0.8042117245304496 and parameters: {'booster': 'gbtree', 'gamma': 2.157573987020962e-06, 'max_depth': 28, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.5327119940110006}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,408] Trial 320 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.0825463775216037e-06, 'max_depth': 22, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.2668897348094116}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,513] Trial 321 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 1.54855537937796e-06, 'max_depth': 26, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.6850616125421641}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,630] Trial 322 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 8.857309190699852e-08, 'max_depth': 35, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.4452388523455434}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,716] Trial 323 finished with value: 0.7933978372225384 and parameters: {'booster': 'gblinear', 'gamma': 3.287153641674223e-06, 'max_depth': 25, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.2978889061247394}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,862] Trial 324 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 1.918206943804316e-06, 'max_depth': 28, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.38171486752566497}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:48] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:48,970] Trial 325 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 1.0182241977165986e-06, 'max_depth': 31, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.9460087018093226}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,080] Trial 326 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 0.00015513782530858896, 'max_depth': 34, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.22914883574013903}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,181] Trial 327 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.6506048808048814e-06, 'max_depth': 23, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.5258275756330468}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,283] Trial 328 finished with value: 0.8144564598747865 and parameters: {'booster': 'dart', 'gamma': 6.365021852590022e-06, 'max_depth': 20, 'n_estimators': 12, 'grow_policy': 'depthwise', 'learning_rate': 0.33317398358471034}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,387] Trial 329 finished with value: 0.811041548093341 and parameters: {'booster': 'dart', 'gamma': 7.476639270906141e-06, 'max_depth': 22, 'n_estimators': 97, 'grow_policy': 'depthwise', 'learning_rate': 0.6939159789153898}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,493] Trial 330 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 4.909093012695408e-06, 'max_depth': 18, 'n_estimators': 12, 'grow_policy': 'depthwise', 'learning_rate': 0.3902283468353429}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,597] Trial 331 finished with value: 0.8138873079112123 and parameters: {'booster': 'dart', 'gamma': 5.233213338540888e-06, 'max_depth': 20, 'n_estimators': 13, 'grow_policy': 'depthwise', 'learning_rate': 0.3069066096987899}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,699] Trial 332 finished with value: 0.8059191804211725 and parameters: {'booster': 'dart', 'gamma': 6.6811604555630015e-06, 'max_depth': 18, 'n_estimators': 11, 'grow_policy': 'depthwise', 'learning_rate': 0.23353015157528095}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,806] Trial 333 finished with value: 0.8127490039840638 and parameters: {'booster': 'dart', 'gamma': 5.95000504036981e-06, 'max_depth': 16, 'n_estimators': 12, 'grow_policy': 'depthwise', 'learning_rate': 0.30705472410203327}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:49,908] Trial 334 finished with value: 0.8064883323847467 and parameters: {'booster': 'dart', 'gamma': 5.042894572267227e-06, 'max_depth': 20, 'n_estimators': 10, 'grow_policy': 'depthwise', 'learning_rate': 0.5409203910945763}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:49] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,012] Trial 335 finished with value: 0.8042117245304496 and parameters: {'booster': 'dart', 'gamma': 7.724768849852725e-06, 'max_depth': 20, 'n_estimators': 16, 'grow_policy': 'depthwise', 'learning_rate': 0.21428859794439692}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,116] Trial 336 finished with value: 0.8121798520204895 and parameters: {'booster': 'dart', 'gamma': 1.8891628023893756e-05, 'max_depth': 16, 'n_estimators': 19, 'grow_policy': 'depthwise', 'learning_rate': 0.32093109258936164}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,220] Trial 337 finished with value: 0.7985202048947069 and parameters: {'booster': 'dart', 'gamma': 9.230056269475964e-06, 'max_depth': 20, 'n_estimators': 3, 'grow_policy': 'depthwise', 'learning_rate': 0.7336925796602781}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,325] Trial 338 finished with value: 0.8030734206033011 and parameters: {'booster': 'dart', 'gamma': 2.7517776036006786e-07, 'max_depth': 22, 'n_estimators': 9, 'grow_policy': 'depthwise', 'learning_rate': 0.17229690591445462}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,431] Trial 339 finished with value: 0.807057484348321 and parameters: {'booster': 'dart', 'gamma': 3.307003557851928e-05, 'max_depth': 24, 'n_estimators': 8, 'grow_policy': 'depthwise', 'learning_rate': 0.4788181870076778}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,532] Trial 340 finished with value: 0.7723392145702903 and parameters: {'booster': 'dart', 'gamma': 3.812022825701713e-06, 'max_depth': 14, 'n_estimators': 13, 'grow_policy': 'depthwise', 'learning_rate': 0.005027826500077184}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,636] Trial 341 finished with value: 0.8076266363118952 and parameters: {'booster': 'dart', 'gamma': 5.167072320513312e-07, 'max_depth': 25, 'n_estimators': 15, 'grow_policy': 'depthwise', 'learning_rate': 0.2928801971675256}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,741] Trial 342 finished with value: 0.5082527034718269 and parameters: {'booster': 'dart', 'gamma': 2.8853853266706026e-06, 'max_depth': 19, 'n_estimators': 81, 'grow_policy': 'depthwise', 'learning_rate': 5.843547275497046e-06}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,838] Trial 343 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 1.0463221377500947e-06, 'max_depth': 21, 'n_estimators': 15, 'grow_policy': 'depthwise', 'learning_rate': 0.19686203706458114}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:50] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:50,948] Trial 344 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 1.4937392330614496e-06, 'max_depth': 26, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.4391370732471135}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,106] Trial 345 finished with value: 0.7865680136596471 and parameters: {'booster': 'gbtree', 'gamma': 6.51628644389401e-07, 'max_depth': 99, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.7568236035401438}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,192] Trial 346 finished with value: 0.5202048947068867 and parameters: {'booster': 'gblinear', 'gamma': 1.641799474813727e-07, 'max_depth': 24, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 5.496121115216259e-05}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,303] Trial 347 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 4.398626777653771e-06, 'max_depth': 27, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.32677505798728873}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,423] Trial 348 finished with value: 0.7894137734775185 and parameters: {'booster': 'dart', 'gamma': 2.8672900251434338e-06, 'max_depth': 22, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.9925287626779583}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,537] Trial 349 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 3.7298410538945464e-07, 'max_depth': 28, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.12464872919376362}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,656] Trial 350 finished with value: 0.8173022196926579 and parameters: {'booster': 'gbtree', 'gamma': 1.4465964287510813e-06, 'max_depth': 31, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.5333976010926487}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,769] Trial 351 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.2549057290375035e-05, 'max_depth': 32, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.5537498076354189}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,894] Trial 352 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 9.231881347865551e-07, 'max_depth': 37, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.24331798619243072}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:51] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:51,994] Trial 353 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 1.344123398116452e-06, 'max_depth': 30, 'n_estimators': 87, 'grow_policy': 'depthwise', 'learning_rate': 0.15495210225000758}. Best is trial 212 with value: 0.8207171314741036.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,110] Trial 354 finished with value: 0.8218554354012522 and parameters: {'booster': 'gbtree', 'gamma': 7.64807684665781e-07, 'max_depth': 31, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.3087189461317955}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,228] Trial 355 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 0.06263753236155527, 'max_depth': 34, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.6871940823350978}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,346] Trial 356 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 6.154943687467738e-07, 'max_depth': 32, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.36838191879449084}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,461] Trial 357 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 3.8060466689533393e-07, 'max_depth': 30, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.5258665190755434}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,585] Trial 358 finished with value: 0.8150256118383609 and parameters: {'booster': 'gbtree', 'gamma': 6.183375584112674e-07, 'max_depth': 36, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.2895316939971726}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,705] Trial 359 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 6.170860191274364e-07, 'max_depth': 36, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.34310152893068757}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,841] Trial 360 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 4.7135032853188324e-07, 'max_depth': 35, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.5434063681614936}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:52] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:52,958] Trial 361 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 7.258463488886517e-07, 'max_depth': 39, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.30782218105714704}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,080] Trial 362 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 8.771464341405774e-07, 'max_depth': 37, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.7523229742105835}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,196] Trial 363 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 9.768242116723004e-07, 'max_depth': 33, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.4108078566563264}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,303] Trial 364 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 1.7883097439566485e-06, 'max_depth': 39, 'n_estimators': 52, 'grow_policy': 'depthwise', 'learning_rate': 0.25381416510822113}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,416] Trial 365 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 4.827061007095626e-07, 'max_depth': 31, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.5315623330715288}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,537] Trial 366 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 1.1330000968838686e-06, 'max_depth': 34, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.38368001296831905}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,653] Trial 367 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 7.067488353642771e-07, 'max_depth': 32, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.18127856732764677}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,746] Trial 368 finished with value: 0.7939669891861126 and parameters: {'booster': 'gblinear', 'gamma': 4.957044895480832e-06, 'max_depth': 29, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.7627970413230996}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,860] Trial 369 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 1.5782511713337284e-06, 'max_depth': 31, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.25917594442200487}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:53] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:53,983] Trial 370 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 2.473408587497755e-06, 'max_depth': 37, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.4376374079660193}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,103] Trial 371 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 8.59932569367397e-07, 'max_depth': 38, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.09646000818881643}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,237] Trial 372 finished with value: 0.8047808764940239 and parameters: {'booster': 'dart', 'gamma': 3.635048029979735e-06, 'max_depth': 40, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.35326885910665795}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,339] Trial 373 finished with value: 0.8059191804211725 and parameters: {'booster': 'gbtree', 'gamma': 3.3917844367995804e-07, 'max_depth': 37, 'n_estimators': 60, 'grow_policy': 'depthwise', 'learning_rate': 0.1657198283015091}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,458] Trial 374 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 2.0970727942885142e-06, 'max_depth': 36, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.26235626543741913}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,588] Trial 375 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 7.255486434871575e-06, 'max_depth': 41, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 0.473931910376833}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,710] Trial 376 finished with value: 0.8138873079112123 and parameters: {'booster': 'gbtree', 'gamma': 1.2820366818226549e-06, 'max_depth': 34, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.3175230849705287}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,837] Trial 377 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 0.9947073397421794, 'max_depth': 34, 'n_estimators': 65, 'grow_policy': 'lossguide', 'learning_rate': 0.2090780110066686}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:54,959] Trial 378 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.1702486847257112e-06, 'max_depth': 35, 'n_estimators': 69, 'grow_policy': 'lossguide', 'learning_rate': 0.3251903599957249}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,079] Trial 379 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 4.999226181565718e-07, 'max_depth': 33, 'n_estimators': 72, 'grow_policy': 'lossguide', 'learning_rate': 0.5143845985574739}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,204] Trial 380 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 7.548001416957172e-07, 'max_depth': 36, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.1361259754158313}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,333] Trial 381 finished with value: 0.8081957882754696 and parameters: {'booster': 'dart', 'gamma': 1.2866970456382023e-06, 'max_depth': 32, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 0.25319466765300386}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,434] Trial 382 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 0.0003957717584492466, 'max_depth': 30, 'n_estimators': 61, 'grow_policy': 'depthwise', 'learning_rate': 0.40177465284386626}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,555] Trial 383 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 2.8036504030363717e-06, 'max_depth': 34, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.5845073768785056}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,671] Trial 384 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 9.605196336480197e-07, 'max_depth': 28, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.17977679531269464}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,792] Trial 385 finished with value: 0.7911212293682414 and parameters: {'booster': 'gbtree', 'gamma': 0.007762896646855343, 'max_depth': 32, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.01510960509563175}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:55,934] Trial 386 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 1.6060823023082115e-05, 'max_depth': 66, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.31512835663387206}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,053] Trial 387 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 2.5972046205717497e-07, 'max_depth': 30, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 4.101989670971481e-07}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,207] Trial 388 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 1.7323550335459578e-06, 'max_depth': 89, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.43648988773296266}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,340] Trial 389 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 5.825635607072744e-07, 'max_depth': 36, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.22509397166313155}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,441] Trial 390 finished with value: 0.8019351166761526 and parameters: {'booster': 'gbtree', 'gamma': 5.810504448753844e-06, 'max_depth': 28, 'n_estimators': 63, 'grow_policy': 'depthwise', 'learning_rate': 0.10282529464274723}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,565] Trial 391 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 9.247125710078623e-06, 'max_depth': 33, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.6324100015650187}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,698] Trial 392 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.2350747040331274e-06, 'max_depth': 56, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.3057718917975256}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,788] Trial 393 finished with value: 0.774046670461013 and parameters: {'booster': 'gblinear', 'gamma': 5.034986392793802e-05, 'max_depth': 38, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.14702100610492203}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:56,904] Trial 394 finished with value: 0.7951052931132613 and parameters: {'booster': 'gbtree', 'gamma': 3.4445663103219483e-06, 'max_depth': 31, 'n_estimators': 74, 'grow_policy': 'lossguide', 'learning_rate': 0.9334034315778259}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:56] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,016] Trial 395 finished with value: 0.8150256118383609 and parameters: {'booster': 'gbtree', 'gamma': 2.172338243915058e-06, 'max_depth': 27, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.4151822203546195}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,173] Trial 396 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 2.3025794754500747e-06, 'max_depth': 96, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.46397714136758184}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,289] Trial 397 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 3.956576942245877e-06, 'max_depth': 29, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.22838136332264136}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,409] Trial 398 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 2.1989060291634706e-06, 'max_depth': 34, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.34202610191031424}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,515] Trial 399 finished with value: 0.7774615822424588 and parameters: {'booster': 'gbtree', 'gamma': 7.268579729198474e-07, 'max_depth': 27, 'n_estimators': 57, 'grow_policy': 'depthwise', 'learning_rate': 0.0007801827659610305}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,632] Trial 400 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 1.3924160936352042e-06, 'max_depth': 32, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.6307243530074098}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,786] Trial 401 finished with value: 0.8053500284575982 and parameters: {'booster': 'dart', 'gamma': 5.516747465983356e-06, 'max_depth': 81, 'n_estimators': 70, 'grow_policy': 'lossguide', 'learning_rate': 0.19139428056898647}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:57,904] Trial 402 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 4.5696174734930386e-07, 'max_depth': 30, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.3916966334022683}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:57] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,024] Trial 403 finished with value: 0.7996585088218554 and parameters: {'booster': 'gbtree', 'gamma': 2.9564059405732293e-06, 'max_depth': 35, 'n_estimators': 51, 'grow_policy': 'lossguide', 'learning_rate': 0.27755316807232683}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,137] Trial 404 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 1.03700379878943e-06, 'max_depth': 27, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.5499397967717389}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,254] Trial 405 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 1.762107927472076e-06, 'max_depth': 29, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.14487563012849017}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,373] Trial 406 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 8.351324608787254e-07, 'max_depth': 32, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.043656622997599134}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,486] Trial 407 finished with value: 0.8076266363118952 and parameters: {'booster': 'dart', 'gamma': 4.1916000012971156e-06, 'max_depth': 37, 'n_estimators': 19, 'grow_policy': 'depthwise', 'learning_rate': 0.29021058337071887}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,611] Trial 408 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.8073468372786686e-06, 'max_depth': 34, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.7532020617927163}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,728] Trial 409 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.0563538211464313e-05, 'max_depth': 31, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.38431462282124756}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,878] Trial 410 finished with value: 0.8007968127490039 and parameters: {'booster': 'gbtree', 'gamma': 2.758540849020283e-06, 'max_depth': 28, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.9652197514860703}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:58] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:58,994] Trial 411 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 3.5816707389238675e-07, 'max_depth': 26, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.2041657239546054}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,098] Trial 412 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.2627591449675205e-06, 'max_depth': 14, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.4811667589938751}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,220] Trial 413 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 6.242961902477721e-07, 'max_depth': 39, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.2758023876007463}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,316] Trial 414 finished with value: 0.7683551508252704 and parameters: {'booster': 'gblinear', 'gamma': 8.68555734707616e-05, 'max_depth': 29, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.08943226671352064}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,420] Trial 415 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 6.503673251442348e-06, 'max_depth': 33, 'n_estimators': 64, 'grow_policy': 'depthwise', 'learning_rate': 0.4168633047924045}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,542] Trial 416 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 2.28286914216811e-06, 'max_depth': 31, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.18593226532628448}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,677] Trial 417 finished with value: 0.807057484348321 and parameters: {'booster': 'dart', 'gamma': 9.062545188481486e-07, 'max_depth': 36, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.12426233405295777}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,792] Trial 418 finished with value: 0.794536141149687 and parameters: {'booster': 'gbtree', 'gamma': 3.2478193890405928e-06, 'max_depth': 26, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.6068027666342393}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:51:59,903] Trial 419 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 1.4448966740994753e-06, 'max_depth': 18, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.3092042182346658}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:51:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,023] Trial 420 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 4.2800899133908185e-06, 'max_depth': 30, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.4522620705599675}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,144] Trial 421 finished with value: 0.8013659647125783 and parameters: {'booster': 'gbtree', 'gamma': 4.830523868727764e-07, 'max_depth': 34, 'n_estimators': 69, 'grow_policy': 'lossguide', 'learning_rate': 0.2262822196376512}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,260] Trial 422 finished with value: 0.7085941946499715 and parameters: {'booster': 'gbtree', 'gamma': 2.0656274151030168e-06, 'max_depth': 27, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.00016245871442494055}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,369] Trial 423 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 9.778125862559913e-07, 'max_depth': 29, 'n_estimators': 91, 'grow_policy': 'depthwise', 'learning_rate': 0.6698508095082394}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,489] Trial 424 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 6.579368797076345e-07, 'max_depth': 32, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.3356114873520753}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,613] Trial 425 finished with value: 0.8099032441661924 and parameters: {'booster': 'dart', 'gamma': 1.4033212335361767e-06, 'max_depth': 24, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.1620768719366654}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,735] Trial 426 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 5.779250778784052e-06, 'max_depth': 35, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.5009661970343003}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,858] Trial 427 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 2.8415300399608408e-06, 'max_depth': 28, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.2631900040714946}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:00] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:00,977] Trial 428 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 1.8672869477304176e-06, 'max_depth': 31, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.386228091826001}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,106] Trial 429 finished with value: 0.7933978372225384 and parameters: {'booster': 'gbtree', 'gamma': 2.633455412573209e-07, 'max_depth': 37, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.0015026771024175105}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,224] Trial 430 finished with value: 0.7962435970404098 and parameters: {'booster': 'gbtree', 'gamma': 1.0756231779796542e-06, 'max_depth': 26, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.9540058979292669}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,331] Trial 431 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 4.034315849346795e-06, 'max_depth': 33, 'n_estimators': 4, 'grow_policy': 'depthwise', 'learning_rate': 0.6148038899830104}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,447] Trial 432 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 8.750662556411095e-06, 'max_depth': 30, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 0.24224355604139747}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,562] Trial 433 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 5.450914277828753e-07, 'max_depth': 25, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.12623217172457615}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,698] Trial 434 finished with value: 0.8042117245304496 and parameters: {'booster': 'dart', 'gamma': 2.3985630379455502e-05, 'max_depth': 39, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.3563473194400287}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,808] Trial 435 finished with value: 0.7911212293682414 and parameters: {'booster': 'gbtree', 'gamma': 8.277775824069687e-07, 'max_depth': 17, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.0662010966526444}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:01] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:01,930] Trial 436 finished with value: 0.8144564598747865 and parameters: {'booster': 'gbtree', 'gamma': 2.313263308465896e-06, 'max_depth': 28, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.22163654099020222}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,025] Trial 437 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 3.148589187407516e-06, 'max_depth': 3, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 2.0822495340860023e-06}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,120] Trial 438 finished with value: 0.7803073420603301 and parameters: {'booster': 'gblinear', 'gamma': 2.157416502722482e-06, 'max_depth': 62, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.1630459762854562}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,241] Trial 439 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 4.989836977018623e-06, 'max_depth': 27, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.09429400818329989}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,346] Trial 440 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 2.5304452205660815e-06, 'max_depth': 22, 'n_estimators': 62, 'grow_policy': 'depthwise', 'learning_rate': 0.20077958083487465}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,471] Trial 441 finished with value: 0.8087649402390438 and parameters: {'booster': 'gbtree', 'gamma': 1.5994638320226911e-06, 'max_depth': 35, 'n_estimators': 56, 'grow_policy': 'lossguide', 'learning_rate': 0.2307861067785077}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,590] Trial 442 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.3879113339697135e-05, 'max_depth': 29, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.13968422737442784}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,726] Trial 443 finished with value: 0.811041548093341 and parameters: {'booster': 'dart', 'gamma': 3.25000997731554e-06, 'max_depth': 32, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.3186030758792216}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,839] Trial 444 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 6.269084819242867e-06, 'max_depth': 20, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.2009812706013335}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:02] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:02,956] Trial 445 finished with value: 0.8042117245304496 and parameters: {'booster': 'gbtree', 'gamma': 1.3710068433261151e-06, 'max_depth': 24, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.2762223712489538}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,074] Trial 446 finished with value: 0.813318155947638 and parameters: {'booster': 'gbtree', 'gamma': 2.4175571104113357e-06, 'max_depth': 28, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.4397080832065345}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,198] Trial 447 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 4.138657156517557e-06, 'max_depth': 33, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.1773638023861753}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,306] Trial 448 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 1.6689837668469247e-06, 'max_depth': 30, 'n_estimators': 19, 'grow_policy': 'depthwise', 'learning_rate': 0.3187809399873443}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,421] Trial 449 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 3.999759774909371e-07, 'max_depth': 26, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.49115235272787633}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,549] Trial 450 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 0.5871698767115171, 'max_depth': 42, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.251158710888937}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,675] Trial 451 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 1.0627392470716367e-06, 'max_depth': 37, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.1241397246090077}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,813] Trial 452 finished with value: 0.8104723961297666 and parameters: {'booster': 'dart', 'gamma': 0.0009141242181010399, 'max_depth': 35, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.39849981582858357}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:03] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:03,937] Trial 453 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 7.116396780414785e-06, 'max_depth': 31, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.6580213278343496}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,054] Trial 454 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 3.470924488958578e-06, 'max_depth': 25, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.26007542880311235}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,170] Trial 455 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 2.1019721789318616e-06, 'max_depth': 23, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.16288699124258244}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,279] Trial 456 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 6.973473173692148e-07, 'max_depth': 28, 'n_estimators': 55, 'grow_policy': 'depthwise', 'learning_rate': 7.38742227108772e-08}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,404] Trial 457 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 1.2393160729421825e-06, 'max_depth': 33, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.3880141658822005}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,512] Trial 458 finished with value: 0.8207171314741036 and parameters: {'booster': 'gbtree', 'gamma': 4.64923713534343e-06, 'max_depth': 12, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.5416519510582387}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,621] Trial 459 finished with value: 0.7916903813318156 and parameters: {'booster': 'gbtree', 'gamma': 4.690449683140673e-06, 'max_depth': 11, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.995990355761489}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,722] Trial 460 finished with value: 0.7962435970404098 and parameters: {'booster': 'gblinear', 'gamma': 1.0340140982753821e-05, 'max_depth': 6, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.6253132229995926}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,829] Trial 461 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 1.7734304515477953e-06, 'max_depth': 10, 'n_estimators': 91, 'grow_policy': 'lossguide', 'learning_rate': 0.51971165944149}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:04] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:04,952] Trial 462 finished with value: 0.8047808764940239 and parameters: {'booster': 'dart', 'gamma': 8.489303729278973e-07, 'max_depth': 15, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.5549817772176088}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,072] Trial 463 finished with value: 0.7939669891861126 and parameters: {'booster': 'gbtree', 'gamma': 2.730868921501855e-06, 'max_depth': 31, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.7759122505540286}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,196] Trial 464 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 3.6540733348658057e-07, 'max_depth': 34, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.3745452839100725}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,306] Trial 465 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 6.104770739301941e-07, 'max_depth': 30, 'n_estimators': 28, 'grow_policy': 'depthwise', 'learning_rate': 0.31489314322561685}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,411] Trial 466 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 1.2342793765111064e-06, 'max_depth': 9, 'n_estimators': 51, 'grow_policy': 'lossguide', 'learning_rate': 1.6988964616794736e-05}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,515] Trial 467 finished with value: 0.8064883323847467 and parameters: {'booster': 'gbtree', 'gamma': 4.543979313425236e-06, 'max_depth': 8, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.4915295461313539}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,643] Trial 468 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 2.46507867040586e-06, 'max_depth': 37, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.698108172534219}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,768] Trial 469 finished with value: 0.8099032441661924 and parameters: {'booster': 'gbtree', 'gamma': 1.558030700603509e-06, 'max_depth': 29, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.24981535608001665}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:05,890] Trial 470 finished with value: 0.8104723961297666 and parameters: {'booster': 'dart', 'gamma': 7.3960374753212225e-06, 'max_depth': 13, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.375323508322348}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:05] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,022] Trial 471 finished with value: 0.8025042686397268 and parameters: {'booster': 'gbtree', 'gamma': 9.889828519951046e-07, 'max_depth': 40, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.5291938093893774}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,146] Trial 472 finished with value: 0.8081957882754696 and parameters: {'booster': 'gbtree', 'gamma': 3.4411740258397327e-06, 'max_depth': 32, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.19170100554259167}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,258] Trial 473 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 2.0044646168864128e-06, 'max_depth': 35, 'n_estimators': 62, 'grow_policy': 'depthwise', 'learning_rate': 0.3086271815391283}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,365] Trial 474 finished with value: 0.8127490039840638 and parameters: {'booster': 'gbtree', 'gamma': 5.974992149043646e-07, 'max_depth': 12, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.44342405905197607}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,484] Trial 475 finished with value: 0.7899829254410927 and parameters: {'booster': 'gbtree', 'gamma': 1.303790099030859e-06, 'max_depth': 28, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.7824970121571855}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,581] Trial 476 finished with value: 0.5082527034718269 and parameters: {'booster': 'gbtree', 'gamma': 2.765688547977121e-07, 'max_depth': 1, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.2467597093412319}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,705] Trial 477 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 8.855611618744796e-07, 'max_depth': 33, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.38733691493038286}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,839] Trial 478 finished with value: 0.813318155947638 and parameters: {'booster': 'dart', 'gamma': 5.224558240026386e-06, 'max_depth': 27, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.6088767545844865}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:06] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:06,964] Trial 479 finished with value: 0.8053500284575982 and parameters: {'booster': 'gbtree', 'gamma': 2.8191782518896027e-06, 'max_depth': 31, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.10712119824963945}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,088] Trial 480 finished with value: 0.7911212293682414 and parameters: {'booster': 'gbtree', 'gamma': 1.5570040186607404e-06, 'max_depth': 30, 'n_estimators': 53, 'grow_policy': 'lossguide', 'learning_rate': 0.025056929576819476}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,200] Trial 481 finished with value: 0.8047808764940239 and parameters: {'booster': 'gbtree', 'gamma': 2.2096863435718043e-06, 'max_depth': 36, 'n_estimators': 21, 'grow_policy': 'depthwise', 'learning_rate': 0.1986969226516938}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,324] Trial 482 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 5.417034851209669e-07, 'max_depth': 33, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.2929096593069251}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,425] Trial 483 finished with value: 0.7933978372225384 and parameters: {'booster': 'gblinear', 'gamma': 3.266342326982112e-06, 'max_depth': 7, 'n_estimators': 94, 'grow_policy': 'lossguide', 'learning_rate': 0.4364864609816656}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,580] Trial 484 finished with value: 0.7859988616960728 and parameters: {'booster': 'gbtree', 'gamma': 1.5667075823627546e-05, 'max_depth': 73, 'n_estimators': 85, 'grow_policy': 'lossguide', 'learning_rate': 0.6787321776815864}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,710] Trial 485 finished with value: 0.8030734206033011 and parameters: {'booster': 'gbtree', 'gamma': 8.60834458590241e-07, 'max_depth': 38, 'n_estimators': 90, 'grow_policy': 'lossguide', 'learning_rate': 0.15004442658845824}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,832] Trial 486 finished with value: 0.8093340922026181 and parameters: {'booster': 'gbtree', 'gamma': 4.112572284828748e-07, 'max_depth': 28, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.3032348629414904}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:07] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:07,956] Trial 487 finished with value: 0.8116107000569152 and parameters: {'booster': 'gbtree', 'gamma': 9.24483241361902e-06, 'max_depth': 30, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.48336064612875745}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,086] Trial 488 finished with value: 0.790552077404667 and parameters: {'booster': 'dart', 'gamma': 1.8237034779007397e-06, 'max_depth': 26, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.002584892435940796}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,200] Trial 489 finished with value: 0.8104723961297666 and parameters: {'booster': 'gbtree', 'gamma': 5.59710964757139e-06, 'max_depth': 32, 'n_estimators': 64, 'grow_policy': 'depthwise', 'learning_rate': 0.21486258379290682}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,305] Trial 490 finished with value: 0.8036425725668753 and parameters: {'booster': 'gbtree', 'gamma': 3.9099722814906756e-06, 'max_depth': 4, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.3797598038548024}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,433] Trial 491 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 1.0241252678958423e-06, 'max_depth': 35, 'n_estimators': 87, 'grow_policy': 'lossguide', 'learning_rate': 0.08200357109643645}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,548] Trial 492 finished with value: 0.811041548093341 and parameters: {'booster': 'gbtree', 'gamma': 3.5245329388475444e-05, 'max_depth': 16, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.26225176149721274}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,679] Trial 493 finished with value: 0.8002276607854297 and parameters: {'booster': 'gbtree', 'gamma': 1.332724195048521e-06, 'max_depth': 29, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.8207841048489782}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,830] Trial 494 finished with value: 0.8076266363118952 and parameters: {'booster': 'gbtree', 'gamma': 2.4269064200998656e-06, 'max_depth': 27, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.18369742628545782}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:08,968] Trial 495 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 2.0204659698032306e-07, 'max_depth': 34, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.5576038321595721}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:09,106] Trial 496 finished with value: 0.8127490039840638 and parameters: {'booster': 'dart', 'gamma': 6.424865519846829e-07, 'max_depth': 31, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.3236080515127362}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:09,219] Trial 497 finished with value: 0.807057484348321 and parameters: {'booster': 'gbtree', 'gamma': 1.7484840218184327e-06, 'max_depth': 38, 'n_estimators': 55, 'grow_policy': 'depthwise', 'learning_rate': 0.13035777111045085}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:09,343] Trial 498 finished with value: 0.7877063175867957 and parameters: {'booster': 'gbtree', 'gamma': 3.5388239799736933e-06, 'max_depth': 29, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.9691217713468195}. Best is trial 354 with value: 0.8218554354012522.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [03:52:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 03:52:09,467] Trial 499 finished with value: 0.8121798520204895 and parameters: {'booster': 'gbtree', 'gamma': 7.36280134131617e-06, 'max_depth': 26, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.40454091986545976}. Best is trial 354 with value: 0.8218554354012522.\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X, label=dft['Transported'])\n",
    "dvalid = xgb.DMatrix(x, label=dfv['Transported'])\n",
    "\n",
    "def objective(trial):\n",
    "    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth',1, 100),\n",
    "        'max_leaves': trial.suggest_int('max_depth',1, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',1, 100),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True)\n",
    "    }    \n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(dfv['Transported'], pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a2b38",
   "metadata": {
    "papermill": {
     "duration": 0.079849,
     "end_time": "2024-03-08T03:52:09.636493",
     "exception": false,
     "start_time": "2024-03-08T03:52:09.556644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e59599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:09.796573Z",
     "iopub.status.busy": "2024-03-08T03:52:09.796186Z",
     "iopub.status.idle": "2024-03-08T03:52:09.803611Z",
     "shell.execute_reply": "2024-03-08T03:52:09.802593Z"
    },
    "papermill": {
     "duration": 0.09036,
     "end_time": "2024-03-08T03:52:09.805984",
     "exception": false,
     "start_time": "2024-03-08T03:52:09.715624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRFClassifier(\n",
    "    booster='gbtree',\n",
    "    device='cpu',\n",
    "    eval_metric=sklearn.metrics.mean_absolute_percentage_error,\n",
    "    grow_policy = 'lossguide',\n",
    "    gamma = 0.030185106394347308,\n",
    "    max_depth= 5,\n",
    "    n_estimators = 93,\n",
    "    learning_rate = 0.571705231643359\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c099bbd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:09.967492Z",
     "iopub.status.busy": "2024-03-08T03:52:09.967091Z",
     "iopub.status.idle": "2024-03-08T03:52:10.193470Z",
     "shell.execute_reply": "2024-03-08T03:52:10.192534Z"
    },
    "papermill": {
     "duration": 0.308981,
     "end_time": "2024-03-08T03:52:10.195941",
     "exception": false,
     "start_time": "2024-03-08T03:52:09.886960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.51376\tvalidation_0-mean_absolute_percentage_error:871762799624192.00000\tvalidation_1-logloss:0.52159\tvalidation_1-mean_absolute_percentage_error:858098898042880.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7a5b6cb2e290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7a5b6cb2e290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRFClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device='cpu',\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=<function mean_absolute_percentage_error at 0x7a5b6cb2e290>,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy='lossguide', importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective='binary:logistic',\n",
       "                random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,eval_set=[(X,y),(x,Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9ca117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:10.429941Z",
     "iopub.status.busy": "2024-03-08T03:52:10.429506Z",
     "iopub.status.idle": "2024-03-08T03:52:10.455333Z",
     "shell.execute_reply": "2024-03-08T03:52:10.454275Z"
    },
    "papermill": {
     "duration": 0.182591,
     "end_time": "2024-03-08T03:52:10.457930",
     "exception": false,
     "start_time": "2024-03-08T03:52:10.275339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036425725668753"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueval = dfv['Transported']\n",
    "predval = model.predict(x)\n",
    "sklearn.metrics.accuracy_score(trueval, predval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d1a3f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:10.620530Z",
     "iopub.status.busy": "2024-03-08T03:52:10.619448Z",
     "iopub.status.idle": "2024-03-08T03:52:11.124249Z",
     "shell.execute_reply": "2024-03-08T03:52:11.123049Z"
    },
    "papermill": {
     "duration": 0.589014,
     "end_time": "2024-03-08T03:52:11.127363",
     "exception": false,
     "start_time": "2024-03-08T03:52:10.538349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd6fdd",
   "metadata": {
    "papermill": {
     "duration": 0.08112,
     "end_time": "2024-03-08T03:52:11.291290",
     "exception": false,
     "start_time": "2024-03-08T03:52:11.210170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b39c2167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:11.457012Z",
     "iopub.status.busy": "2024-03-08T03:52:11.456567Z",
     "iopub.status.idle": "2024-03-08T03:52:11.492271Z",
     "shell.execute_reply": "2024-03-08T03:52:11.490895Z"
    },
    "papermill": {
     "duration": 0.121447,
     "end_time": "2024-03-08T03:52:11.495297",
     "exception": false,
     "start_time": "2024-03-08T03:52:11.373850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "labels = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45143dd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:11.662041Z",
     "iopub.status.busy": "2024-03-08T03:52:11.660876Z",
     "iopub.status.idle": "2024-03-08T03:52:11.693315Z",
     "shell.execute_reply": "2024-03-08T03:52:11.692155Z"
    },
    "papermill": {
     "duration": 0.118427,
     "end_time": "2024-03-08T03:52:11.695895",
     "exception": false,
     "start_time": "2024-03-08T03:52:11.577468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4195.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>4179.000000</td>\n",
       "      <td>4176.000000</td>\n",
       "      <td>4197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.658146</td>\n",
       "      <td>219.266269</td>\n",
       "      <td>439.484296</td>\n",
       "      <td>177.295525</td>\n",
       "      <td>303.052443</td>\n",
       "      <td>310.710031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.179072</td>\n",
       "      <td>607.011289</td>\n",
       "      <td>1527.663045</td>\n",
       "      <td>560.821123</td>\n",
       "      <td>1117.186015</td>\n",
       "      <td>1246.994742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>11567.000000</td>\n",
       "      <td>25273.000000</td>\n",
       "      <td>8292.000000</td>\n",
       "      <td>19844.000000</td>\n",
       "      <td>22272.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  4186.000000   4195.000000   4171.000000   4179.000000   4176.000000   \n",
       "mean     28.658146    219.266269    439.484296    177.295525    303.052443   \n",
       "std      14.179072    607.011289   1527.663045    560.821123   1117.186015   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      26.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      37.000000     53.000000     78.000000     33.000000     50.000000   \n",
       "max      79.000000  11567.000000  25273.000000   8292.000000  19844.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   4197.000000  \n",
       "mean     310.710031  \n",
       "std     1246.994742  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       36.000000  \n",
       "max    22272.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684aff88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:11.861676Z",
     "iopub.status.busy": "2024-03-08T03:52:11.860972Z",
     "iopub.status.idle": "2024-03-08T03:52:11.906595Z",
     "shell.execute_reply": "2024-03-08T03:52:11.905462Z"
    },
    "papermill": {
     "duration": 0.130676,
     "end_time": "2024-03-08T03:52:11.909202",
     "exception": false,
     "start_time": "2024-03-08T03:52:11.778526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/17557714.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/17557714.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "test_df[['CabinDeck', 'CabinNum', 'CabinSide']] = test_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "test_df = pd.concat([test_df,pd.get_dummies(test_df.Destination)], axis = 1)\n",
    "test_df = test_df.drop(['Name','Destination','Cabin','PassengerId'],axis=1)\n",
    "test_df.fillna(0,inplace=True)\n",
    "\n",
    "test_df['CryoSleep'] = test_df['CryoSleep'].astype(bool)\n",
    "test_df['VIP'] = test_df['VIP'].astype(bool)\n",
    "test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "test_df['CabinNum'] = test_df['CabinNum'].astype(int)\n",
    "test_df['CabinDeck'] = test_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1aa1ec2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:12.074342Z",
     "iopub.status.busy": "2024-03-08T03:52:12.073877Z",
     "iopub.status.idle": "2024-03-08T03:52:12.104999Z",
     "shell.execute_reply": "2024-03-08T03:52:12.103862Z"
    },
    "papermill": {
     "duration": 0.116251,
     "end_time": "2024-03-08T03:52:12.107685",
     "exception": false,
     "start_time": "2024-03-08T03:52:11.991434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0              1       True  27.0  False          0.0        0.0   \n",
       "1              1      False  19.0  False          0.0        9.0   \n",
       "2              0       True  31.0  False          0.0        0.0   \n",
       "3              0      False  38.0  False          0.0     6652.0   \n",
       "4              1      False  20.0  False         10.0        0.0   \n",
       "...          ...        ...   ...    ...          ...        ...   \n",
       "4272           1       True  34.0  False          0.0        0.0   \n",
       "4273           1      False  42.0  False          0.0      847.0   \n",
       "4274           2       True   0.0  False          0.0        0.0   \n",
       "4275           0      False   0.0  False          0.0     2680.0   \n",
       "4276           1       True  43.0  False          0.0        0.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  CabinDeck  CabinNum  CabinSide  \\\n",
       "0              0.0     0.0     0.0          0         3          0   \n",
       "1              0.0  2823.0     0.0          0         4          0   \n",
       "2              0.0     0.0     0.0          0         0          0   \n",
       "3              0.0   181.0   585.0          0         1          0   \n",
       "4            635.0     0.0     0.0          0         5          0   \n",
       "...            ...     ...     ...        ...       ...        ...   \n",
       "4272           0.0     0.0     0.0          0      1496          0   \n",
       "4273          17.0    10.0   144.0          0         0          0   \n",
       "4274           0.0     0.0     0.0          1       296          1   \n",
       "4275           0.0     0.0   523.0          1       297          1   \n",
       "4276           0.0     0.0     0.0          0      1498          0   \n",
       "\n",
       "      55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0           False          False         True  \n",
       "1           False          False         True  \n",
       "2            True          False        False  \n",
       "3           False          False         True  \n",
       "4           False          False         True  \n",
       "...           ...            ...          ...  \n",
       "4272        False          False         True  \n",
       "4273        False          False         True  \n",
       "4274         True          False        False  \n",
       "4275        False          False        False  \n",
       "4276        False           True        False  \n",
       "\n",
       "[4277 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e34119a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T03:52:12.272627Z",
     "iopub.status.busy": "2024-03-08T03:52:12.272174Z",
     "iopub.status.idle": "2024-03-08T03:52:12.319487Z",
     "shell.execute_reply": "2024-03-08T03:52:12.318294Z"
    },
    "papermill": {
     "duration": 0.133389,
     "end_time": "2024-03-08T03:52:12.322658",
     "exception": false,
     "start_time": "2024-03-08T03:52:12.189269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df['Survived'] = model.predict(test_df)\n",
    "test_df['PassengerId'] = labels\n",
    "dfexport = test_df[['PassengerId','Survived']]\n",
    "dfexport.to_csv('predictionoutput.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d67f1",
   "metadata": {
    "papermill": {
     "duration": 0.099182,
     "end_time": "2024-03-08T03:52:12.544575",
     "exception": false,
     "start_time": "2024-03-08T03:52:12.445393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.306248,
   "end_time": "2024-03-08T03:52:13.452315",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T03:51:09.146067",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
