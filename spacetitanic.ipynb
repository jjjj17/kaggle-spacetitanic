{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6222b75e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:04.721173Z",
     "iopub.status.busy": "2024-03-08T04:03:04.720854Z",
     "iopub.status.idle": "2024-03-08T04:03:05.619470Z",
     "shell.execute_reply": "2024-03-08T04:03:05.618520Z"
    },
    "papermill": {
     "duration": 0.907838,
     "end_time": "2024-03-08T04:03:05.621323",
     "exception": false,
     "start_time": "2024-03-08T04:03:04.713485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/spaceship-titanic/sample_submission.csv\n",
      "/kaggle/input/spaceship-titanic/train.csv\n",
      "/kaggle/input/spaceship-titanic/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b697844e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:05.635213Z",
     "iopub.status.busy": "2024-03-08T04:03:05.634092Z",
     "iopub.status.idle": "2024-03-08T04:03:08.399909Z",
     "shell.execute_reply": "2024-03-08T04:03:08.398806Z"
    },
    "papermill": {
     "duration": 2.775148,
     "end_time": "2024-03-08T04:03:08.402293",
     "exception": false,
     "start_time": "2024-03-08T04:03:05.627145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import optuna\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1939c7",
   "metadata": {
    "papermill": {
     "duration": 0.005725,
     "end_time": "2024-03-08T04:03:08.414053",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.408328",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1d70d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.428778Z",
     "iopub.status.busy": "2024-03-08T04:03:08.427411Z",
     "iopub.status.idle": "2024-03-08T04:03:08.480603Z",
     "shell.execute_reply": "2024-03-08T04:03:08.479765Z"
    },
    "papermill": {
     "duration": 0.062325,
     "end_time": "2024-03-08T04:03:08.482797",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.420472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9e4efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.496530Z",
     "iopub.status.busy": "2024-03-08T04:03:08.496000Z",
     "iopub.status.idle": "2024-03-08T04:03:08.499328Z",
     "shell.execute_reply": "2024-03-08T04:03:08.498742Z"
    },
    "papermill": {
     "duration": 0.011859,
     "end_time": "2024-03-08T04:03:08.500900",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.489041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df=train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fb8764",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.514932Z",
     "iopub.status.busy": "2024-03-08T04:03:08.514249Z",
     "iopub.status.idle": "2024-03-08T04:03:08.565538Z",
     "shell.execute_reply": "2024-03-08T04:03:08.563996Z"
    },
    "papermill": {
     "duration": 0.061511,
     "end_time": "2024-03-08T04:03:08.567881",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.506370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2362847667.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/2362847667.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_raw['Transported']\n",
    "train_df[['CabinDeck', 'CabinNum', 'CabinSide']] = train_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "train_df = pd.concat([train_df,pd.get_dummies(train_df.Destination)], axis = 1)\n",
    "train_df = train_df.drop(['Name','Destination','Cabin'],axis=1)\n",
    "train_df.dropna(inplace=True)\n",
    "\n",
    "train_df['CryoSleep'] = train_df['CryoSleep'].astype(bool)\n",
    "train_df['VIP'] = train_df['VIP'].astype(bool)\n",
    "train_df['CabinSide'] = train_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "train_df['CabinNum'] = train_df['CabinNum'].astype(int)\n",
    "train_df['CabinDeck'] = train_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567baadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.580623Z",
     "iopub.status.busy": "2024-03-08T04:03:08.580327Z",
     "iopub.status.idle": "2024-03-08T04:03:08.584756Z",
     "shell.execute_reply": "2024-03-08T04:03:08.583581Z"
    },
    "papermill": {
     "duration": 0.012627,
     "end_time": "2024-03-08T04:03:08.586546",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.573919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df[train_df['HomePlanet'].isnull()]\n",
    "#df1 = train_df[train_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d01a5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.598913Z",
     "iopub.status.busy": "2024-03-08T04:03:08.598560Z",
     "iopub.status.idle": "2024-03-08T04:03:08.627706Z",
     "shell.execute_reply": "2024-03-08T04:03:08.626736Z"
    },
    "papermill": {
     "duration": 0.040205,
     "end_time": "2024-03-08T04:03:08.632355",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.592150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Transported</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1499</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6913 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0        0001_01           0      False  39.0  False          0.0        0.0   \n",
       "1        0002_01           1      False  24.0  False        109.0        9.0   \n",
       "2        0003_01           0      False  58.0   True         43.0     3576.0   \n",
       "3        0003_02           0      False  33.0  False          0.0     1283.0   \n",
       "4        0004_01           1      False  16.0  False        303.0       70.0   \n",
       "...          ...         ...        ...   ...    ...          ...        ...   \n",
       "8688     9276_01           0      False  41.0   True          0.0     6819.0   \n",
       "8689     9278_01           1       True  18.0  False          0.0        0.0   \n",
       "8690     9279_01           1      False  26.0  False          0.0        0.0   \n",
       "8691     9280_01           0      False  32.0  False          0.0     1049.0   \n",
       "8692     9280_02           0      False  44.0  False        126.0     4688.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Transported  CabinDeck  CabinNum  \\\n",
       "0              0.0     0.0     0.0        False          1         0   \n",
       "1             25.0   549.0    44.0         True          0         0   \n",
       "2              0.0  6715.0    49.0        False          0         0   \n",
       "3            371.0  3329.0   193.0        False          0         0   \n",
       "4            151.0   565.0     2.0         True          0         1   \n",
       "...            ...     ...     ...          ...        ...       ...   \n",
       "8688           0.0  1643.0    74.0        False          1        98   \n",
       "8689           0.0     0.0     0.0        False          0      1499   \n",
       "8690        1872.0     1.0     0.0         True          0      1500   \n",
       "8691           0.0   353.0  3235.0        False          0       608   \n",
       "8692           0.0     0.0    12.0         True          0       608   \n",
       "\n",
       "      CabinSide  55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0             1        False          False         True  \n",
       "1             0        False          False         True  \n",
       "2             0        False          False         True  \n",
       "3             0        False          False         True  \n",
       "4             0        False          False         True  \n",
       "...         ...          ...            ...          ...  \n",
       "8688          1         True          False        False  \n",
       "8689          0        False           True        False  \n",
       "8690          0        False          False         True  \n",
       "8691          0         True          False        False  \n",
       "8692          0        False          False         True  \n",
       "\n",
       "[6913 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6882e",
   "metadata": {
    "papermill": {
     "duration": 0.006086,
     "end_time": "2024-03-08T04:03:08.645145",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.639059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfa277b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.660452Z",
     "iopub.status.busy": "2024-03-08T04:03:08.660090Z",
     "iopub.status.idle": "2024-03-08T04:03:08.665815Z",
     "shell.execute_reply": "2024-03-08T04:03:08.664448Z"
    },
    "papermill": {
     "duration": 0.016246,
     "end_time": "2024-03-08T04:03:08.667712",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.651466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_dataset(dataset, test_ratio=0.25):\n",
    "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
    "  return dataset[~test_indices], dataset[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2b41e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.681916Z",
     "iopub.status.busy": "2024-03-08T04:03:08.681290Z",
     "iopub.status.idle": "2024-03-08T04:03:08.688655Z",
     "shell.execute_reply": "2024-03-08T04:03:08.687185Z"
    },
    "papermill": {
     "duration": 0.016856,
     "end_time": "2024-03-08T04:03:08.690884",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.674028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145 examples in training, 1768 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "dft, dfv = split_dataset(train_df)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(dft), len(dfv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344d516e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.704895Z",
     "iopub.status.busy": "2024-03-08T04:03:08.704564Z",
     "iopub.status.idle": "2024-03-08T04:03:08.712108Z",
     "shell.execute_reply": "2024-03-08T04:03:08.711066Z"
    },
    "papermill": {
     "duration": 0.016978,
     "end_time": "2024-03-08T04:03:08.714102",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.697124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y= dft['Transported']\n",
    "Y=dfv['Transported']\n",
    "x = dfv.drop(['Transported','PassengerId'],axis=1)\n",
    "X=dft.drop(['Transported','PassengerId'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d755a8c",
   "metadata": {
    "papermill": {
     "duration": 0.006103,
     "end_time": "2024-03-08T04:03:08.727095",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.720992",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optuna HP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cf0056e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:08.743935Z",
     "iopub.status.busy": "2024-03-08T04:03:08.743572Z",
     "iopub.status.idle": "2024-03-08T04:03:45.658139Z",
     "shell.execute_reply": "2024-03-08T04:03:45.657292Z"
    },
    "papermill": {
     "duration": 36.924207,
     "end_time": "2024-03-08T04:03:45.659946",
     "exception": false,
     "start_time": "2024-03-08T04:03:08.735739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-08 04:03:08,778] A new study created in memory with name: no-name-cdbccf61-fba8-4f33-9450-128f22c32c23\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:08,841] Trial 0 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 2.0341797678305787e-07, 'max_depth': 6, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 1.7106485684639066e-08}. Best is trial 0 with value: 0.49095022624434387.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:08,857] Trial 1 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.1765349881902577e-06, 'max_depth': 4, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.00043940393637430453}. Best is trial 0 with value: 0.49095022624434387.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:08,898] Trial 2 finished with value: 0.6233031674208145 and parameters: {'booster': 'dart', 'gamma': 0.015354477228249572, 'max_depth': 80, 'n_estimators': 60, 'grow_policy': 'depthwise', 'learning_rate': 0.0015684227401751598}. Best is trial 2 with value: 0.6233031674208145.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:08,970] Trial 3 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 6.819944312435519e-05, 'max_depth': 100, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 2.4466255279437593e-08}. Best is trial 2 with value: 0.6233031674208145.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:08,986] Trial 4 finished with value: 0.49095022624434387 and parameters: {'booster': 'gblinear', 'gamma': 2.0924745119948768e-08, 'max_depth': 93, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 3.7623657983770455e-08}. Best is trial 2 with value: 0.6233031674208145.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:08] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,004] Trial 5 finished with value: 0.7782805429864253 and parameters: {'booster': 'gbtree', 'gamma': 0.05195954134243837, 'max_depth': 7, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.01118673152784846}. Best is trial 5 with value: 0.7782805429864253.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,071] Trial 6 finished with value: 0.7828054298642534 and parameters: {'booster': 'gbtree', 'gamma': 0.008345638225507816, 'max_depth': 87, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.007569140067336795}. Best is trial 6 with value: 0.7828054298642534.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,086] Trial 7 finished with value: 0.49095022624434387 and parameters: {'booster': 'gblinear', 'gamma': 2.896846838628345e-05, 'max_depth': 18, 'n_estimators': 17, 'grow_policy': 'depthwise', 'learning_rate': 2.4157868318086924e-06}. Best is trial 6 with value: 0.7828054298642534.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,159] Trial 8 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 0.0013875537351872172, 'max_depth': 100, 'n_estimators': 100, 'grow_policy': 'lossguide', 'learning_rate': 0.06653445042507619}. Best is trial 8 with value: 0.7952488687782805.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,173] Trial 9 finished with value: 0.5209276018099548 and parameters: {'booster': 'gblinear', 'gamma': 0.2332891827373457, 'max_depth': 71, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.0011154442697913231}. Best is trial 8 with value: 0.7952488687782805.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,222] Trial 10 finished with value: 0.7816742081447964 and parameters: {'booster': 'gbtree', 'gamma': 0.00018643857204895205, 'max_depth': 48, 'n_estimators': 98, 'grow_policy': 'depthwise', 'learning_rate': 0.8516299016191495}. Best is trial 8 with value: 0.7952488687782805.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,297] Trial 11 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.002436467839602903, 'max_depth': 61, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.14599238434185244}. Best is trial 11 with value: 0.7975113122171946.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,366] Trial 12 finished with value: 0.7782805429864253 and parameters: {'booster': 'gbtree', 'gamma': 0.0019208181599532342, 'max_depth': 54, 'n_estimators': 99, 'grow_policy': 'lossguide', 'learning_rate': 0.9631340333377504}. Best is trial 11 with value: 0.7975113122171946.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,439] Trial 13 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.0006299824977868644, 'max_depth': 60, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.07708591562023152}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,484] Trial 14 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.6575284685443955, 'max_depth': 55, 'n_estimators': 46, 'grow_policy': 'depthwise', 'learning_rate': 1.6283564680969925e-05}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,554] Trial 15 finished with value: 0.7975113122171946 and parameters: {'booster': 'dart', 'gamma': 5.028949429062968e-06, 'max_depth': 42, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.058669811305572556}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,632] Trial 16 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.0005074848280821275, 'max_depth': 67, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 4.681542124240374e-05}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,688] Trial 17 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 1.3927565302227567e-05, 'max_depth': 30, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.13574011272679767}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,781] Trial 18 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 9.612319895549275e-06, 'max_depth': 33, 'n_estimators': 1, 'grow_policy': 'depthwise', 'learning_rate': 1.2895336169696813e-06}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,858] Trial 19 finished with value: 0.7579185520361991 and parameters: {'booster': 'gblinear', 'gamma': 5.149270131723719e-07, 'max_depth': 30, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.009173705548265612}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,915] Trial 20 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 1.4248716560864057e-08, 'max_depth': 26, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.19450707245490045}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:09,968] Trial 21 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 1.753111121290947e-08, 'max_depth': 25, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.1641861562342434}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:09] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,033] Trial 22 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 1.461347529281896e-07, 'max_depth': 38, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.024714695329131942}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,112] Trial 23 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 3.878367623238917e-06, 'max_depth': 18, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.29619301848659146}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,182] Trial 24 finished with value: 0.7590497737556561 and parameters: {'booster': 'gbtree', 'gamma': 6.697638022222381e-08, 'max_depth': 20, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.0021981377440051086}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,248] Trial 25 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 3.063042390665597e-05, 'max_depth': 42, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.0356696899373494}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,295] Trial 26 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.00015289548823141236, 'max_depth': 49, 'n_estimators': 55, 'grow_policy': 'depthwise', 'learning_rate': 0.00025004105510267123}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,338] Trial 27 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 1.7465140150754512e-06, 'max_depth': 13, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.24765515526984333}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,403] Trial 28 finished with value: 0.7754524886877828 and parameters: {'booster': 'dart', 'gamma': 1.1493544092430815e-05, 'max_depth': 25, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 0.0035744913279322017}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,439] Trial 29 finished with value: 0.745475113122172 and parameters: {'booster': 'gblinear', 'gamma': 2.543994986264688e-07, 'max_depth': 36, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.022718461633322834}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,545] Trial 30 finished with value: 0.8031674208144797 and parameters: {'booster': 'dart', 'gamma': 5.024994780952411e-08, 'max_depth': 72, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.11477863685041528}. Best is trial 13 with value: 0.8037330316742082.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,613] Trial 31 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 2.154836715001132e-06, 'max_depth': 10, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.4209277951910637}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,647] Trial 32 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 8.015652010075179e-07, 'max_depth': 1, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.5094492386481855}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,688] Trial 33 finished with value: 0.7850678733031674 and parameters: {'booster': 'gbtree', 'gamma': 0.0005776855721552705, 'max_depth': 11, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.09020169056756953}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,737] Trial 34 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 4.841302803241232e-05, 'max_depth': 25, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.45080169565389133}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,784] Trial 35 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.6082796735439476e-06, 'max_depth': 10, 'n_estimators': 58, 'grow_policy': 'lossguide', 'learning_rate': 0.000512323244606129}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,849] Trial 36 finished with value: 0.795814479638009 and parameters: {'booster': 'gbtree', 'gamma': 0.008894538503432555, 'max_depth': 59, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.018106617139818145}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,887] Trial 37 finished with value: 0.705316742081448 and parameters: {'booster': 'gbtree', 'gamma': 4.4776473265502185e-08, 'max_depth': 5, 'n_estimators': 89, 'grow_policy': 'depthwise', 'learning_rate': 0.005763003512311188}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:10] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:10,984] Trial 38 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 1.4879299727748403e-05, 'max_depth': 80, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.051473410645395186}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,023] Trial 39 finished with value: 0.7895927601809954 and parameters: {'booster': 'gblinear', 'gamma': 9.245591574609057e-05, 'max_depth': 16, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.9320967703446964}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,078] Trial 40 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.0004343440586927916, 'max_depth': 22, 'n_estimators': 67, 'grow_policy': 'lossguide', 'learning_rate': 1.0589848428687508e-08}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,137] Trial 41 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 3.5142467286539605e-06, 'max_depth': 30, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.189235736948771}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,184] Trial 42 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 3.2385430087879784e-06, 'max_depth': 15, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.3197070094078141}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,226] Trial 43 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 4.094888312531932e-07, 'max_depth': 8, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 7.855775980446804e-08}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,261] Trial 44 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.3114800209713415e-07, 'max_depth': 1, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.09881749771290559}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,315] Trial 45 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 2.3166466689670454e-05, 'max_depth': 21, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.4170937973917038}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,366] Trial 46 finished with value: 0.7811085972850679 and parameters: {'booster': 'gbtree', 'gamma': 0.004267275893501892, 'max_depth': 46, 'n_estimators': 21, 'grow_policy': 'depthwise', 'learning_rate': 0.06073379713162201}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,425] Trial 47 finished with value: 0.794683257918552 and parameters: {'booster': 'gbtree', 'gamma': 6.482628000961497e-05, 'max_depth': 29, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.013594528474351834}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,467] Trial 48 finished with value: 0.5118778280542986 and parameters: {'booster': 'gblinear', 'gamma': 0.0814084435882784, 'max_depth': 65, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.0009394033275149478}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,531] Trial 49 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 4.588268596297064e-06, 'max_depth': 36, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.18858535158088005}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,577] Trial 50 finished with value: 0.793552036199095 and parameters: {'booster': 'gbtree', 'gamma': 0.00030809881949405083, 'max_depth': 17, 'n_estimators': 50, 'grow_policy': 'depthwise', 'learning_rate': 0.5653660908655894}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,622] Trial 51 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 2.8789959662403946e-06, 'max_depth': 15, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.29917125204359807}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,668] Trial 52 finished with value: 0.7816742081447964 and parameters: {'booster': 'gbtree', 'gamma': 8.928656612850768e-06, 'max_depth': 13, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.0395629197534662}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,709] Trial 53 finished with value: 0.7918552036199095 and parameters: {'booster': 'gbtree', 'gamma': 9.083362390860842e-07, 'max_depth': 7, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.9541701343451543}. Best is trial 31 with value: 0.8042986425339367.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,762] Trial 54 finished with value: 0.8065610859728507 and parameters: {'booster': 'gbtree', 'gamma': 6.136962231906721e-06, 'max_depth': 20, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.3165187202208539}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,819] Trial 55 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 0.0010298074831707126, 'max_depth': 22, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.11800702492052714}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,892] Trial 56 finished with value: 0.791289592760181 and parameters: {'booster': 'gbtree', 'gamma': 3.099735541532638e-05, 'max_depth': 55, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.006896494171320414}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:11,970] Trial 57 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 6.054141741503726e-06, 'max_depth': 41, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 7.677206879998455e-06}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:11] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,022] Trial 58 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 1.4843481013842724e-08, 'max_depth': 27, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.17551324771424193}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,061] Trial 59 finished with value: 0.7449095022624435 and parameters: {'booster': 'gblinear', 'gamma': 0.0002219334829437266, 'max_depth': 34, 'n_estimators': 37, 'grow_policy': 'depthwise', 'learning_rate': 0.02853673338082893}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,117] Trial 60 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 0.00013830531805161374, 'max_depth': 19, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.08651182885339954}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,167] Trial 61 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 2.0419500811299397e-06, 'max_depth': 13, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.31645758310063016}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,221] Trial 62 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.5207996102065612e-05, 'max_depth': 23, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.30256890345986814}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,276] Trial 63 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 5.65631844422292e-07, 'max_depth': 17, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.48518375531975416}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,316] Trial 64 finished with value: 0.753393665158371 and parameters: {'booster': 'gbtree', 'gamma': 6.70267608914821e-06, 'max_depth': 4, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.043264862470754305}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,378] Trial 65 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 2.457718579540021e-07, 'max_depth': 32, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.670524015943901}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,422] Trial 66 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.1593319997816816e-06, 'max_depth': 9, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.00010621617388454708}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,518] Trial 67 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 9.85753491632693e-08, 'max_depth': 74, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.13557122632196994}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,589] Trial 68 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 4.62217715915558e-05, 'max_depth': 51, 'n_estimators': 63, 'grow_policy': 'lossguide', 'learning_rate': 0.01361307659067719}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,646] Trial 69 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 2.6064568319386088e-08, 'max_depth': 27, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.06783023747985605}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,717] Trial 70 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 2.3692608362191517e-06, 'max_depth': 61, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 7.355095023205493e-07}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,824] Trial 71 finished with value: 0.8054298642533937 and parameters: {'booster': 'dart', 'gamma': 1.0479633981113656e-08, 'max_depth': 87, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.251524995680135}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:12,930] Trial 72 finished with value: 0.7952488687782805 and parameters: {'booster': 'dart', 'gamma': 1.111865645358631e-08, 'max_depth': 92, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.3031990434976055}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:12] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,037] Trial 73 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 2.2126829128025247e-08, 'max_depth': 85, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.16951032961537765}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,149] Trial 74 finished with value: 0.7754524886877828 and parameters: {'booster': 'dart', 'gamma': 0.0008773655552890495, 'max_depth': 97, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.8318001462987438}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,249] Trial 75 finished with value: 0.7997737556561086 and parameters: {'booster': 'dart', 'gamma': 6.777824832593359e-08, 'max_depth': 80, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.25241257820106316}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,288] Trial 76 finished with value: 0.7483031674208145 and parameters: {'booster': 'gblinear', 'gamma': 1.8792592882455985e-05, 'max_depth': 19, 'n_estimators': 28, 'grow_policy': 'depthwise', 'learning_rate': 0.08211337556778966}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,334] Trial 77 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 3.556451665996922e-07, 'max_depth': 11, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.4806234033523313}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,401] Trial 78 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 3.20343614887035e-08, 'max_depth': 24, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.020827315467725756}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,485] Trial 79 finished with value: 0.795814479638009 and parameters: {'booster': 'gbtree', 'gamma': 4.382401063660044e-06, 'max_depth': 75, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.04185003283950165}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,566] Trial 80 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 9.265636321592305e-06, 'max_depth': 67, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.12662442763299328}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,655] Trial 81 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 4.612700142758312e-08, 'max_depth': 83, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.12656003996568807}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,757] Trial 82 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 1.6262798331893237e-08, 'max_depth': 91, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.4113604553785702}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,857] Trial 83 finished with value: 0.8020361990950227 and parameters: {'booster': 'dart', 'gamma': 1.504354120053641e-07, 'max_depth': 74, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.0672194123460644}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:13,948] Trial 84 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 1.3998899787718507e-06, 'max_depth': 58, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.2257312755779654}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:13] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,030] Trial 85 finished with value: 0.7856334841628959 and parameters: {'booster': 'gbtree', 'gamma': 3.92924793079419e-08, 'max_depth': 64, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.7148691753634385}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,130] Trial 86 finished with value: 0.7720588235294118 and parameters: {'booster': 'dart', 'gamma': 6.451911304433703e-07, 'max_depth': 69, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.003810736897367007}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,184] Trial 87 finished with value: 0.7748868778280543 and parameters: {'booster': 'gbtree', 'gamma': 1.0050660113861348e-08, 'max_depth': 14, 'n_estimators': 28, 'grow_policy': 'depthwise', 'learning_rate': 0.03081497637467441}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,228] Trial 88 finished with value: 0.7528280542986425 and parameters: {'booster': 'gblinear', 'gamma': 0.0024810006673644026, 'max_depth': 44, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.10350599147278282}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,288] Trial 89 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 8.4717463648043e-08, 'max_depth': 19, 'n_estimators': 54, 'grow_policy': 'lossguide', 'learning_rate': 0.2116485524751312}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,388] Trial 90 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.00010875685168886082, 'max_depth': 96, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.34079834381785407}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,446] Trial 91 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 3.434713102032728e-05, 'max_depth': 24, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.5452519967182599}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,513] Trial 92 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 4.6107175654125194e-05, 'max_depth': 29, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.4249012261301985}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,603] Trial 93 finished with value: 0.7867647058823529 and parameters: {'booster': 'gbtree', 'gamma': 1.249178807680144e-05, 'max_depth': 77, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.9397475408391168}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,653] Trial 94 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 8.255867807754682e-05, 'max_depth': 16, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.14611057146639395}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,711] Trial 95 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 6.503897793199005e-06, 'max_depth': 21, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.21869830444257882}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,773] Trial 96 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 7.256719501194835e-06, 'max_depth': 21, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.051450905125721966}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,821] Trial 97 finished with value: 0.7845022624434389 and parameters: {'booster': 'gbtree', 'gamma': 3.2094909026970147e-06, 'max_depth': 11, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.08710958146043118}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:14,918] Trial 98 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 1.0040404239975257e-06, 'max_depth': 89, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.20478162440325173}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:14] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,024] Trial 99 finished with value: 0.7822398190045249 and parameters: {'booster': 'dart', 'gamma': 2.170333068573952e-06, 'max_depth': 86, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.6387949977176136}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,087] Trial 100 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 8.658890031106628e-07, 'max_depth': 90, 'n_estimators': 17, 'grow_policy': 'depthwise', 'learning_rate': 0.3240494674108769}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,131] Trial 101 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 3.3652455423986474e-06, 'max_depth': 6, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.1724387816578753}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,217] Trial 102 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 5.373929654956955e-06, 'max_depth': 95, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.23346996123175415}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,300] Trial 103 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 1.6912071103320439e-06, 'max_depth': 89, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.05918404061063548}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,379] Trial 104 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 2.02440828255267e-05, 'max_depth': 83, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.13241130359772565}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,477] Trial 105 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 2.0530782210102986e-08, 'max_depth': 99, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.10113875532919729}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,540] Trial 106 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 1.044126377648303e-06, 'max_depth': 26, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.20000191491666702}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,594] Trial 107 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 4.308628616589271e-07, 'max_depth': 13, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 1.826750453209379e-07}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,638] Trial 108 finished with value: 0.75 and parameters: {'booster': 'gblinear', 'gamma': 1.0960528027346482e-05, 'max_depth': 53, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.01737160132134181}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,697] Trial 109 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.029760755751581977, 'max_depth': 17, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.6099388917280503}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,766] Trial 110 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.04797467713474738, 'max_depth': 18, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.6297559455389155}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,826] Trial 111 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 0.06320265097969073, 'max_depth': 22, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.2993279833488893}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,871] Trial 112 finished with value: 0.7907239819004525 and parameters: {'booster': 'gbtree', 'gamma': 0.34676511212552047, 'max_depth': 4, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.43470959067636084}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:15,922] Trial 113 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 0.026084388475963817, 'max_depth': 15, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.21797642304775497}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:15] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,005] Trial 114 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 4.024767848677266e-06, 'max_depth': 88, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.3649532366886125}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,057] Trial 115 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 7.067037350108252e-06, 'max_depth': 9, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 2.1582210794013867e-05}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,117] Trial 116 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 0.010055203225155863, 'max_depth': 17, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.07263120816979844}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,178] Trial 117 finished with value: 0.7890271493212669 and parameters: {'booster': 'gbtree', 'gamma': 0.004604771618606809, 'max_depth': 20, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.9402271403786843}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,249] Trial 118 finished with value: 0.8031674208144797 and parameters: {'booster': 'dart', 'gamma': 0.6532799800285725, 'max_depth': 28, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.1567554864227589}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,325] Trial 119 finished with value: 0.793552036199095 and parameters: {'booster': 'gbtree', 'gamma': 2.5401349253969705e-06, 'max_depth': 39, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.5915042936438976}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,375] Trial 120 finished with value: 0.7833710407239819 and parameters: {'booster': 'gbtree', 'gamma': 3.21940812058151e-08, 'max_depth': 31, 'n_estimators': 14, 'grow_policy': 'depthwise', 'learning_rate': 0.03510533594874369}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,437] Trial 121 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 0.13925301822342576, 'max_depth': 22, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.2561711155069923}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,498] Trial 122 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.03195148623121952, 'max_depth': 25, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.36776656001043045}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,551] Trial 123 finished with value: 0.7867647058823529 and parameters: {'booster': 'gbtree', 'gamma': 0.07495770291585724, 'max_depth': 13, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.1047707136341748}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,612] Trial 124 finished with value: 0.795814479638009 and parameters: {'booster': 'gbtree', 'gamma': 1.5173127977725096e-05, 'max_depth': 23, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.2776454771575608}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,664] Trial 125 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 4.7741571338662953e-08, 'max_depth': 18, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.5403614636457683}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,760] Trial 126 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 0.09886857329474133, 'max_depth': 94, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.15635947948799978}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,841] Trial 127 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 1.3458426301292116e-08, 'max_depth': 34, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.23612507194966542}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,894] Trial 128 finished with value: 0.793552036199095 and parameters: {'booster': 'gbtree', 'gamma': 0.19452270380004094, 'max_depth': 15, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.053299039677620855}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,937] Trial 129 finished with value: 0.7845022624434389 and parameters: {'booster': 'gblinear', 'gamma': 1.2972408929142077e-06, 'max_depth': 72, 'n_estimators': 21, 'grow_policy': 'lossguide', 'learning_rate': 0.717650524733925}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:16] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:16,994] Trial 130 finished with value: 0.8059954751131222 and parameters: {'booster': 'gbtree', 'gamma': 1.9548048904558975e-07, 'max_depth': 21, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.33052909674471775}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,054] Trial 131 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 1.1634277007361778e-07, 'max_depth': 21, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.38421311952323633}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,112] Trial 132 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 1.8480290909949382e-07, 'max_depth': 20, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.11131570539094769}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,174] Trial 133 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 2.293890953977033e-08, 'max_depth': 24, 'n_estimators': 23, 'grow_policy': 'lossguide', 'learning_rate': 0.2786655088717938}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,223] Trial 134 finished with value: 0.792420814479638 and parameters: {'booster': 'gbtree', 'gamma': 2.935267293634143e-07, 'max_depth': 12, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.9987352013971262}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,300] Trial 135 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 5.864572559639028e-08, 'max_depth': 58, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.16620366311240486}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,361] Trial 136 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.016307089745284654, 'max_depth': 16, 'n_estimators': 19, 'grow_policy': 'lossguide', 'learning_rate': 0.44219587085504114}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,434] Trial 137 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 6.682911857274761e-07, 'max_depth': 27, 'n_estimators': 16, 'grow_policy': 'lossguide', 'learning_rate': 0.09452739713664375}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,490] Trial 138 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 4.241336717080057e-06, 'max_depth': 19, 'n_estimators': 61, 'grow_policy': 'lossguide', 'learning_rate': 0.32327431340947355}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,543] Trial 139 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 4.579352076502613e-06, 'max_depth': 10, 'n_estimators': 60, 'grow_policy': 'lossguide', 'learning_rate': 0.6112377151527422}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,637] Trial 140 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 2.122185592125442e-06, 'max_depth': 79, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.17430777320042173}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,697] Trial 141 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 7.900747331423632e-06, 'max_depth': 22, 'n_estimators': 68, 'grow_policy': 'lossguide', 'learning_rate': 0.3125035946002589}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,757] Trial 142 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 3.1906704872784252e-06, 'max_depth': 18, 'n_estimators': 62, 'grow_policy': 'lossguide', 'learning_rate': 0.24407249324610938}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,833] Trial 143 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.6942357698416317e-08, 'max_depth': 48, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.00012770096812361644}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,893] Trial 144 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 5.096733010588627e-06, 'max_depth': 20, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.4278980318335582}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:17,942] Trial 145 finished with value: 0.7788461538461539 and parameters: {'booster': 'gbtree', 'gamma': 1.653914337535206e-06, 'max_depth': 7, 'n_estimators': 55, 'grow_policy': 'depthwise', 'learning_rate': 0.13334291232855386}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:17] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,002] Trial 146 finished with value: 0.7895927601809954 and parameters: {'booster': 'gbtree', 'gamma': 2.5165119954158525e-05, 'max_depth': 16, 'n_estimators': 22, 'grow_policy': 'lossguide', 'learning_rate': 0.06282629711171879}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,077] Trial 147 finished with value: 0.8031674208144797 and parameters: {'booster': 'dart', 'gamma': 6.186748612232592e-06, 'max_depth': 25, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.19237971596420353}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,154] Trial 148 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 1.0331492125340706e-05, 'max_depth': 64, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.3216599450466647}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,255] Trial 149 finished with value: 0.7816742081447964 and parameters: {'booster': 'gbtree', 'gamma': 2.451006007908629e-06, 'max_depth': 84, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.6829875866635252}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,313] Trial 150 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 8.008381977201554e-08, 'max_depth': 22, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.08182554203389675}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,393] Trial 151 finished with value: 0.7980769230769231 and parameters: {'booster': 'dart', 'gamma': 0.9418761526920173, 'max_depth': 28, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.1812953036545694}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,454] Trial 152 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 0.4078060063366658, 'max_depth': 18, 'n_estimators': 20, 'grow_policy': 'lossguide', 'learning_rate': 0.14492657486396993}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,531] Trial 153 finished with value: 0.8020361990950227 and parameters: {'booster': 'dart', 'gamma': 0.0018825491592605133, 'max_depth': 26, 'n_estimators': 17, 'grow_policy': 'lossguide', 'learning_rate': 0.48906259658634454}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,609] Trial 154 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 3.18605774811741e-08, 'max_depth': 29, 'n_estimators': 24, 'grow_policy': 'lossguide', 'learning_rate': 0.11882425766960915}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,680] Trial 155 finished with value: 0.8026018099547512 and parameters: {'booster': 'dart', 'gamma': 3.5207615954636107e-06, 'max_depth': 23, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.24289192841654214}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,758] Trial 156 finished with value: 0.8048642533936652 and parameters: {'booster': 'dart', 'gamma': 0.5828455571889201, 'max_depth': 31, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.3838354448182459}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,838] Trial 157 finished with value: 0.505656108597285 and parameters: {'booster': 'dart', 'gamma': 1.196138281335115e-06, 'max_depth': 31, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.0013931303368832177}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,883] Trial 158 finished with value: 0.7867647058823529 and parameters: {'booster': 'gblinear', 'gamma': 0.006197038158675097, 'max_depth': 20, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.34133672841536566}. Best is trial 54 with value: 0.8065610859728507.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:18,946] Trial 159 finished with value: 0.8076923076923077 and parameters: {'booster': 'gbtree', 'gamma': 0.2845691187537245, 'max_depth': 35, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4904502810481099}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:18] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,017] Trial 160 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.39800842234099576, 'max_depth': 35, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.7793105403924242}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,092] Trial 161 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 0.24377749937074997, 'max_depth': 38, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.5060812142665246}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,162] Trial 162 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.6029022789525428, 'max_depth': 33, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.3404490086794116}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,223] Trial 163 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 0.1706452411414045, 'max_depth': 24, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.5592071527398802}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,293] Trial 164 finished with value: 0.8071266968325792 and parameters: {'booster': 'gbtree', 'gamma': 0.3128657135944654, 'max_depth': 30, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.21470160201132377}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,360] Trial 165 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 0.8364989850524822, 'max_depth': 32, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.24069640174937598}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,429] Trial 166 finished with value: 0.7878959276018099 and parameters: {'booster': 'gbtree', 'gamma': 0.5501122185922388, 'max_depth': 32, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.9775567360765935}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,503] Trial 167 finished with value: 0.8048642533936652 and parameters: {'booster': 'dart', 'gamma': 0.8522432308456234, 'max_depth': 29, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.21498005480681937}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,573] Trial 168 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.9857391083199324, 'max_depth': 37, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.4369191004002761}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,641] Trial 169 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 0.27432894285221554, 'max_depth': 31, 'n_estimators': 7, 'grow_policy': 'depthwise', 'learning_rate': 0.21615029265631575}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,719] Trial 170 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.44872848436225093, 'max_depth': 28, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.28832555674145255}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,866] Trial 171 finished with value: 0.8026018099547512 and parameters: {'booster': 'dart', 'gamma': 0.8351430461959891, 'max_depth': 40, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.12283450213977497}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:19,941] Trial 172 finished with value: 0.8042986425339367 and parameters: {'booster': 'dart', 'gamma': 0.37971583027943984, 'max_depth': 33, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.18709165286220486}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:19] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,020] Trial 173 finished with value: 0.8037330316742082 and parameters: {'booster': 'dart', 'gamma': 0.27423100594920824, 'max_depth': 35, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.182888364471699}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,100] Trial 174 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.6556188323312523, 'max_depth': 30, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4058210317974286}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,178] Trial 175 finished with value: 0.7975113122171946 and parameters: {'booster': 'dart', 'gamma': 0.34651247798301943, 'max_depth': 33, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.6890667213565341}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,243] Trial 176 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 0.15398638992123326, 'max_depth': 29, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.2692554769199618}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,311] Trial 177 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.12408108661167884, 'max_depth': 29, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 2.4621999832985897e-06}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,393] Trial 178 finished with value: 0.7941176470588235 and parameters: {'booster': 'dart', 'gamma': 0.20457569856401703, 'max_depth': 33, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.09055918915414234}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,458] Trial 179 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 0.4971317947264804, 'max_depth': 36, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.25790691520278924}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,524] Trial 180 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.737344965245248, 'max_depth': 31, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.1522096180402331}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,590] Trial 181 finished with value: 0.8059954751131222 and parameters: {'booster': 'gbtree', 'gamma': 0.3339741013581652, 'max_depth': 26, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.3739927799568032}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,655] Trial 182 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 0.37646394290855484, 'max_depth': 27, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.22985733254074556}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,719] Trial 183 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 0.246146256313064, 'max_depth': 26, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.3903013909769417}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,786] Trial 184 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 0.11471533734522313, 'max_depth': 26, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4075039565089056}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,851] Trial 185 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.2813180405764296, 'max_depth': 30, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.3332866030017757}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,913] Trial 186 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 0.49754246664800017, 'max_depth': 26, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.5026932637407345}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:20] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:20,982] Trial 187 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.18363495838687713, 'max_depth': 26, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.5342838432583599}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,047] Trial 188 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.6292227460709823, 'max_depth': 28, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.2714575038292177}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,121] Trial 189 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.27257456586470985, 'max_depth': 32, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.49353553574199593}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,204] Trial 190 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.14292910417297958, 'max_depth': 29, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.15282657770177746}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,270] Trial 191 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.9898545705992606, 'max_depth': 24, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.36433260877398704}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,436] Trial 192 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.46413012931893366, 'max_depth': 34, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.00041845038697604854}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,497] Trial 193 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 0.4928482069728181, 'max_depth': 26, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.25049186646928384}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,566] Trial 194 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 0.3466448099210819, 'max_depth': 30, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.7643756231142751}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,633] Trial 195 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 0.7075162860488187, 'max_depth': 24, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.17698246577841534}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,716] Trial 196 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.19407530654779764, 'max_depth': 43, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.42232691471964146}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,785] Trial 197 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 0.2621315837907401, 'max_depth': 28, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.11115563887628094}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,832] Trial 198 finished with value: 0.7861990950226244 and parameters: {'booster': 'gblinear', 'gamma': 0.5308558039050841, 'max_depth': 32, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.30220590055865443}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,896] Trial 199 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 0.32629120173754395, 'max_depth': 26, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.7389843142246904}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:21] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:21,964] Trial 200 finished with value: 0.7850678733031674 and parameters: {'booster': 'dart', 'gamma': 1.088399391615921e-08, 'max_depth': 36, 'n_estimators': 40, 'grow_policy': 'depthwise', 'learning_rate': 0.1918247602320957}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,041] Trial 201 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 3.2797332074830286e-06, 'max_depth': 45, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.22688882433842647}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,111] Trial 202 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 1.7069895977972094e-06, 'max_depth': 30, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.3937334814148684}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,170] Trial 203 finished with value: 0.7929864253393665 and parameters: {'booster': 'gbtree', 'gamma': 0.00023661017754592983, 'max_depth': 14, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.14040311272130174}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,269] Trial 204 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 4.653044527694573e-06, 'max_depth': 91, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.2899612684226701}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,336] Trial 205 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.6259955048427356, 'max_depth': 23, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.5708618929378027}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,399] Trial 206 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 2.343650696607377e-06, 'max_depth': 19, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.21185001957834668}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,501] Trial 207 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.0005824668185134507, 'max_depth': 88, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.07863474970891059}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,566] Trial 208 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.971379020553732, 'max_depth': 27, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.35838869168926696}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,641] Trial 209 finished with value: 0.7975113122171946 and parameters: {'booster': 'dart', 'gamma': 0.43060289328969464, 'max_depth': 25, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.5374755615917584}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,707] Trial 210 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 0.09097115607841201, 'max_depth': 21, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.1256566182648996}. Best is trial 159 with value: 0.8076923076923077.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,767] Trial 211 finished with value: 0.8088235294117647 and parameters: {'booster': 'gbtree', 'gamma': 0.055016150755537445, 'max_depth': 17, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.5805596479393171}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,829] Trial 212 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 0.15985649465905316, 'max_depth': 19, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.2975493195302607}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,892] Trial 213 finished with value: 0.8088235294117647 and parameters: {'booster': 'gbtree', 'gamma': 0.18305495797519644, 'max_depth': 17, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.47320194104120644}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:22,957] Trial 214 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 0.04853636411567539, 'max_depth': 18, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.7364469748150787}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:22] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,020] Trial 215 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 0.15006879271872237, 'max_depth': 20, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.47814494458767454}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,089] Trial 216 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 0.1794763531839045, 'max_depth': 24, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.3145887982500697}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,154] Trial 217 finished with value: 0.7805429864253394 and parameters: {'booster': 'gbtree', 'gamma': 0.08872557036159577, 'max_depth': 22, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.9863603710300938}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,215] Trial 218 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 0.25506023041842574, 'max_depth': 18, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4901032068493002}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,285] Trial 219 finished with value: 0.792420814479638 and parameters: {'booster': 'gbtree', 'gamma': 0.19546808412530353, 'max_depth': 34, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.5779881397030595}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,354] Trial 220 finished with value: 0.8071266968325792 and parameters: {'booster': 'dart', 'gamma': 0.22499763074289375, 'max_depth': 16, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4176875192990851}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,430] Trial 221 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.24296643902794626, 'max_depth': 17, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.45958330649656703}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,498] Trial 222 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.32327859641621937, 'max_depth': 12, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.3353969642389195}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,569] Trial 223 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 0.15301414385834392, 'max_depth': 14, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.24467992424637797}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,633] Trial 224 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 0.11619934224989045, 'max_depth': 15, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.6478216452162792}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,709] Trial 225 finished with value: 0.8042986425339367 and parameters: {'booster': 'dart', 'gamma': 0.25643470203652863, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.4137955810735712}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,787] Trial 226 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.23069020152546615, 'max_depth': 19, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.46304726605345187}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,865] Trial 227 finished with value: 0.8037330316742082 and parameters: {'booster': 'dart', 'gamma': 0.3751222670420616, 'max_depth': 16, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.377410786503805}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:23,940] Trial 228 finished with value: 0.795814479638009 and parameters: {'booster': 'dart', 'gamma': 0.5194169415790891, 'max_depth': 17, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.7878909386959251}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:23] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,026] Trial 229 finished with value: 0.8082579185520362 and parameters: {'booster': 'dart', 'gamma': 0.2579433114460621, 'max_depth': 31, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.24896767507556955}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,103] Trial 230 finished with value: 0.795814479638009 and parameters: {'booster': 'dart', 'gamma': 0.06719799699857, 'max_depth': 19, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.5699398081937669}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,180] Trial 231 finished with value: 0.8037330316742082 and parameters: {'booster': 'dart', 'gamma': 0.2570198662384497, 'max_depth': 32, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.25669940215071635}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,257] Trial 232 finished with value: 0.8042986425339367 and parameters: {'booster': 'dart', 'gamma': 0.1355844725425451, 'max_depth': 30, 'n_estimators': 82, 'grow_policy': 'lossguide', 'learning_rate': 0.35162275294395706}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,342] Trial 233 finished with value: 0.8042986425339367 and parameters: {'booster': 'dart', 'gamma': 0.11735296155888769, 'max_depth': 30, 'n_estimators': 97, 'grow_policy': 'lossguide', 'learning_rate': 0.38054855335782517}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,428] Trial 234 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 0.11042170167902633, 'max_depth': 29, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.39338773351694856}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,515] Trial 235 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 0.14937633622960475, 'max_depth': 31, 'n_estimators': 93, 'grow_policy': 'lossguide', 'learning_rate': 0.31017109377689267}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,591] Trial 236 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.22165818211628574, 'max_depth': 28, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.469162610968371}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,665] Trial 237 finished with value: 0.7890271493212669 and parameters: {'booster': 'dart', 'gamma': 0.32865655487022566, 'max_depth': 33, 'n_estimators': 89, 'grow_policy': 'lossguide', 'learning_rate': 0.684524102149643}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,747] Trial 238 finished with value: 0.7771493212669683 and parameters: {'booster': 'dart', 'gamma': 0.07833077921216525, 'max_depth': 30, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.9792010198127984}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,819] Trial 239 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.13165272555569238, 'max_depth': 20, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.21396265141199639}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,885] Trial 240 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 0.19562934396953793, 'max_depth': 22, 'n_estimators': 95, 'grow_policy': 'lossguide', 'learning_rate': 0.334929863380331}. Best is trial 211 with value: 0.8088235294117647.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:24,972] Trial 241 finished with value: 0.8099547511312217 and parameters: {'booster': 'dart', 'gamma': 0.3742112460478382, 'max_depth': 32, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.42156772358972777}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,059] Trial 242 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 0.4034093294364918, 'max_depth': 35, 'n_estimators': 92, 'grow_policy': 'lossguide', 'learning_rate': 0.4413974228716774}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,149] Trial 243 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.27503653784603443, 'max_depth': 32, 'n_estimators': 88, 'grow_policy': 'lossguide', 'learning_rate': 0.5530258460767374}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,238] Trial 244 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.6602895559192188, 'max_depth': 31, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.306740919417777}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,323] Trial 245 finished with value: 0.7975113122171946 and parameters: {'booster': 'dart', 'gamma': 0.424709813993285, 'max_depth': 28, 'n_estimators': 66, 'grow_policy': 'lossguide', 'learning_rate': 0.2261049148370843}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,412] Trial 246 finished with value: 0.8071266968325792 and parameters: {'booster': 'dart', 'gamma': 0.1779577413989696, 'max_depth': 38, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.4148652537228925}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,496] Trial 247 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.19860792690479767, 'max_depth': 34, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 3.103821582090939e-08}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,588] Trial 248 finished with value: 0.8003393665158371 and parameters: {'booster': 'dart', 'gamma': 0.31142041425378475, 'max_depth': 38, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.6335926359907986}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,663] Trial 249 finished with value: 0.7969457013574661 and parameters: {'booster': 'dart', 'gamma': 0.554357132545069, 'max_depth': 35, 'n_estimators': 82, 'grow_policy': 'depthwise', 'learning_rate': 0.27695107574993516}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,736] Trial 250 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 0.15700794369445578, 'max_depth': 16, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.1870284492896157}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,815] Trial 251 finished with value: 0.8031674208144797 and parameters: {'booster': 'dart', 'gamma': 0.26759004017461724, 'max_depth': 18, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.4518038212046634}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,904] Trial 252 finished with value: 0.7890271493212669 and parameters: {'booster': 'dart', 'gamma': 0.3713202435800513, 'max_depth': 37, 'n_estimators': 84, 'grow_policy': 'lossguide', 'learning_rate': 0.6923846442663252}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:25] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:25,990] Trial 253 finished with value: 0.7997737556561086 and parameters: {'booster': 'dart', 'gamma': 0.7045251654132721, 'max_depth': 32, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.36848653715838203}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,044] Trial 254 finished with value: 0.7839366515837104 and parameters: {'booster': 'gblinear', 'gamma': 0.2130879658911057, 'max_depth': 27, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.2759121128105504}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,120] Trial 255 finished with value: 0.7969457013574661 and parameters: {'booster': 'dart', 'gamma': 0.4389915351004524, 'max_depth': 14, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.5003549253973976}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,191] Trial 256 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.16618143838710478, 'max_depth': 21, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.17711130485056173}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,277] Trial 257 finished with value: 0.8026018099547512 and parameters: {'booster': 'dart', 'gamma': 0.7315411922348648, 'max_depth': 33, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.26515488577229934}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,338] Trial 258 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.2751317779846696, 'max_depth': 1, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.9814991575509336}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,410] Trial 259 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.10048792776053786, 'max_depth': 25, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.530905799270563}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,480] Trial 260 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 0.4964005264528812, 'max_depth': 29, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.37654814904012807}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,554] Trial 261 finished with value: 0.8020361990950227 and parameters: {'booster': 'dart', 'gamma': 0.34998504940682335, 'max_depth': 18, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.19432617044203687}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,618] Trial 262 finished with value: 0.7918552036199095 and parameters: {'booster': 'gbtree', 'gamma': 0.9968346593797078, 'max_depth': 21, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.6238370938337525}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,687] Trial 263 finished with value: 0.7980769230769231 and parameters: {'booster': 'dart', 'gamma': 0.20760046183591294, 'max_depth': 11, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.35002934689022897}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,756] Trial 264 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 0.1397853869497204, 'max_depth': 23, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.2194738926486547}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,837] Trial 265 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 0.052646474450398315, 'max_depth': 36, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.44706846020460567}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,927] Trial 266 finished with value: 0.7890271493212669 and parameters: {'booster': 'dart', 'gamma': 0.5562508622234523, 'max_depth': 41, 'n_estimators': 83, 'grow_policy': 'lossguide', 'learning_rate': 0.7166388647088585}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:26] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:26,987] Trial 267 finished with value: 0.7437782805429864 and parameters: {'booster': 'gbtree', 'gamma': 0.28965547915924567, 'max_depth': 16, 'n_estimators': 1, 'grow_policy': 'depthwise', 'learning_rate': 0.002994171974889482}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,060] Trial 268 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 0.36787578656914255, 'max_depth': 31, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.3068249514884202}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,116] Trial 269 finished with value: 0.7664027149321267 and parameters: {'booster': 'gblinear', 'gamma': 0.22290772618021512, 'max_depth': 27, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.168567363510626}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,201] Trial 270 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.16352299427297226, 'max_depth': 34, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.46436829196245477}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,259] Trial 271 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 0.09614624478595157, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.2536915213542494}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,326] Trial 272 finished with value: 0.792420814479638 and parameters: {'booster': 'gbtree', 'gamma': 0.4636527397769727, 'max_depth': 25, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.6666210447354867}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,400] Trial 273 finished with value: 0.7969457013574661 and parameters: {'booster': 'dart', 'gamma': 0.7311787628230796, 'max_depth': 29, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.1437741804496138}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,471] Trial 274 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 0.2547767634889419, 'max_depth': 39, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.3693637058820943}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,551] Trial 275 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.34535177399253775, 'max_depth': 30, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 7.577972323058625e-08}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,616] Trial 276 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 0.14572515613807016, 'max_depth': 15, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.28668304031246095}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,680] Trial 277 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 0.5301425320003568, 'max_depth': 9, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.5736242153166347}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,751] Trial 278 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.21531900291536404, 'max_depth': 20, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 4.976510677470559e-05}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,825] Trial 279 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 0.07365790915880241, 'max_depth': 27, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.2268176981201473}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,912] Trial 280 finished with value: 0.8065610859728507 and parameters: {'booster': 'dart', 'gamma': 1.5011539746302924e-07, 'max_depth': 32, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.4349224962184947}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:27] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:27,986] Trial 281 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 3.457808033583382e-07, 'max_depth': 34, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.8254170262177827}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:28,089] Trial 282 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 1.9215977870484469e-07, 'max_depth': 32, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.4260270876036675}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:28,519] Trial 283 finished with value: 0.7952488687782805 and parameters: {'booster': 'dart', 'gamma': 5.584534711075622e-07, 'max_depth': 52, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.150989409255423}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:28] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,003] Trial 284 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 0.6988654970240525, 'max_depth': 17, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.5009082722960344}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,085] Trial 285 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 1.2118323729327133e-07, 'max_depth': 22, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.2569986332720313}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,164] Trial 286 finished with value: 0.7890271493212669 and parameters: {'booster': 'gbtree', 'gamma': 0.39050569260666845, 'max_depth': 37, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.7744263328328533}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,227] Trial 287 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 0.5039286933378327, 'max_depth': 23, 'n_estimators': 7, 'grow_policy': 'depthwise', 'learning_rate': 0.37774225030429404}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,301] Trial 288 finished with value: 0.8048642533936652 and parameters: {'booster': 'dart', 'gamma': 0.2820188382639355, 'max_depth': 13, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.1917874293617957}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,361] Trial 289 finished with value: 0.7918552036199095 and parameters: {'booster': 'gbtree', 'gamma': 0.32238398965972137, 'max_depth': 12, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.13023818891214797}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,437] Trial 290 finished with value: 0.7952488687782805 and parameters: {'booster': 'dart', 'gamma': 0.95204287253382, 'max_depth': 13, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 0.1861657155477641}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,496] Trial 291 finished with value: 0.7788461538461539 and parameters: {'booster': 'gblinear', 'gamma': 0.6341582333399046, 'max_depth': 11, 'n_estimators': 15, 'grow_policy': 'lossguide', 'learning_rate': 0.23068948018627045}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,575] Trial 292 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 0.4316805583038678, 'max_depth': 32, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.11762708765060188}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,649] Trial 293 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.20327585775649176, 'max_depth': 8, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 4.438478045956523e-07}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,727] Trial 294 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 0.36835737325575846, 'max_depth': 14, 'n_estimators': 14, 'grow_policy': 'lossguide', 'learning_rate': 0.2952218054603049}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,813] Trial 295 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 0.2584824371218372, 'max_depth': 28, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.17097628129540296}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,924] Trial 296 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 2.4294517700883923e-07, 'max_depth': 35, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 5.363732896707207e-06}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:29] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:29,995] Trial 297 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 8.697787277338605e-08, 'max_depth': 16, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.4803333415203221}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,061] Trial 298 finished with value: 0.7839366515837104 and parameters: {'booster': 'gbtree', 'gamma': 7.523709857511722e-08, 'max_depth': 15, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.989115253149295}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,145] Trial 299 finished with value: 0.8009049773755657 and parameters: {'booster': 'dart', 'gamma': 1.2142591788277788e-07, 'max_depth': 13, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.5916881215550454}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,228] Trial 300 finished with value: 0.8099547511312217 and parameters: {'booster': 'gbtree', 'gamma': 1.6823070292733116e-07, 'max_depth': 33, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.5371412924037636}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,328] Trial 301 finished with value: 0.8059954751131222 and parameters: {'booster': 'dart', 'gamma': 1.9171796101260773e-07, 'max_depth': 34, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.6020547727786659}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,410] Trial 302 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.7136060493177678e-07, 'max_depth': 36, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.0008516731821996909}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,486] Trial 303 finished with value: 0.7986425339366516 and parameters: {'booster': 'dart', 'gamma': 2.576174999257684e-07, 'max_depth': 10, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.7225466418274357}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,554] Trial 304 finished with value: 0.8059954751131222 and parameters: {'booster': 'gbtree', 'gamma': 2.570004317902656e-07, 'max_depth': 16, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.532246957606927}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,651] Trial 305 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.5437660991589312e-07, 'max_depth': 56, 'n_estimators': 2, 'grow_policy': 'lossguide', 'learning_rate': 0.585574831766053}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,731] Trial 306 finished with value: 0.792420814479638 and parameters: {'booster': 'dart', 'gamma': 8.066379891159579e-08, 'max_depth': 16, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.9035524654641728}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,793] Trial 307 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 5.072162023509846e-07, 'max_depth': 33, 'n_estimators': 8, 'grow_policy': 'depthwise', 'learning_rate': 0.5270329166008436}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,864] Trial 308 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 3.000638641267204e-07, 'max_depth': 14, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.49880466825414954}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:30] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:30,959] Trial 309 finished with value: 0.7867647058823529 and parameters: {'booster': 'dart', 'gamma': 2.0600426683340777e-07, 'max_depth': 50, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.6525287661083267}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,029] Trial 310 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 1.1842041499451483e-07, 'max_depth': 17, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.43139612519804477}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,122] Trial 311 finished with value: 0.7850678733031674 and parameters: {'booster': 'dart', 'gamma': 3.867342577325626e-07, 'max_depth': 37, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.9705638971684233}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,198] Trial 312 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 4.8840620657398455e-08, 'max_depth': 34, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.6655605060753826}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,273] Trial 313 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.9538864460029589e-07, 'max_depth': 30, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.4050114031988299}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,351] Trial 314 finished with value: 0.7941176470588235 and parameters: {'booster': 'dart', 'gamma': 2.556676831761283e-07, 'max_depth': 12, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.5164206667474557}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,410] Trial 315 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 8.950066023875953e-08, 'max_depth': 6, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.3825238041191196}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,466] Trial 316 finished with value: 0.7850678733031674 and parameters: {'booster': 'gblinear', 'gamma': 1.3033676606220203e-07, 'max_depth': 32, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.6603687031242284}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,580] Trial 317 finished with value: 0.8037330316742082 and parameters: {'booster': 'dart', 'gamma': 1.5924577899116115e-07, 'max_depth': 62, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.3318651290716082}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,645] Trial 318 finished with value: 0.8088235294117647 and parameters: {'booster': 'gbtree', 'gamma': 6.245855448312957e-08, 'max_depth': 16, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.4853775951383042}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,710] Trial 319 finished with value: 0.790158371040724 and parameters: {'booster': 'gbtree', 'gamma': 3.9097684125171414e-08, 'max_depth': 16, 'n_estimators': 12, 'grow_policy': 'lossguide', 'learning_rate': 0.9453885420634203}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,790] Trial 320 finished with value: 0.8065610859728507 and parameters: {'booster': 'dart', 'gamma': 9.257664106864531e-08, 'max_depth': 15, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.509424043821987}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,859] Trial 321 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 9.443723237561374e-08, 'max_depth': 17, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.5366739119356975}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:31,930] Trial 322 finished with value: 0.8065610859728507 and parameters: {'booster': 'gbtree', 'gamma': 9.728482978143217e-08, 'max_depth': 18, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.6138989491840584}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:31] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,003] Trial 323 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 5.345636313192421e-08, 'max_depth': 17, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.7020533767163578}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,084] Trial 324 finished with value: 0.7788461538461539 and parameters: {'booster': 'gbtree', 'gamma': 6.728193049040862e-08, 'max_depth': 18, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.9812942361054068}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,156] Trial 325 finished with value: 0.8088235294117647 and parameters: {'booster': 'gbtree', 'gamma': 1.1317087989290623e-07, 'max_depth': 16, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.55564302583158}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,222] Trial 326 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 9.506068885158814e-08, 'max_depth': 15, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.7099093197719404}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,296] Trial 327 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 1.401021484368616e-07, 'max_depth': 20, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.46468142622822933}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,363] Trial 328 finished with value: 0.8071266968325792 and parameters: {'booster': 'gbtree', 'gamma': 6.119682800603139e-08, 'max_depth': 16, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.5677794610780776}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,423] Trial 329 finished with value: 0.795814479638009 and parameters: {'booster': 'gbtree', 'gamma': 5.908227435709244e-08, 'max_depth': 15, 'n_estimators': 41, 'grow_policy': 'depthwise', 'learning_rate': 0.61411101228601}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,497] Trial 330 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 6.283969811749757e-08, 'max_depth': 21, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.7510975795814148}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,568] Trial 331 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 4.209090029436278e-08, 'max_depth': 18, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.5333136274340541}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,655] Trial 332 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 1.5190630342981742e-07, 'max_depth': 39, 'n_estimators': 28, 'grow_policy': 'lossguide', 'learning_rate': 0.354918656214456}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,722] Trial 333 finished with value: 0.7839366515837104 and parameters: {'booster': 'gbtree', 'gamma': 1.0921131359464468e-07, 'max_depth': 14, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.7483676631161958}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,795] Trial 334 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 3.4058425454065835e-08, 'max_depth': 19, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.4258147764564843}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,887] Trial 335 finished with value: 0.7811085972850679 and parameters: {'booster': 'gbtree', 'gamma': 2.959845203307975e-07, 'max_depth': 48, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.9624680270903933}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:32,955] Trial 336 finished with value: 0.8054298642533937 and parameters: {'booster': 'gbtree', 'gamma': 1.6091988763767489e-07, 'max_depth': 16, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.3133509049871341}. Best is trial 241 with value: 0.8099547511312217.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:32] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,022] Trial 337 finished with value: 0.8144796380090498 and parameters: {'booster': 'gbtree', 'gamma': 1.7543390994830197e-08, 'max_depth': 18, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.5683210778955603}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,092] Trial 338 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.4947000080305134e-08, 'max_depth': 21, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.00020011933025096106}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,165] Trial 339 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.5044519081220102e-08, 'max_depth': 24, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.6250384437067601}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,262] Trial 340 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 2.4278529060698967e-08, 'max_depth': 68, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.2951518776127888}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,325] Trial 341 finished with value: 0.7878959276018099 and parameters: {'booster': 'gbtree', 'gamma': 3.074175660953939e-08, 'max_depth': 14, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.9941421421417292}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,391] Trial 342 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.825688988973757e-08, 'max_depth': 19, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.4630320472991476}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,467] Trial 343 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 2.3286830727125427e-07, 'max_depth': 35, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.636176517450066}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,532] Trial 344 finished with value: 0.7811085972850679 and parameters: {'booster': 'gbtree', 'gamma': 7.151923317064367e-08, 'max_depth': 17, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.00835988925440927}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,591] Trial 345 finished with value: 0.7867647058823529 and parameters: {'booster': 'gblinear', 'gamma': 1.0632938269937001e-08, 'max_depth': 12, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.37508870718175275}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,658] Trial 346 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 1.251378366786126e-07, 'max_depth': 22, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.26615050529707407}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,730] Trial 347 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 2.3078330264767967e-08, 'max_depth': 15, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.5341933198711414}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,800] Trial 348 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.9769325726912995e-07, 'max_depth': 18, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.3628509639224239}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,875] Trial 349 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 4.747230013593497e-08, 'max_depth': 26, 'n_estimators': 26, 'grow_policy': 'lossguide', 'learning_rate': 0.5747878287647616}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:33,949] Trial 350 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 9.403874404928989e-08, 'max_depth': 20, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.27849481855375935}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:33] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,019] Trial 351 finished with value: 0.7907239819004525 and parameters: {'booster': 'gbtree', 'gamma': 1.075680964299338e-07, 'max_depth': 36, 'n_estimators': 41, 'grow_policy': 'depthwise', 'learning_rate': 0.6984754902339376}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,105] Trial 352 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 3.450584704283464e-07, 'max_depth': 33, 'n_estimators': 55, 'grow_policy': 'lossguide', 'learning_rate': 0.3794847150735894}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,222] Trial 353 finished with value: 0.7731900452488688 and parameters: {'booster': 'gbtree', 'gamma': 6.07951079373417e-08, 'max_depth': 100, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.9639804366823901}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,311] Trial 354 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 1.0223769148808707e-08, 'max_depth': 42, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.4691751107133053}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,376] Trial 355 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.6680406276909536e-07, 'max_depth': 16, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.24001950194434682}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,448] Trial 356 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 8.136165624980809e-08, 'max_depth': 24, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.6972557103733686}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,517] Trial 357 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.018161136329514223, 'max_depth': 14, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.3528458053424265}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,586] Trial 358 finished with value: 0.8048642533936652 and parameters: {'booster': 'gbtree', 'gamma': 2.760232168379219e-08, 'max_depth': 18, 'n_estimators': 30, 'grow_policy': 'lossguide', 'learning_rate': 0.5147781250731005}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,684] Trial 359 finished with value: 0.8026018099547512 and parameters: {'booster': 'dart', 'gamma': 4.103276749755644e-07, 'max_depth': 38, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.24392085933082583}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,761] Trial 360 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 2.3088183879521852e-07, 'max_depth': 31, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.7036861626236712}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,816] Trial 361 finished with value: 0.7861990950226244 and parameters: {'booster': 'gblinear', 'gamma': 1.215852431209584e-07, 'max_depth': 34, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.4340321228526044}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,900] Trial 362 finished with value: 0.7850678733031674 and parameters: {'booster': 'dart', 'gamma': 5.322008988129022e-08, 'max_depth': 20, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.9932510163585252}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:34] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:34,974] Trial 363 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 6.949792958449914e-07, 'max_depth': 26, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.30954748083102235}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,051] Trial 364 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 0.00035189802328856727, 'max_depth': 22, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.501173717342983}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,134] Trial 365 finished with value: 0.7969457013574661 and parameters: {'booster': 'dart', 'gamma': 1.7727158550340405e-07, 'max_depth': 16, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.20955023160680447}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,203] Trial 366 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 2.1748363512056613e-08, 'max_depth': 12, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.34421412015127}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,281] Trial 367 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 8.413044640297826e-08, 'max_depth': 31, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.6867567285176928}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,361] Trial 368 finished with value: 0.7680995475113123 and parameters: {'booster': 'dart', 'gamma': 4.169168374064869e-08, 'max_depth': 17, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.005239396024271274}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,429] Trial 369 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 1.189759575184374e-07, 'max_depth': 28, 'n_estimators': 2, 'grow_policy': 'depthwise', 'learning_rate': 0.48931297774777205}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,511] Trial 370 finished with value: 0.7929864253393665 and parameters: {'booster': 'gbtree', 'gamma': 2.798985376570162e-07, 'max_depth': 36, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.23854498066347418}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,595] Trial 371 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 2.028418110804704e-07, 'max_depth': 14, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.3687267657952431}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,676] Trial 372 finished with value: 0.7878959276018099 and parameters: {'booster': 'gbtree', 'gamma': 6.398599571788567e-08, 'max_depth': 33, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.7140052011375492}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,752] Trial 373 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 1.4066911355606746e-08, 'max_depth': 23, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.5004693562225303}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,830] Trial 374 finished with value: 0.7986425339366516 and parameters: {'booster': 'dart', 'gamma': 1.4158233075610783e-07, 'max_depth': 18, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.17191128539812586}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,915] Trial 375 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 3.593596791753208e-08, 'max_depth': 40, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 2.5076382299231482e-05}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:35] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:35,997] Trial 376 finished with value: 0.8042986425339367 and parameters: {'booster': 'dart', 'gamma': 6.704170123904257e-08, 'max_depth': 20, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.28195632263003445}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,074] Trial 377 finished with value: 0.7890271493212669 and parameters: {'booster': 'gbtree', 'gamma': 0.0009098178218129975, 'max_depth': 26, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.9898448612251112}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,153] Trial 378 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 0.0031414974111363494, 'max_depth': 29, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.37310375275270363}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,230] Trial 379 finished with value: 0.7952488687782805 and parameters: {'booster': 'dart', 'gamma': 1.1015437878630163e-07, 'max_depth': 15, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.6423311877593527}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,318] Trial 380 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 0.00012075542250074186, 'max_depth': 46, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.48683018666644257}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,382] Trial 381 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 3.6874899867459804e-07, 'max_depth': 10, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.2538642051621658}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,471] Trial 382 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 0.03829983731922516, 'max_depth': 34, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 1.439450916054247e-08}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,542] Trial 383 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 1.9781650476483375e-07, 'max_depth': 21, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.16432630087144515}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,603] Trial 384 finished with value: 0.7856334841628959 and parameters: {'booster': 'gblinear', 'gamma': 4.2774491486188865e-05, 'max_depth': 17, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.7102110675503417}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,682] Trial 385 finished with value: 0.7941176470588235 and parameters: {'booster': 'gbtree', 'gamma': 1.915484984344073e-08, 'max_depth': 31, 'n_estimators': 18, 'grow_policy': 'lossguide', 'learning_rate': 0.34896582689532063}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,757] Trial 386 finished with value: 0.7986425339366516 and parameters: {'booster': 'dart', 'gamma': 9.082428919017796e-08, 'max_depth': 13, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.5037975452825547}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,824] Trial 387 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 0.5337138037244749, 'max_depth': 24, 'n_estimators': 31, 'grow_policy': 'depthwise', 'learning_rate': 0.2258043630898427}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,898] Trial 388 finished with value: 0.8076923076923077 and parameters: {'booster': 'gbtree', 'gamma': 1.0186783370797198e-08, 'max_depth': 18, 'n_estimators': 77, 'grow_policy': 'lossguide', 'learning_rate': 0.35860793095162213}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:36] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:36,970] Trial 389 finished with value: 0.7929864253393665 and parameters: {'booster': 'gbtree', 'gamma': 1.0401852177581913e-08, 'max_depth': 18, 'n_estimators': 73, 'grow_policy': 'lossguide', 'learning_rate': 0.1149504470872032}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,048] Trial 390 finished with value: 0.8048642533936652 and parameters: {'booster': 'dart', 'gamma': 1.5607921691175574e-08, 'max_depth': 16, 'n_estimators': 9, 'grow_policy': 'lossguide', 'learning_rate': 0.31182772497939243}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,158] Trial 391 finished with value: 0.794683257918552 and parameters: {'booster': 'gbtree', 'gamma': 1.2742401909656515e-08, 'max_depth': 77, 'n_estimators': 75, 'grow_policy': 'lossguide', 'learning_rate': 0.18347150881686994}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,236] Trial 392 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 3.0701185708159435e-08, 'max_depth': 19, 'n_estimators': 79, 'grow_policy': 'lossguide', 'learning_rate': 0.39960765736986953}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,316] Trial 393 finished with value: 0.794683257918552 and parameters: {'booster': 'dart', 'gamma': 2.006859503557247e-08, 'max_depth': 15, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 0.6946148784807298}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,390] Trial 394 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.1722746892247935e-08, 'max_depth': 20, 'n_estimators': 59, 'grow_policy': 'lossguide', 'learning_rate': 0.282862910537082}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,461] Trial 395 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.09733696587908865, 'max_depth': 12, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.41013472000202}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,561] Trial 396 finished with value: 0.8048642533936652 and parameters: {'booster': 'dart', 'gamma': 1.6699072248944028e-08, 'max_depth': 38, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.2169665582770026}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,634] Trial 397 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 5.051956282806916e-08, 'max_depth': 17, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.5698441280078766}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,721] Trial 398 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 1.0272622010570454e-08, 'max_depth': 35, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.1428196944099369}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,804] Trial 399 finished with value: 0.8031674208144797 and parameters: {'booster': 'dart', 'gamma': 2.7392534255561996e-08, 'max_depth': 19, 'n_estimators': 77, 'grow_policy': 'lossguide', 'learning_rate': 0.32112197089453365}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,876] Trial 400 finished with value: 0.7918552036199095 and parameters: {'booster': 'gbtree', 'gamma': 1.3834202974795583e-07, 'max_depth': 15, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.7275660379106133}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:37] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:37,957] Trial 401 finished with value: 0.8048642533936652 and parameters: {'booster': 'gbtree', 'gamma': 5.241313332234071e-07, 'max_depth': 32, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.4473237148860309}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,043] Trial 402 finished with value: 0.7850678733031674 and parameters: {'booster': 'dart', 'gamma': 2.4356080468960917e-07, 'max_depth': 22, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.9925256623108571}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,113] Trial 403 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 7.609794693002128e-08, 'max_depth': 13, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.2648620035593844}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,185] Trial 404 finished with value: 0.8048642533936652 and parameters: {'booster': 'gbtree', 'gamma': 0.19130252659261146, 'max_depth': 17, 'n_estimators': 74, 'grow_policy': 'lossguide', 'learning_rate': 0.4742539955441522}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,318] Trial 405 finished with value: 0.7861990950226244 and parameters: {'booster': 'dart', 'gamma': 0.009589509141376861, 'max_depth': 97, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.7014609375052014}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,389] Trial 406 finished with value: 0.8065610859728507 and parameters: {'booster': 'gbtree', 'gamma': 1.7362560480111155e-07, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'depthwise', 'learning_rate': 0.3622951490782457}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,451] Trial 407 finished with value: 0.7743212669683258 and parameters: {'booster': 'gblinear', 'gamma': 1.4298703993223196e-07, 'max_depth': 19, 'n_estimators': 9, 'grow_policy': 'depthwise', 'learning_rate': 0.1962344127713084}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,523] Trial 408 finished with value: 0.7856334841628959 and parameters: {'booster': 'gbtree', 'gamma': 2.449674289516835e-07, 'max_depth': 21, 'n_estimators': 9, 'grow_policy': 'depthwise', 'learning_rate': 0.11105431804555257}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,601] Trial 409 finished with value: 0.8020361990950227 and parameters: {'booster': 'dart', 'gamma': 1.8113459349195985e-07, 'max_depth': 16, 'n_estimators': 79, 'grow_policy': 'depthwise', 'learning_rate': 0.3208224731715286}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,669] Trial 410 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 1.0301041507048531e-07, 'max_depth': 18, 'n_estimators': 100, 'grow_policy': 'depthwise', 'learning_rate': 0.5638803472463789}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,739] Trial 411 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 1.723047032714753e-07, 'max_depth': 14, 'n_estimators': 16, 'grow_policy': 'depthwise', 'learning_rate': 0.257213784394917}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,832] Trial 412 finished with value: 0.7941176470588235 and parameters: {'booster': 'dart', 'gamma': 3.339056788249741e-07, 'max_depth': 36, 'n_estimators': 12, 'grow_policy': 'depthwise', 'learning_rate': 0.40231080272097675}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,905] Trial 413 finished with value: 0.7873303167420814 and parameters: {'booster': 'gbtree', 'gamma': 1.0856479022262612e-07, 'max_depth': 20, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.7654467139903384}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:38] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:38,967] Trial 414 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 4.835630759255173e-08, 'max_depth': 11, 'n_estimators': 29, 'grow_policy': 'depthwise', 'learning_rate': 2.1636113818580914e-06}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,048] Trial 415 finished with value: 0.746606334841629 and parameters: {'booster': 'dart', 'gamma': 7.539274194201698e-08, 'max_depth': 17, 'n_estimators': 8, 'grow_policy': 'depthwise', 'learning_rate': 0.0021477546925591008}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,123] Trial 416 finished with value: 0.7878959276018099 and parameters: {'booster': 'gbtree', 'gamma': 4.573934693898963e-07, 'max_depth': 33, 'n_estimators': 22, 'grow_policy': 'depthwise', 'learning_rate': 0.14606743944352235}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,198] Trial 417 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 7.771250807131467e-05, 'max_depth': 15, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.5214768372156487}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,314] Trial 418 finished with value: 0.8037330316742082 and parameters: {'booster': 'dart', 'gamma': 2.72834765021596e-07, 'max_depth': 71, 'n_estimators': 71, 'grow_policy': 'lossguide', 'learning_rate': 0.32775486079646066}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,387] Trial 419 finished with value: 0.8048642533936652 and parameters: {'booster': 'gbtree', 'gamma': 1.7768247883808434e-08, 'max_depth': 19, 'n_estimators': 57, 'grow_policy': 'lossguide', 'learning_rate': 0.19953966503819592}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,457] Trial 420 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.391643329087923e-07, 'max_depth': 13, 'n_estimators': 50, 'grow_policy': 'lossguide', 'learning_rate': 0.5494090261698539}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,544] Trial 421 finished with value: 0.7980769230769231 and parameters: {'booster': 'dart', 'gamma': 1.0123737310314954e-07, 'max_depth': 21, 'n_estimators': 7, 'grow_policy': 'lossguide', 'learning_rate': 0.37097902301141417}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,654] Trial 422 finished with value: 0.7873303167420814 and parameters: {'booster': 'gbtree', 'gamma': 4.0966966915636516e-08, 'max_depth': 81, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.7536093949645596}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,752] Trial 423 finished with value: 0.7873303167420814 and parameters: {'booster': 'gbtree', 'gamma': 1.87652134974805e-07, 'max_depth': 37, 'n_estimators': 34, 'grow_policy': 'lossguide', 'learning_rate': 0.9909886779358482}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,883] Trial 424 finished with value: 0.49095022624434387 and parameters: {'booster': 'dart', 'gamma': 8.281445475048976e-07, 'max_depth': 17, 'n_estimators': 13, 'grow_policy': 'lossguide', 'learning_rate': 1.043696518599114e-05}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:39] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:39,968] Trial 425 finished with value: 0.794683257918552 and parameters: {'booster': 'gbtree', 'gamma': 7.285375604636642e-08, 'max_depth': 34, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.08675812107819615}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,048] Trial 426 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 1.0555482455981808e-08, 'max_depth': 30, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.2678451858254363}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,147] Trial 427 finished with value: 0.8014705882352942 and parameters: {'booster': 'dart', 'gamma': 0.001230674106515932, 'max_depth': 15, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.44337819090454256}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,221] Trial 428 finished with value: 0.8048642533936652 and parameters: {'booster': 'gbtree', 'gamma': 0.12215348072791221, 'max_depth': 19, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.20227647875703259}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,309] Trial 429 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 3.018109428210395e-08, 'max_depth': 32, 'n_estimators': 32, 'grow_policy': 'lossguide', 'learning_rate': 0.5511089269573016}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,377] Trial 430 finished with value: 0.7861990950226244 and parameters: {'booster': 'gblinear', 'gamma': 0.06863992174729926, 'max_depth': 23, 'n_estimators': 83, 'grow_policy': 'depthwise', 'learning_rate': 0.3244489882243529}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,465] Trial 431 finished with value: 0.7929864253393665 and parameters: {'booster': 'dart', 'gamma': 3.3645285423724557e-07, 'max_depth': 17, 'n_estimators': 25, 'grow_policy': 'lossguide', 'learning_rate': 0.7146202027740057}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,537] Trial 432 finished with value: 0.8076923076923077 and parameters: {'booster': 'gbtree', 'gamma': 1.4036632663698015e-07, 'max_depth': 14, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.3852040855372555}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,606] Trial 433 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 1.603225873873213e-07, 'max_depth': 10, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.4452275293668645}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,675] Trial 434 finished with value: 0.8071266968325792 and parameters: {'booster': 'gbtree', 'gamma': 1.0134454048096239e-07, 'max_depth': 13, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.5868187108749071}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,741] Trial 435 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.0417923461754746e-07, 'max_depth': 8, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.7542008792482725}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,812] Trial 436 finished with value: 0.7929864253393665 and parameters: {'booster': 'gbtree', 'gamma': 6.496402600563248e-08, 'max_depth': 12, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.9570080769756173}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,882] Trial 437 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 1.2982126171072833e-07, 'max_depth': 11, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.5801239674466644}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:40] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:40,954] Trial 438 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 2.0695683991196635e-07, 'max_depth': 13, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.5626538381677187}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,031] Trial 439 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 9.329869046440771e-08, 'max_depth': 14, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.4039711741321525}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,103] Trial 440 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 5.388119157489274e-08, 'max_depth': 15, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.7206628886293456}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,175] Trial 441 finished with value: 0.8071266968325792 and parameters: {'booster': 'gbtree', 'gamma': 2.682157303255622e-07, 'max_depth': 16, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.3852907248117341}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,242] Trial 442 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 1.3967465330018768e-07, 'max_depth': 9, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.34847595746678295}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,319] Trial 443 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 8.797708294085361e-08, 'max_depth': 12, 'n_estimators': 48, 'grow_policy': 'lossguide', 'learning_rate': 0.33262642939326603}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,391] Trial 444 finished with value: 0.7709276018099548 and parameters: {'booster': 'gbtree', 'gamma': 0.00016377018310740975, 'max_depth': 14, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.013892122919963883}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,459] Trial 445 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 1.9006252600958132e-07, 'max_depth': 18, 'n_estimators': 37, 'grow_policy': 'depthwise', 'learning_rate': 0.44223806747790895}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,531] Trial 446 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 1.3700806329833381e-07, 'max_depth': 16, 'n_estimators': 86, 'grow_policy': 'lossguide', 'learning_rate': 5.138313734721248e-05}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,607] Trial 447 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 2.5766053527878054e-07, 'max_depth': 20, 'n_estimators': 46, 'grow_policy': 'lossguide', 'learning_rate': 0.26350209302216987}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,680] Trial 448 finished with value: 0.7918552036199095 and parameters: {'booster': 'gbtree', 'gamma': 6.892780289584149e-08, 'max_depth': 13, 'n_estimators': 5, 'grow_policy': 'lossguide', 'learning_rate': 0.9847561392815102}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,752] Trial 449 finished with value: 0.8065610859728507 and parameters: {'booster': 'gbtree', 'gamma': 4.717732986261857e-07, 'max_depth': 16, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.5697390688600125}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,830] Trial 450 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 0.02119195616054359, 'max_depth': 16, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.0003743367590455133}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,906] Trial 451 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 4.0567972564158365e-07, 'max_depth': 18, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.40005003868984057}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:41] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:41,982] Trial 452 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 2.5691807757635565e-05, 'max_depth': 14, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.2542345396512497}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,058] Trial 453 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 2.912062570720455e-07, 'max_depth': 11, 'n_estimators': 45, 'grow_policy': 'lossguide', 'learning_rate': 0.5779909588391423}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,138] Trial 454 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 9.905664459849743e-08, 'max_depth': 16, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 2.221877622493716e-07}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,218] Trial 455 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 5.676345863237258e-07, 'max_depth': 21, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.37742391824439175}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,302] Trial 456 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 4.439434028212954e-08, 'max_depth': 18, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.165412156843858}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,371] Trial 457 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 1.3703627582507193e-07, 'max_depth': 15, 'n_estimators': 38, 'grow_policy': 'depthwise', 'learning_rate': 0.6987032657170423}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,451] Trial 458 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.17379277196271634, 'max_depth': 19, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.4793505728842028}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,525] Trial 459 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 0.2989640524475209, 'max_depth': 13, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.2729519730555431}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,607] Trial 460 finished with value: 0.7890271493212669 and parameters: {'booster': 'gbtree', 'gamma': 2.0837464586759535e-07, 'max_depth': 22, 'n_estimators': 80, 'grow_policy': 'lossguide', 'learning_rate': 0.7265509442920554}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,684] Trial 461 finished with value: 0.8065610859728507 and parameters: {'booster': 'gbtree', 'gamma': 7.809479693042146e-08, 'max_depth': 17, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.32103024226452975}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,759] Trial 462 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 5.708940691436575e-08, 'max_depth': 17, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.20679292450573553}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,837] Trial 463 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 8.244456390799052e-08, 'max_depth': 10, 'n_estimators': 36, 'grow_policy': 'lossguide', 'learning_rate': 0.33963764598973767}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,905] Trial 464 finished with value: 0.7845022624434389 and parameters: {'booster': 'gblinear', 'gamma': 3.6499909950804975e-08, 'max_depth': 15, 'n_estimators': 33, 'grow_policy': 'lossguide', 'learning_rate': 0.5202432902524469}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:42] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:42,988] Trial 465 finished with value: 0.8014705882352942 and parameters: {'booster': 'gbtree', 'gamma': 6.446575838498782e-08, 'max_depth': 17, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.2780305697033826}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,068] Trial 466 finished with value: 0.7929864253393665 and parameters: {'booster': 'gbtree', 'gamma': 1.0766843873836028e-07, 'max_depth': 12, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.9853153112547606}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,147] Trial 467 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 1.4595232377076768e-07, 'max_depth': 19, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.14601297547702277}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,215] Trial 468 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 3.813427797453443e-07, 'max_depth': 14, 'n_estimators': 40, 'grow_policy': 'depthwise', 'learning_rate': 0.4598802963886829}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,293] Trial 469 finished with value: 0.7969457013574661 and parameters: {'booster': 'gbtree', 'gamma': 8.016215993963094e-08, 'max_depth': 17, 'n_estimators': 39, 'grow_policy': 'lossguide', 'learning_rate': 0.6173123828153848}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,374] Trial 470 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 4.9766416124498845e-08, 'max_depth': 15, 'n_estimators': 38, 'grow_policy': 'lossguide', 'learning_rate': 0.2122729469081999}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,451] Trial 471 finished with value: 0.8020361990950227 and parameters: {'booster': 'gbtree', 'gamma': 1.0977752696465192e-07, 'max_depth': 20, 'n_estimators': 69, 'grow_policy': 'lossguide', 'learning_rate': 0.41402078334617254}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,529] Trial 472 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 2.619976228903233e-07, 'max_depth': 13, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.3050887584986429}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,605] Trial 473 finished with value: 0.7890271493212669 and parameters: {'booster': 'gbtree', 'gamma': 1.602411901662582e-07, 'max_depth': 18, 'n_estimators': 64, 'grow_policy': 'lossguide', 'learning_rate': 0.684593340827928}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,681] Trial 474 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 7.747961194403101e-08, 'max_depth': 10, 'n_estimators': 31, 'grow_policy': 'lossguide', 'learning_rate': 0.44670979709034614}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,762] Trial 475 finished with value: 0.7997737556561086 and parameters: {'booster': 'gbtree', 'gamma': 2.2780576455762136e-07, 'max_depth': 16, 'n_estimators': 78, 'grow_policy': 'lossguide', 'learning_rate': 0.21818622054626527}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,848] Trial 476 finished with value: 0.49095022624434387 and parameters: {'booster': 'gbtree', 'gamma': 4.071484494441208e-08, 'max_depth': 20, 'n_estimators': 40, 'grow_policy': 'lossguide', 'learning_rate': 0.0008240090927657517}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:43,930] Trial 477 finished with value: 0.8042986425339367 and parameters: {'booster': 'gbtree', 'gamma': 1.1981300710317438e-06, 'max_depth': 14, 'n_estimators': 35, 'grow_policy': 'lossguide', 'learning_rate': 0.3255128076591336}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,003] Trial 478 finished with value: 0.7980769230769231 and parameters: {'booster': 'gbtree', 'gamma': 1.053314154682991e-07, 'max_depth': 7, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.7195515191665798}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,097] Trial 479 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 6.93935582626041e-07, 'max_depth': 41, 'n_estimators': 43, 'grow_policy': 'lossguide', 'learning_rate': 0.5316491976290205}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,165] Trial 480 finished with value: 0.7884615384615384 and parameters: {'booster': 'gblinear', 'gamma': 2.627108678356997e-08, 'max_depth': 18, 'n_estimators': 34, 'grow_policy': 'depthwise', 'learning_rate': 0.9792220583634903}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,250] Trial 481 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 1.8794416571896008e-07, 'max_depth': 16, 'n_estimators': 52, 'grow_policy': 'lossguide', 'learning_rate': 0.3532689358541776}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,328] Trial 482 finished with value: 0.7952488687782805 and parameters: {'booster': 'gbtree', 'gamma': 5.8807380084274213e-08, 'max_depth': 12, 'n_estimators': 81, 'grow_policy': 'lossguide', 'learning_rate': 0.13654144341107538}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,410] Trial 483 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 4.591608377493248e-07, 'max_depth': 21, 'n_estimators': 29, 'grow_policy': 'lossguide', 'learning_rate': 0.5391699703217608}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,488] Trial 484 finished with value: 0.8003393665158371 and parameters: {'booster': 'gbtree', 'gamma': 9.321561096197834e-08, 'max_depth': 16, 'n_estimators': 47, 'grow_policy': 'lossguide', 'learning_rate': 0.24497802486848969}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,565] Trial 485 finished with value: 0.7992081447963801 and parameters: {'booster': 'gbtree', 'gamma': 1.4991831307376658e-05, 'max_depth': 19, 'n_estimators': 11, 'grow_policy': 'lossguide', 'learning_rate': 0.38968879571355763}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,641] Trial 486 finished with value: 0.7975113122171946 and parameters: {'booster': 'gbtree', 'gamma': 1.4482229365088609e-07, 'max_depth': 14, 'n_estimators': 6, 'grow_policy': 'lossguide', 'learning_rate': 0.1761331151100394}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,717] Trial 487 finished with value: 0.794683257918552 and parameters: {'booster': 'gbtree', 'gamma': 0.0056391908671279065, 'max_depth': 22, 'n_estimators': 3, 'grow_policy': 'lossguide', 'learning_rate': 0.7068097038016196}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,794] Trial 488 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 0.04235875779939763, 'max_depth': 18, 'n_estimators': 44, 'grow_policy': 'lossguide', 'learning_rate': 0.4832091416968903}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,872] Trial 489 finished with value: 0.7856334841628959 and parameters: {'booster': 'gbtree', 'gamma': 0.1251335507261558, 'max_depth': 15, 'n_estimators': 8, 'grow_policy': 'lossguide', 'learning_rate': 0.9978288668494391}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:44,942] Trial 490 finished with value: 0.7986425339366516 and parameters: {'booster': 'gbtree', 'gamma': 5.448478578039075e-05, 'max_depth': 12, 'n_estimators': 41, 'grow_policy': 'lossguide', 'learning_rate': 0.27574009808199146}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:44] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,021] Trial 491 finished with value: 0.8037330316742082 and parameters: {'booster': 'gbtree', 'gamma': 1.3509053838060938e-07, 'max_depth': 17, 'n_estimators': 27, 'grow_policy': 'lossguide', 'learning_rate': 0.3713595246614899}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,096] Trial 492 finished with value: 0.8026018099547512 and parameters: {'booster': 'gbtree', 'gamma': 2.8587463923719643e-07, 'max_depth': 20, 'n_estimators': 6, 'grow_policy': 'depthwise', 'learning_rate': 0.5678356797006565}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,175] Trial 493 finished with value: 0.795814479638009 and parameters: {'booster': 'dart', 'gamma': 0.2069925752404187, 'max_depth': 10, 'n_estimators': 76, 'grow_policy': 'lossguide', 'learning_rate': 0.2717938184410848}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,254] Trial 494 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 6.070382944580102e-08, 'max_depth': 16, 'n_estimators': 1, 'grow_policy': 'lossguide', 'learning_rate': 0.6879206819494593}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,331] Trial 495 finished with value: 0.8031674208144797 and parameters: {'booster': 'gbtree', 'gamma': 0.09243710563460228, 'max_depth': 14, 'n_estimators': 4, 'grow_policy': 'lossguide', 'learning_rate': 0.1928208837475019}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,410] Trial 496 finished with value: 0.8009049773755657 and parameters: {'booster': 'gbtree', 'gamma': 1.9770377109923282e-07, 'max_depth': 18, 'n_estimators': 37, 'grow_policy': 'lossguide', 'learning_rate': 0.41574496930455057}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,504] Trial 497 finished with value: 0.7992081447963801 and parameters: {'booster': 'dart', 'gamma': 3.30885200212714e-08, 'max_depth': 22, 'n_estimators': 10, 'grow_policy': 'lossguide', 'learning_rate': 0.5647986637542257}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,584] Trial 498 finished with value: 0.7963800904977375 and parameters: {'booster': 'gbtree', 'gamma': 9.255553428824357e-08, 'max_depth': 19, 'n_estimators': 42, 'grow_policy': 'lossguide', 'learning_rate': 0.09696344579571628}. Best is trial 337 with value: 0.8144796380090498.\n",
      "/opt/conda/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [04:03:45] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"gamma\", \"grow_policy\", \"max_depth\", \"max_leaves\", \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-03-08 04:03:45,654] Trial 499 finished with value: 0.7861990950226244 and parameters: {'booster': 'gblinear', 'gamma': 3.3329159145880566e-07, 'max_depth': 13, 'n_estimators': 49, 'grow_policy': 'lossguide', 'learning_rate': 0.3263719176399219}. Best is trial 337 with value: 0.8144796380090498.\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(X, label=dft['Transported'])\n",
    "dvalid = xgb.DMatrix(x, label=dfv['Transported'])\n",
    "\n",
    "def objective(trial):\n",
    "    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n",
    "    param = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth',1, 100),\n",
    "        'max_leaves': trial.suggest_int('max_depth',1, 100),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',1, 100),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1.0, log=True)\n",
    "    }    \n",
    "    bst = xgb.train(param, dtrain)\n",
    "    preds = bst.predict(dvalid)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.accuracy_score(dfv['Transported'], pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd07a50",
   "metadata": {
    "papermill": {
     "duration": 0.050639,
     "end_time": "2024-03-08T04:03:45.760086",
     "exception": false,
     "start_time": "2024-03-08T04:03:45.709447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475b8f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:45.861934Z",
     "iopub.status.busy": "2024-03-08T04:03:45.860406Z",
     "iopub.status.idle": "2024-03-08T04:03:45.866610Z",
     "shell.execute_reply": "2024-03-08T04:03:45.865722Z"
    },
    "papermill": {
     "duration": 0.058873,
     "end_time": "2024-03-08T04:03:45.868583",
     "exception": false,
     "start_time": "2024-03-08T04:03:45.809710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRFClassifier(\n",
    "    booster='gbtree',\n",
    "    device='cpu',\n",
    "    eval_metric=sklearn.metrics.mean_absolute_percentage_error,\n",
    "    grow_policy = 'lossguide',\n",
    "    gamma = 0.030185106394347308,\n",
    "    max_depth= 5,\n",
    "    n_estimators = 93,\n",
    "    learning_rate = 0.571705231643359\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a514f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:45.973406Z",
     "iopub.status.busy": "2024-03-08T04:03:45.973040Z",
     "iopub.status.idle": "2024-03-08T04:03:46.177935Z",
     "shell.execute_reply": "2024-03-08T04:03:46.177053Z"
    },
    "papermill": {
     "duration": 0.259347,
     "end_time": "2024-03-08T04:03:46.179932",
     "exception": false,
     "start_time": "2024-03-08T04:03:45.920585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.51376\tvalidation_0-mean_absolute_percentage_error:869371106820096.00000\tvalidation_1-logloss:0.52386\tvalidation_1-mean_absolute_percentage_error:913133401014272.00000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7ec08f006290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRFClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBRFClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device=&#x27;cpu&#x27;,\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=&lt;function mean_absolute_percentage_error at 0x7ec08f006290&gt;,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy=&#x27;lossguide&#x27;, importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective=&#x27;binary:logistic&#x27;,\n",
       "                random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRFClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "                colsample_bylevel=None, colsample_bytree=None, device='cpu',\n",
       "                early_stopping_rounds=None, enable_categorical=False,\n",
       "                eval_metric=<function mean_absolute_percentage_error at 0x7ec08f006290>,\n",
       "                feature_types=None, gamma=0.030185106394347308,\n",
       "                grow_policy='lossguide', importance_type=None,\n",
       "                interaction_constraints=None, learning_rate=0.571705231643359,\n",
       "                max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "                max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                multi_strategy=None, n_estimators=93, n_jobs=None,\n",
       "                num_parallel_tree=None, objective='binary:logistic',\n",
       "                random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,eval_set=[(X,y),(x,Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e23fd79b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:46.345639Z",
     "iopub.status.busy": "2024-03-08T04:03:46.344925Z",
     "iopub.status.idle": "2024-03-08T04:03:46.364679Z",
     "shell.execute_reply": "2024-03-08T04:03:46.363887Z"
    },
    "papermill": {
     "duration": 0.135037,
     "end_time": "2024-03-08T04:03:46.366773",
     "exception": false,
     "start_time": "2024-03-08T04:03:46.231736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7861990950226244"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueval = dfv['Transported']\n",
    "predval = model.predict(x)\n",
    "sklearn.metrics.accuracy_score(trueval, predval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74c5a50d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:46.472744Z",
     "iopub.status.busy": "2024-03-08T04:03:46.472387Z",
     "iopub.status.idle": "2024-03-08T04:03:46.819724Z",
     "shell.execute_reply": "2024-03-08T04:03:46.818845Z"
    },
    "papermill": {
     "duration": 0.403271,
     "end_time": "2024-03-08T04:03:46.821820",
     "exception": false,
     "start_time": "2024-03-08T04:03:46.418549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b5bd2",
   "metadata": {
    "papermill": {
     "duration": 0.051167,
     "end_time": "2024-03-08T04:03:46.924740",
     "exception": false,
     "start_time": "2024-03-08T04:03:46.873573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cedbe09b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.029246Z",
     "iopub.status.busy": "2024-03-08T04:03:47.028934Z",
     "iopub.status.idle": "2024-03-08T04:03:47.055280Z",
     "shell.execute_reply": "2024-03-08T04:03:47.054106Z"
    },
    "papermill": {
     "duration": 0.081249,
     "end_time": "2024-03-08T04:03:47.057323",
     "exception": false,
     "start_time": "2024-03-08T04:03:46.976074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')\n",
    "labels = test_df['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d4864b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.166711Z",
     "iopub.status.busy": "2024-03-08T04:03:47.166015Z",
     "iopub.status.idle": "2024-03-08T04:03:47.195940Z",
     "shell.execute_reply": "2024-03-08T04:03:47.194133Z"
    },
    "papermill": {
     "duration": 0.087693,
     "end_time": "2024-03-08T04:03:47.198559",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.110866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4186.000000</td>\n",
       "      <td>4195.000000</td>\n",
       "      <td>4171.000000</td>\n",
       "      <td>4179.000000</td>\n",
       "      <td>4176.000000</td>\n",
       "      <td>4197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.658146</td>\n",
       "      <td>219.266269</td>\n",
       "      <td>439.484296</td>\n",
       "      <td>177.295525</td>\n",
       "      <td>303.052443</td>\n",
       "      <td>310.710031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.179072</td>\n",
       "      <td>607.011289</td>\n",
       "      <td>1527.663045</td>\n",
       "      <td>560.821123</td>\n",
       "      <td>1117.186015</td>\n",
       "      <td>1246.994742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>11567.000000</td>\n",
       "      <td>25273.000000</td>\n",
       "      <td>8292.000000</td>\n",
       "      <td>19844.000000</td>\n",
       "      <td>22272.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
       "count  4186.000000   4195.000000   4171.000000   4179.000000   4176.000000   \n",
       "mean     28.658146    219.266269    439.484296    177.295525    303.052443   \n",
       "std      14.179072    607.011289   1527.663045    560.821123   1117.186015   \n",
       "min       0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%      26.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%      37.000000     53.000000     78.000000     33.000000     50.000000   \n",
       "max      79.000000  11567.000000  25273.000000   8292.000000  19844.000000   \n",
       "\n",
       "             VRDeck  \n",
       "count   4197.000000  \n",
       "mean     310.710031  \n",
       "std     1246.994742  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%       36.000000  \n",
       "max    22272.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a28d650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.306168Z",
     "iopub.status.busy": "2024-03-08T04:03:47.305516Z",
     "iopub.status.idle": "2024-03-08T04:03:47.334316Z",
     "shell.execute_reply": "2024-03-08T04:03:47.333533Z"
    },
    "papermill": {
     "duration": 0.085169,
     "end_time": "2024-03-08T04:03:47.336176",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.251007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/17557714.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
      "/tmp/ipykernel_18/17557714.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})\n"
     ]
    }
   ],
   "source": [
    "test_df[['CabinDeck', 'CabinNum', 'CabinSide']] = test_df['Cabin'].str.split('/', n=2, expand=True)\n",
    "test_df = pd.concat([test_df,pd.get_dummies(test_df.Destination)], axis = 1)\n",
    "test_df = test_df.drop(['Name','Destination','Cabin','PassengerId'],axis=1)\n",
    "test_df.fillna(0,inplace=True)\n",
    "\n",
    "test_df['CryoSleep'] = test_df['CryoSleep'].astype(bool)\n",
    "test_df['VIP'] = test_df['VIP'].astype(bool)\n",
    "test_df['CabinSide'] = test_df['CabinSide'].replace({'S': 0, 'P': 1})\n",
    "test_df['CabinNum'] = test_df['CabinNum'].astype(int)\n",
    "test_df['CabinDeck'] = test_df['CabinSide'].replace(\n",
    "    {'A': 0,\n",
    "     'B': 1,\n",
    "     'C': 2,\n",
    "     'D': 3,\n",
    "     'E': 4,\n",
    "     'F': 5,\n",
    "     'G': 6,\n",
    "     'T': 7\n",
    "    })\n",
    "test_df['HomePlanet'] = test_df['HomePlanet'].replace({'Europa': 0, 'Earth': 1, 'Mars': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2509b0d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.444401Z",
     "iopub.status.busy": "2024-03-08T04:03:47.443774Z",
     "iopub.status.idle": "2024-03-08T04:03:47.463573Z",
     "shell.execute_reply": "2024-03-08T04:03:47.462426Z"
    },
    "papermill": {
     "duration": 0.076222,
     "end_time": "2024-03-08T04:03:47.465498",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.389276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>55 Cancri e</th>\n",
       "      <th>PSO J318.5-22</th>\n",
       "      <th>TRAPPIST-1e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>1</td>\n",
       "      <td>297</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomePlanet  CryoSleep   Age    VIP  RoomService  FoodCourt  \\\n",
       "0              1       True  27.0  False          0.0        0.0   \n",
       "1              1      False  19.0  False          0.0        9.0   \n",
       "2              0       True  31.0  False          0.0        0.0   \n",
       "3              0      False  38.0  False          0.0     6652.0   \n",
       "4              1      False  20.0  False         10.0        0.0   \n",
       "...          ...        ...   ...    ...          ...        ...   \n",
       "4272           1       True  34.0  False          0.0        0.0   \n",
       "4273           1      False  42.0  False          0.0      847.0   \n",
       "4274           2       True   0.0  False          0.0        0.0   \n",
       "4275           0      False   0.0  False          0.0     2680.0   \n",
       "4276           1       True  43.0  False          0.0        0.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  CabinDeck  CabinNum  CabinSide  \\\n",
       "0              0.0     0.0     0.0          0         3          0   \n",
       "1              0.0  2823.0     0.0          0         4          0   \n",
       "2              0.0     0.0     0.0          0         0          0   \n",
       "3              0.0   181.0   585.0          0         1          0   \n",
       "4            635.0     0.0     0.0          0         5          0   \n",
       "...            ...     ...     ...        ...       ...        ...   \n",
       "4272           0.0     0.0     0.0          0      1496          0   \n",
       "4273          17.0    10.0   144.0          0         0          0   \n",
       "4274           0.0     0.0     0.0          1       296          1   \n",
       "4275           0.0     0.0   523.0          1       297          1   \n",
       "4276           0.0     0.0     0.0          0      1498          0   \n",
       "\n",
       "      55 Cancri e  PSO J318.5-22  TRAPPIST-1e  \n",
       "0           False          False         True  \n",
       "1           False          False         True  \n",
       "2            True          False        False  \n",
       "3           False          False         True  \n",
       "4           False          False         True  \n",
       "...           ...            ...          ...  \n",
       "4272        False          False         True  \n",
       "4273        False          False         True  \n",
       "4274         True          False        False  \n",
       "4275        False          False        False  \n",
       "4276        False           True        False  \n",
       "\n",
       "[4277 rows x 15 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0672a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.572246Z",
     "iopub.status.busy": "2024-03-08T04:03:47.571896Z",
     "iopub.status.idle": "2024-03-08T04:03:47.595544Z",
     "shell.execute_reply": "2024-03-08T04:03:47.594185Z"
    },
    "papermill": {
     "duration": 0.080216,
     "end_time": "2024-03-08T04:03:47.598090",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.517874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2563146156.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfexport['Transported'] = dfexport['Transported'].replace({0: False, 1: True})\n",
      "/tmp/ipykernel_18/2563146156.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfexport['Transported'] = dfexport['Transported'].replace({0: False, 1: True})\n"
     ]
    }
   ],
   "source": [
    "test_df['Transported'] = model.predict(test_df)\n",
    "test_df['PassengerId'] = labels\n",
    "dfexport = test_df[['PassengerId','Transported']]\n",
    "dfexport['Transported'] = dfexport['Transported'].replace({0: False, 1: True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb727878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.704367Z",
     "iopub.status.busy": "2024-03-08T04:03:47.703992Z",
     "iopub.status.idle": "2024-03-08T04:03:47.715365Z",
     "shell.execute_reply": "2024-03-08T04:03:47.714722Z"
    },
    "papermill": {
     "duration": 0.066458,
     "end_time": "2024-03-08T04:03:47.716959",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.650501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Transported\n",
       "0        0013_01         True\n",
       "1        0018_01        False\n",
       "2        0019_01         True\n",
       "3        0021_01         True\n",
       "4        0023_01        False\n",
       "...          ...          ...\n",
       "4272     9266_02         True\n",
       "4273     9269_01         True\n",
       "4274     9271_01         True\n",
       "4275     9273_01         True\n",
       "4276     9277_01         True\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21aab274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.824957Z",
     "iopub.status.busy": "2024-03-08T04:03:47.824306Z",
     "iopub.status.idle": "2024-03-08T04:03:47.836618Z",
     "shell.execute_reply": "2024-03-08T04:03:47.835482Z"
    },
    "papermill": {
     "duration": 0.069186,
     "end_time": "2024-03-08T04:03:47.838899",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.769713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfexport.to_csv('predictionoutput2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "149cd71c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-08T04:03:47.949209Z",
     "iopub.status.busy": "2024-03-08T04:03:47.947924Z",
     "iopub.status.idle": "2024-03-08T04:03:47.953360Z",
     "shell.execute_reply": "2024-03-08T04:03:47.951881Z"
    },
    "papermill": {
     "duration": 0.061449,
     "end_time": "2024-03-08T04:03:47.955786",
     "exception": false,
     "start_time": "2024-03-08T04:03:47.894337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The fillna method is trash"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.927687,
   "end_time": "2024-03-08T04:03:48.731308",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-08T04:03:01.803621",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
